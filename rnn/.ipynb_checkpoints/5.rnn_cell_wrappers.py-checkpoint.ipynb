{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic RNN cells and wrappers\n",
    "http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features\n",
    "\n",
    "可查看源代码：rnn_cell.py and contrib/rnn_cell.\n",
    "    \n",
    "As of the time of this writing, the basic RNN cells and wrappers are:\n",
    "\n",
    "+ BasicRNNCell – A vanilla RNN cell.\n",
    "+ GRUCell – A Gated Recurrent Unit cell.\n",
    "+ BasicLSTMCell – An LSTM cell based on Recurrent Neural Network Regularization. No peephole connection or cell clipping.\n",
    "+ LSTMCell – A more complex LSTM cell that allows for optional peephole connections and cell clipping.\n",
    "+ MultiRNNCell – A wrapper to combine multiple cells into a multi-layer cell.\n",
    "+ DropoutWrapper – A wrapper to add dropout to input and/or output connections of a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据API文档，其构造函数中num_units是没有默认值，必须由网络设计者给定。API文档中对这个参数的作用描述如下\n",
    "\n",
    "num_units: int, The number of units in the LSTM cell\n",
    "\n",
    "对于上述描述，笔者表示仍然看不懂，因为“units in the LSTM cell”这个概念在API文档上并没有直接定义。\n",
    "\n",
    "为了解决这个问题，我们从TF源代码入手，分析上述API对应的源代码 core_rnn_cell_impl.py，找到如下源代码\n",
    "```python\n",
    "class BasicLSTMCell(RNNCell):\n",
    "  \"\"\"Basic LSTM recurrent network cell.\n",
    "  The implementation is based on: http://arxiv.org/abs/1409.2329.\n",
    "  We add forget_bias (default: 1) to the biases of the forget gate in order to\n",
    "  reduce the scale of forgetting in the beginning of the training.\n",
    "  It does not allow cell clipping, a projection layer, and does not\n",
    "  use peep-hole connections: it is the basic baseline.\n",
    "  For advanced models, please use the full LSTMCell that follows.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, num_units, forget_bias=1.0, input_size=None,\n",
    "               state_is_tuple=True, activation=tanh, reuse=None):\n",
    "    \"\"\"Initialize the basic LSTM cell.\n",
    "    Args:\n",
    "      num_units: int, The number of units in the LSTM cell.\n",
    "      forget_bias: float, The bias added to forget gates (see above).\n",
    "      input_size: Deprecated and unused.\n",
    "      state_is_tuple: If True, accepted and returned states are 2-tuples of\n",
    "        the `c_state` and `m_state`.  If False, they are concatenated\n",
    "        along the column axis.  The latter behavior will soon be deprecated.\n",
    "      activation: Activation function of the inner states.\n",
    "      reuse: (optional) Python boolean describing whether to reuse variables\n",
    "        in an existing scope.  If not `True`, and the existing scope already has\n",
    "        the given variables, an error is raised.\n",
    "    \"\"\"\n",
    "    if not state_is_tuple:\n",
    "      logging.warn(\"%s: Using a concatenated state is slower and will soon be \"\n",
    "                   \"deprecated.  Use state_is_tuple=True.\", self)\n",
    "    if input_size is not None:\n",
    "      logging.warn(\"%s: The input_size parameter is deprecated.\", self)\n",
    "    self._num_units = num_units\n",
    "    self._forget_bias = forget_bias\n",
    "    self._state_is_tuple = state_is_tuple\n",
    "    self._activation = activation\n",
    "    self._reuse = reuse\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "```\n",
    "\n",
    "注意到其中output_size()函数返回值就是num_units，所以可以推断num_units决定了LSTM Cell输出向量的维度，\n",
    "对于一个batch中的一个sample，num_units决定了这个sample的维度。进一步，num_units可以理解为RNN网络表征特征的复杂度，\n",
    "需要区分的特征越复杂，就需要越多的维度来表征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-2e1a65539247>:54: run_n (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py:842: run_feeds (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py:900: run_feeds_iter (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "(2, 10, 64)\n",
      "[[[ 0.0014168   0.00064998  0.         ..., -0.          0.00074619\n",
      "    0.00175768]\n",
      "  [ 0.00136874  0.          0.00150519 ..., -0.00395315  0.          0.00420968]\n",
      "  [ 0.00180548  0.          0.00125465 ..., -0.00368526  0.0026687\n",
      "    0.00566239]\n",
      "  ..., \n",
      "  [ 0.00759778 -0.00582007  0.         ...,  0.         -0.00136309\n",
      "   -0.00707219]\n",
      "  [ 0.0127089  -0.01148308  0.01078373 ...,  0.00687817 -0.         -0.        ]\n",
      "  [ 0.         -0.00485191  0.         ...,  0.         -0.         -0.        ]]\n",
      "\n",
      " [[-0.00129557  0.          0.         ...,  0.00106029  0.00174878\n",
      "   -0.000134  ]\n",
      "  [-0.00115162 -0.          0.         ...,  0.00166114  0.0009723\n",
      "   -0.00200903]\n",
      "  [-0.00557713  0.00480456  0.00459343 ...,  0.00461992 -0.00172829  0.        ]\n",
      "  ..., \n",
      "  [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "  [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      "  [ 0.          0.          0.         ...,  0.          0.          0.        ]]]\n",
      "(2, 64)\n",
      "[[-0.09618975  0.04516253 -0.01128957  0.07569801 -0.04433284 -0.00882167\n",
      "   0.13450912  0.03154868 -0.04553171 -0.01101304  0.01658795 -0.09143129\n",
      "  -0.04773291  0.00761628 -0.03939458  0.01781564  0.08936297 -0.03508556\n",
      "  -0.04549305 -0.0308867   0.00467171  0.00710501  0.05302733  0.05625946\n",
      "   0.08224664 -0.04884221  0.00332295  0.1635122  -0.09785284 -0.03971914\n",
      "   0.01947939 -0.21687048 -0.03653531  0.02335797 -0.01562606  0.04697738\n",
      "   0.03530674 -0.07293496  0.04157212  0.11575638 -0.01609156  0.2183619\n",
      "  -0.03434607 -0.10981249  0.07016585  0.11494733  0.06180264  0.03001492\n",
      "  -0.17980661 -0.06087087 -0.0052284   0.04829981  0.07369502  0.11022837\n",
      "   0.00970277  0.03616669 -0.05938105 -0.06215665  0.02116021 -0.15244035\n",
      "  -0.01770749 -0.01612439 -0.04938776  0.0445581 ]\n",
      " [ 0.00267238 -0.02767996 -0.0260169  -0.01179068  0.04891104  0.01441581\n",
      "  -0.1150207  -0.03564028 -0.01993733 -0.00834985  0.02809402  0.09163248\n",
      "   0.00522764  0.01223224 -0.04748968 -0.01641501 -0.04400187 -0.06146921\n",
      "   0.02855793  0.08305258  0.02920081 -0.06245852 -0.07292063 -0.03164257\n",
      "   0.00411283  0.0760323   0.00963495 -0.14270132 -0.00581491  0.01337341\n",
      "  -0.01713964  0.06077553 -0.01600062  0.05618319  0.00648087  0.07517429\n",
      "  -0.03471491 -0.10911105  0.12165361  0.12698147 -0.03007039 -0.06130242\n",
      "   0.15889963 -0.04681588 -0.05278892 -0.02067744 -0.02832109 -0.15264614\n",
      "   0.02358512  0.04196715 -0.00161371  0.03929942 -0.07267454  0.01390939\n",
      "   0.06064013  0.08031475 -0.02237298  0.03087287  0.07585874  0.05006228\n",
      "   0.06723797 -0.05424024  0.02313708 -0.05482635]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create input data\n",
    "X = np.random.randn(2, 10, 8)\n",
    "\n",
    "# The second example is of length 6 \n",
    "X[1,6,:] = 0\n",
    "X_lengths = [10, 6]\n",
    "\n",
    "# ============================\n",
    "# tf.nn.rnn_cell --> tf.contrib.rnn\n",
    "# cell = tf.contrib.rnn.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "# cell = tf.contrib.rnn.DropoutWrapper(cell=cell, output_keep_prob=0.5)\n",
    "# If before you were using: MultiRNNCell([LSTMCell(...)] * num_layers), change to: MultiRNNCell([LSTMCell(...) for _ in range(num_layers)]).\n",
    "# cell = tf.contrib.rnn.MultiRNNCell(cells=[cell] * 4, state_is_tuple=True)\n",
    "# cell = tf.contrib.rnn.MultiRNNCell([cell for _ in range(5)])\n",
    "\n",
    "# ============================\n",
    "cells=[]\n",
    "for _ in range(4):\n",
    "    \n",
    "    # 参数num_units: int, The number of units in the LSTM cell\n",
    "    cell = tf.contrib.rnn.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell=cell, output_keep_prob=0.5)\n",
    "    cells.append(cell)\n",
    "cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# is_training = True\n",
    "# NUM_LAYERS = 4\n",
    "\n",
    "# # cell = tf.contrib.rnn.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "# cell = tf.contrib.rnn.BasicLSTMCell(NUM_LAYERS)\n",
    "# if is_training:\n",
    "#     cell = tf.contrib.rnn.DropoutWrapper(cell=cell, output_keep_prob=0.5)\n",
    "\n",
    "# for _ in range(NUM_LAYERS):\n",
    "#     cells.append(cell)\n",
    "# cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "    \n",
    "        \n",
    "\n",
    "outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=X_lengths,\n",
    "    inputs=X)\n",
    "\n",
    "result = tf.contrib.learn.run_n(\n",
    "    {\"outputs\": outputs, \"last_states\": last_states},\n",
    "    n=1,\n",
    "    feed_dict=None)\n",
    "\n",
    "\n",
    "print(result[0][\"outputs\"].shape)\n",
    "print(result[0][\"outputs\"])\n",
    "assert result[0][\"outputs\"].shape == (2, 10, 64)\n",
    "\n",
    "# Outputs for the second example past past length 6 should be 0\n",
    "assert (result[0][\"outputs\"][1,7,:] == np.zeros(cell.output_size)).all()\n",
    "\n",
    "print(result[0][\"last_states\"][0].h.shape)\n",
    "print(result[0][\"last_states\"][0].h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
