{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate test data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3371e7048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30383114 -0.31524192]\n",
      " [-1.57902621  0.9132736 ]\n",
      " [ 2.01559853  0.92793037]\n",
      " ..., \n",
      " [-0.883716    0.27946108]\n",
      " [ 2.05923534  1.96412965]\n",
      " [-2.1460431   1.83034363]]\n",
      "[0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 0 1 0 1\n",
      " 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1\n",
      " 0]\n",
      "<zip object at 0x7fb3371c7ec8>\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "\n",
    "def generate_data(data_num, data_dim, show_data=True):\n",
    "    X, Y = make_classification(n_samples=data_num, n_features=data_dim, n_redundant=0, n_clusters_per_class=1,  n_classes=2)\n",
    "    \n",
    "    if show_data:\n",
    "        plt.scatter(X[:,0], X[:,1], marker=\"o\", c=Y)\n",
    "        plt.title(\"raw data\")\n",
    "        plt.xlabel(\"X[:,0]\")\n",
    "        plt.ylabel(\"X[:,1]\")\n",
    "        plt.show()\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def make_example(features, label):\n",
    "    ex = tf.train.Example(\n",
    "        features = tf.train.Features(\n",
    "            feature = {\n",
    "                \"data\": tf.train.Feature(float_list=tf.train.FloatList(value=features)),\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) # [label][][]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return ex\n",
    "\n",
    "def generate_tfrecords(data_num, data_dim, filename):\n",
    "    X, Y = generate_data(data_num, data_dim, False)\n",
    "    print(X)\n",
    "    print(Y)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    print(zip(X,Y))\n",
    "    for x, y in zip(X, Y):\n",
    "        ex = make_example(x, y)\n",
    "        writer.write(ex.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"generate test data\")\n",
    "    generate_tfrecords(1000, 2, \"lr.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.691648 and the accuracy is 0.656250\n",
      "the loss is 0.653416 and the accuracy is 0.781250\n",
      "the loss is 0.641456 and the accuracy is 0.750000\n",
      "the loss is 0.615398 and the accuracy is 0.843750\n",
      "the loss is 0.542150 and the accuracy is 0.968750\n",
      "the loss is 0.574484 and the accuracy is 0.750000\n",
      "the loss is 0.519985 and the accuracy is 0.875000\n",
      "the loss is 0.484887 and the accuracy is 0.875000\n",
      "the loss is 0.483290 and the accuracy is 0.843750\n",
      "the loss is 0.446350 and the accuracy is 0.875000\n",
      "the loss is 0.439576 and the accuracy is 0.875000\n",
      "the loss is 0.506826 and the accuracy is 0.812500\n",
      "the loss is 0.468004 and the accuracy is 0.843750\n",
      "the loss is 0.366150 and the accuracy is 0.937500\n",
      "the loss is 0.442967 and the accuracy is 0.843750\n",
      "the loss is 0.353247 and the accuracy is 0.906250\n",
      "the loss is 0.382719 and the accuracy is 0.843750\n",
      "the loss is 0.306281 and the accuracy is 0.968750\n",
      "the loss is 0.393161 and the accuracy is 0.812500\n",
      "the loss is 0.411221 and the accuracy is 0.812500\n",
      "the loss is 0.381868 and the accuracy is 0.781250\n",
      "the loss is 0.424070 and the accuracy is 0.875000\n",
      "the loss is 0.363355 and the accuracy is 0.937500\n",
      "the loss is 0.327563 and the accuracy is 0.968750\n",
      "the loss is 0.323781 and the accuracy is 0.968750\n",
      "the loss is 0.400507 and the accuracy is 0.843750\n",
      "the loss is 0.452175 and the accuracy is 0.781250\n",
      "the loss is 0.273065 and the accuracy is 0.937500\n",
      "the loss is 0.523969 and the accuracy is 0.781250\n",
      "the loss is 0.366635 and the accuracy is 0.812500\n",
      "the loss is 0.305745 and the accuracy is 0.906250\n",
      "the loss is 0.262190 and the accuracy is 0.968750\n",
      "the loss is 0.384582 and the accuracy is 0.906250\n",
      "the loss is 0.337455 and the accuracy is 0.875000\n",
      "the loss is 0.363663 and the accuracy is 0.843750\n",
      "the loss is 0.409119 and the accuracy is 0.750000\n",
      "the loss is 0.372124 and the accuracy is 0.843750\n",
      "the loss is 0.327001 and the accuracy is 0.937500\n",
      "the loss is 0.342484 and the accuracy is 0.843750\n",
      "the loss is 0.343530 and the accuracy is 0.875000\n",
      "the loss is 0.232656 and the accuracy is 0.937500\n",
      "the loss is 0.301769 and the accuracy is 0.875000\n",
      "the loss is 0.216250 and the accuracy is 0.937500\n",
      "the loss is 0.307309 and the accuracy is 0.875000\n",
      "the loss is 0.347077 and the accuracy is 0.875000\n",
      "the loss is 0.308833 and the accuracy is 0.875000\n",
      "the loss is 0.219298 and the accuracy is 0.968750\n",
      "the loss is 0.391868 and the accuracy is 0.843750\n",
      "the loss is 0.222855 and the accuracy is 0.968750\n",
      "the loss is 0.319972 and the accuracy is 0.843750\n",
      "the loss is 0.229904 and the accuracy is 0.937500\n",
      "the loss is 0.231003 and the accuracy is 0.906250\n",
      "the loss is 0.257827 and the accuracy is 0.906250\n",
      "the loss is 0.435427 and the accuracy is 0.781250\n",
      "the loss is 0.369592 and the accuracy is 0.906250\n",
      "the loss is 0.446310 and the accuracy is 0.843750\n",
      "the loss is 0.352719 and the accuracy is 0.843750\n",
      "the loss is 0.231552 and the accuracy is 0.937500\n",
      "the loss is 0.344351 and the accuracy is 0.843750\n",
      "the loss is 0.292923 and the accuracy is 0.937500\n",
      "the loss is 0.383598 and the accuracy is 0.781250\n",
      "the loss is 0.398339 and the accuracy is 0.781250\n",
      "the loss is 0.324412 and the accuracy is 0.906250\n",
      "the loss is 0.337314 and the accuracy is 0.875000\n",
      "the loss is 0.404095 and the accuracy is 0.781250\n",
      "the loss is 0.362592 and the accuracy is 0.843750\n",
      "the loss is 0.349390 and the accuracy is 0.812500\n",
      "the loss is 0.257834 and the accuracy is 0.937500\n",
      "the loss is 0.296975 and the accuracy is 0.937500\n",
      "the loss is 0.322142 and the accuracy is 0.843750\n",
      "the loss is 0.346762 and the accuracy is 0.843750\n",
      "the loss is 0.310692 and the accuracy is 0.875000\n",
      "the loss is 0.266103 and the accuracy is 0.906250\n",
      "the loss is 0.365096 and the accuracy is 0.812500\n",
      "the loss is 0.270689 and the accuracy is 0.937500\n",
      "the loss is 0.319826 and the accuracy is 0.812500\n",
      "the loss is 0.263064 and the accuracy is 0.906250\n",
      "the loss is 0.280435 and the accuracy is 0.875000\n",
      "the loss is 0.219005 and the accuracy is 0.906250\n",
      "the loss is 0.311088 and the accuracy is 0.843750\n",
      "the loss is 0.186874 and the accuracy is 0.968750\n",
      "the loss is 0.273083 and the accuracy is 0.906250\n",
      "the loss is 0.168236 and the accuracy is 0.968750\n",
      "the loss is 0.293289 and the accuracy is 0.906250\n",
      "the loss is 0.366977 and the accuracy is 0.906250\n",
      "the loss is 0.348281 and the accuracy is 0.812500\n",
      "the loss is 0.287489 and the accuracy is 0.843750\n",
      "the loss is 0.289421 and the accuracy is 0.843750\n",
      "the loss is 0.429184 and the accuracy is 0.843750\n",
      "the loss is 0.261702 and the accuracy is 0.875000\n",
      "the loss is 0.290365 and the accuracy is 0.937500\n",
      "the loss is 0.187548 and the accuracy is 1.000000\n",
      "the loss is 0.261620 and the accuracy is 0.906250\n",
      "the loss is 0.337483 and the accuracy is 0.843750\n",
      "the loss is 0.326511 and the accuracy is 0.843750\n",
      "the loss is 0.394445 and the accuracy is 0.812500\n",
      "the loss is 0.336679 and the accuracy is 0.875000\n",
      "the loss is 0.363707 and the accuracy is 0.843750\n",
      "the loss is 0.465769 and the accuracy is 0.750000\n",
      "the loss is 0.359186 and the accuracy is 0.781250\n",
      "the loss is 0.519065 and the accuracy is 0.781250\n",
      "the loss is 0.192088 and the accuracy is 0.968750\n",
      "the loss is 0.143575 and the accuracy is 0.968750\n",
      "the loss is 0.219239 and the accuracy is 0.937500\n",
      "the loss is 0.248671 and the accuracy is 0.937500\n",
      "the loss is 0.423635 and the accuracy is 0.812500\n",
      "the loss is 0.201936 and the accuracy is 0.968750\n",
      "the loss is 0.232398 and the accuracy is 0.875000\n",
      "the loss is 0.500258 and the accuracy is 0.812500\n",
      "the loss is 0.189326 and the accuracy is 0.937500\n",
      "the loss is 0.201674 and the accuracy is 0.937500\n",
      "the loss is 0.348432 and the accuracy is 0.781250\n",
      "the loss is 0.415925 and the accuracy is 0.781250\n",
      "the loss is 0.302733 and the accuracy is 0.843750\n",
      "the loss is 0.250764 and the accuracy is 0.937500\n",
      "the loss is 0.133592 and the accuracy is 1.000000\n",
      "the loss is 0.300301 and the accuracy is 0.906250\n",
      "the loss is 0.277244 and the accuracy is 0.875000\n",
      "the loss is 0.209935 and the accuracy is 0.937500\n",
      "the loss is 0.370236 and the accuracy is 0.843750\n",
      "the loss is 0.322502 and the accuracy is 0.906250\n",
      "the loss is 0.182196 and the accuracy is 0.906250\n",
      "the loss is 0.168348 and the accuracy is 0.937500\n",
      "the loss is 0.261944 and the accuracy is 0.906250\n",
      "the loss is 0.333611 and the accuracy is 0.875000\n",
      "the loss is 0.206736 and the accuracy is 0.937500\n",
      "the loss is 0.294381 and the accuracy is 0.906250\n",
      "the loss is 0.296791 and the accuracy is 0.843750\n",
      "the loss is 0.192350 and the accuracy is 0.937500\n",
      "the loss is 0.588031 and the accuracy is 0.718750\n",
      "the loss is 0.280956 and the accuracy is 0.906250\n",
      "the loss is 0.216396 and the accuracy is 0.906250\n",
      "the loss is 0.306509 and the accuracy is 0.843750\n",
      "the loss is 0.396181 and the accuracy is 0.812500\n",
      "the loss is 0.456098 and the accuracy is 0.812500\n",
      "the loss is 0.163141 and the accuracy is 0.968750\n",
      "the loss is 0.191723 and the accuracy is 0.968750\n",
      "the loss is 0.289104 and the accuracy is 0.906250\n",
      "the loss is 0.323769 and the accuracy is 0.843750\n",
      "the loss is 0.358693 and the accuracy is 0.781250\n",
      "the loss is 0.239885 and the accuracy is 0.937500\n",
      "the loss is 0.250318 and the accuracy is 0.875000\n",
      "the loss is 0.343206 and the accuracy is 0.781250\n",
      "the loss is 0.413301 and the accuracy is 0.812500\n",
      "the loss is 0.193104 and the accuracy is 0.937500\n",
      "the loss is 0.198392 and the accuracy is 0.906250\n",
      "the loss is 0.198111 and the accuracy is 0.937500\n",
      "the loss is 0.229670 and the accuracy is 0.875000\n",
      "the loss is 0.443011 and the accuracy is 0.843750\n",
      "the loss is 0.282862 and the accuracy is 0.906250\n",
      "the loss is 0.248549 and the accuracy is 0.906250\n",
      "the loss is 0.291885 and the accuracy is 0.875000\n",
      "the loss is 0.444672 and the accuracy is 0.781250\n",
      "the loss is 0.345782 and the accuracy is 0.812500\n",
      "the loss is 0.269654 and the accuracy is 0.843750\n",
      "the loss is 0.364302 and the accuracy is 0.875000\n",
      "the loss is 0.224571 and the accuracy is 0.937500\n",
      "the loss is 0.183062 and the accuracy is 0.906250\n",
      "the loss is 0.273424 and the accuracy is 0.906250\n",
      "the loss is 0.118621 and the accuracy is 1.000000\n",
      "the loss is 0.229635 and the accuracy is 0.968750\n",
      "the loss is 0.320891 and the accuracy is 0.812500\n",
      "the loss is 0.430916 and the accuracy is 0.781250\n",
      "the loss is 0.268038 and the accuracy is 0.906250\n",
      "the loss is 0.278270 and the accuracy is 0.875000\n",
      "the loss is 0.246884 and the accuracy is 0.843750\n",
      "the loss is 0.187515 and the accuracy is 0.906250\n",
      "the loss is 0.306925 and the accuracy is 0.843750\n",
      "the loss is 0.409426 and the accuracy is 0.750000\n",
      "the loss is 0.226747 and the accuracy is 0.937500\n",
      "the loss is 0.417431 and the accuracy is 0.750000\n",
      "the loss is 0.244357 and the accuracy is 0.906250\n",
      "the loss is 0.267582 and the accuracy is 0.843750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.440314 and the accuracy is 0.812500\n",
      "the loss is 0.529499 and the accuracy is 0.812500\n",
      "the loss is 0.200663 and the accuracy is 0.937500\n",
      "the loss is 0.236639 and the accuracy is 0.843750\n",
      "the loss is 0.515836 and the accuracy is 0.781250\n",
      "the loss is 0.243068 and the accuracy is 0.906250\n",
      "the loss is 0.590590 and the accuracy is 0.781250\n",
      "the loss is 0.277245 and the accuracy is 0.843750\n",
      "the loss is 0.273743 and the accuracy is 0.875000\n",
      "the loss is 0.219813 and the accuracy is 0.906250\n",
      "the loss is 0.243256 and the accuracy is 0.937500\n",
      "the loss is 0.345528 and the accuracy is 0.781250\n",
      "the loss is 0.297661 and the accuracy is 0.875000\n",
      "the loss is 0.258039 and the accuracy is 0.875000\n",
      "the loss is 0.326117 and the accuracy is 0.875000\n",
      "the loss is 0.437819 and the accuracy is 0.812500\n",
      "the loss is 0.214047 and the accuracy is 0.937500\n",
      "the loss is 0.260525 and the accuracy is 0.906250\n",
      "the loss is 0.213701 and the accuracy is 0.906250\n",
      "the loss is 0.463999 and the accuracy is 0.750000\n",
      "the loss is 0.388805 and the accuracy is 0.843750\n",
      "the loss is 0.249795 and the accuracy is 0.906250\n",
      "the loss is 0.340620 and the accuracy is 0.781250\n",
      "the loss is 0.293773 and the accuracy is 0.937500\n",
      "the loss is 0.215731 and the accuracy is 0.937500\n",
      "the loss is 0.212143 and the accuracy is 0.968750\n",
      "the loss is 0.369476 and the accuracy is 0.843750\n",
      "the loss is 0.240883 and the accuracy is 0.875000\n",
      "the loss is 0.219777 and the accuracy is 0.906250\n",
      "the loss is 0.346787 and the accuracy is 0.875000\n",
      "the loss is 0.324871 and the accuracy is 0.875000\n",
      "the loss is 0.475068 and the accuracy is 0.812500\n",
      "the loss is 0.402308 and the accuracy is 0.843750\n",
      "the loss is 0.516312 and the accuracy is 0.718750\n",
      "the loss is 0.403947 and the accuracy is 0.812500\n",
      "the loss is 0.331806 and the accuracy is 0.875000\n",
      "the loss is 0.210884 and the accuracy is 0.875000\n",
      "the loss is 0.222529 and the accuracy is 0.906250\n",
      "the loss is 0.379059 and the accuracy is 0.812500\n",
      "the loss is 0.177594 and the accuracy is 0.937500\n",
      "the loss is 0.187310 and the accuracy is 0.937500\n",
      "the loss is 0.179700 and the accuracy is 0.937500\n",
      "the loss is 0.435251 and the accuracy is 0.843750\n",
      "the loss is 0.381994 and the accuracy is 0.812500\n",
      "the loss is 0.295750 and the accuracy is 0.812500\n",
      "the loss is 0.425798 and the accuracy is 0.812500\n",
      "the loss is 0.296048 and the accuracy is 0.812500\n",
      "the loss is 0.454006 and the accuracy is 0.843750\n",
      "the loss is 0.403201 and the accuracy is 0.843750\n",
      "the loss is 0.237317 and the accuracy is 0.906250\n",
      "the loss is 0.259151 and the accuracy is 0.875000\n",
      "the loss is 0.310658 and the accuracy is 0.875000\n",
      "the loss is 0.380462 and the accuracy is 0.781250\n",
      "the loss is 0.491858 and the accuracy is 0.781250\n",
      "the loss is 0.400298 and the accuracy is 0.812500\n",
      "the loss is 0.213285 and the accuracy is 0.906250\n",
      "the loss is 0.146181 and the accuracy is 0.937500\n",
      "the loss is 0.289794 and the accuracy is 0.875000\n",
      "the loss is 0.226970 and the accuracy is 0.937500\n",
      "the loss is 0.281515 and the accuracy is 0.875000\n",
      "the loss is 0.343688 and the accuracy is 0.875000\n",
      "the loss is 0.461559 and the accuracy is 0.781250\n",
      "the loss is 0.406080 and the accuracy is 0.843750\n",
      "the loss is 0.332929 and the accuracy is 0.781250\n",
      "the loss is 0.184581 and the accuracy is 0.937500\n",
      "the loss is 0.233881 and the accuracy is 0.875000\n",
      "the loss is 0.278778 and the accuracy is 0.906250\n",
      "the loss is 0.256125 and the accuracy is 0.875000\n",
      "the loss is 0.282832 and the accuracy is 0.937500\n",
      "the loss is 0.226801 and the accuracy is 0.937500\n",
      "the loss is 0.311189 and the accuracy is 0.843750\n",
      "the loss is 0.472039 and the accuracy is 0.781250\n",
      "the loss is 0.251893 and the accuracy is 0.875000\n",
      "the loss is 0.333460 and the accuracy is 0.937500\n",
      "the loss is 0.339816 and the accuracy is 0.843750\n",
      "the loss is 0.211046 and the accuracy is 0.906250\n",
      "the loss is 0.313610 and the accuracy is 0.906250\n",
      "the loss is 0.161814 and the accuracy is 0.968750\n",
      "the loss is 0.301118 and the accuracy is 0.843750\n",
      "the loss is 0.477780 and the accuracy is 0.781250\n",
      "the loss is 0.302644 and the accuracy is 0.875000\n",
      "the loss is 0.423634 and the accuracy is 0.781250\n",
      "the loss is 0.347116 and the accuracy is 0.875000\n",
      "the loss is 0.179801 and the accuracy is 0.937500\n",
      "the loss is 0.376500 and the accuracy is 0.875000\n",
      "the loss is 0.304276 and the accuracy is 0.843750\n",
      "the loss is 0.397198 and the accuracy is 0.843750\n",
      "the loss is 0.210960 and the accuracy is 0.937500\n",
      "the loss is 0.224102 and the accuracy is 0.906250\n",
      "the loss is 0.257333 and the accuracy is 0.906250\n",
      "the loss is 0.285360 and the accuracy is 0.812500\n",
      "the loss is 0.521103 and the accuracy is 0.718750\n",
      "the loss is 0.143577 and the accuracy is 0.937500\n",
      "the loss is 0.279416 and the accuracy is 0.875000\n",
      "the loss is 0.187860 and the accuracy is 0.937500\n",
      "the loss is 0.427928 and the accuracy is 0.843750\n",
      "the loss is 0.375646 and the accuracy is 0.875000\n",
      "the loss is 0.379348 and the accuracy is 0.781250\n",
      "the loss is 0.150476 and the accuracy is 0.968750\n",
      "the loss is 0.337396 and the accuracy is 0.843750\n",
      "the loss is 0.226163 and the accuracy is 0.843750\n",
      "the loss is 0.240139 and the accuracy is 0.906250\n",
      "the loss is 0.213915 and the accuracy is 0.937500\n",
      "the loss is 0.312485 and the accuracy is 0.875000\n",
      "the loss is 0.380344 and the accuracy is 0.843750\n",
      "the loss is 0.165938 and the accuracy is 0.968750\n",
      "the loss is 0.185408 and the accuracy is 0.968750\n",
      "the loss is 0.226602 and the accuracy is 0.875000\n",
      "the loss is 0.254899 and the accuracy is 0.843750\n",
      "the loss is 0.360816 and the accuracy is 0.843750\n",
      "the loss is 0.465570 and the accuracy is 0.750000\n",
      "the loss is 0.371479 and the accuracy is 0.906250\n",
      "the loss is 0.187838 and the accuracy is 0.968750\n",
      "the loss is 0.338920 and the accuracy is 0.875000\n",
      "the loss is 0.178336 and the accuracy is 0.937500\n",
      "the loss is 0.285840 and the accuracy is 0.875000\n",
      "the loss is 0.228931 and the accuracy is 0.843750\n",
      "the loss is 0.264249 and the accuracy is 0.875000\n",
      "the loss is 0.374897 and the accuracy is 0.843750\n",
      "the loss is 0.339256 and the accuracy is 0.812500\n",
      "the loss is 0.252047 and the accuracy is 0.875000\n",
      "the loss is 0.351112 and the accuracy is 0.875000\n",
      "the loss is 0.419532 and the accuracy is 0.781250\n",
      "the loss is 0.265600 and the accuracy is 0.843750\n",
      "the loss is 0.213332 and the accuracy is 0.906250\n",
      "the loss is 0.498582 and the accuracy is 0.781250\n",
      "the loss is 0.317188 and the accuracy is 0.812500\n",
      "the loss is 0.084382 and the accuracy is 1.000000\n",
      "the loss is 0.196918 and the accuracy is 0.937500\n",
      "the loss is 0.319800 and the accuracy is 0.875000\n",
      "the loss is 0.262625 and the accuracy is 0.906250\n",
      "the loss is 0.338173 and the accuracy is 0.875000\n",
      "the loss is 0.179679 and the accuracy is 0.937500\n",
      "the loss is 0.225690 and the accuracy is 0.843750\n",
      "the loss is 0.243762 and the accuracy is 0.906250\n",
      "the loss is 0.182877 and the accuracy is 0.968750\n",
      "the loss is 0.186764 and the accuracy is 0.937500\n",
      "the loss is 0.349578 and the accuracy is 0.906250\n",
      "the loss is 0.148265 and the accuracy is 0.968750\n",
      "the loss is 0.219850 and the accuracy is 0.875000\n",
      "the loss is 0.378812 and the accuracy is 0.781250\n",
      "the loss is 0.224243 and the accuracy is 0.937500\n",
      "the loss is 0.165399 and the accuracy is 0.906250\n",
      "the loss is 0.359188 and the accuracy is 0.843750\n",
      "the loss is 0.362306 and the accuracy is 0.843750\n",
      "the loss is 0.241058 and the accuracy is 0.906250\n",
      "the loss is 0.152137 and the accuracy is 0.968750\n",
      "the loss is 0.133169 and the accuracy is 1.000000\n",
      "the loss is 0.284404 and the accuracy is 0.906250\n",
      "the loss is 0.458696 and the accuracy is 0.781250\n",
      "the loss is 0.526771 and the accuracy is 0.718750\n",
      "the loss is 0.486764 and the accuracy is 0.718750\n",
      "the loss is 0.271874 and the accuracy is 0.843750\n",
      "the loss is 0.490788 and the accuracy is 0.750000\n",
      "the loss is 0.421623 and the accuracy is 0.781250\n",
      "the loss is 0.244326 and the accuracy is 0.875000\n",
      "the loss is 0.291030 and the accuracy is 0.906250\n",
      "the loss is 0.298729 and the accuracy is 0.812500\n",
      "the loss is 0.266170 and the accuracy is 0.906250\n",
      "the loss is 0.306143 and the accuracy is 0.875000\n",
      "the loss is 0.196389 and the accuracy is 0.875000\n",
      "the loss is 0.268287 and the accuracy is 0.937500\n",
      "the loss is 0.201608 and the accuracy is 0.937500\n",
      "the loss is 0.165647 and the accuracy is 0.937500\n",
      "the loss is 0.363781 and the accuracy is 0.812500\n",
      "the loss is 0.367515 and the accuracy is 0.875000\n",
      "the loss is 0.319424 and the accuracy is 0.843750\n",
      "the loss is 0.213810 and the accuracy is 0.937500\n",
      "the loss is 0.231953 and the accuracy is 0.906250\n",
      "the loss is 0.494524 and the accuracy is 0.812500\n",
      "the loss is 0.452824 and the accuracy is 0.750000\n",
      "the loss is 0.283248 and the accuracy is 0.812500\n",
      "the loss is 0.353442 and the accuracy is 0.906250\n",
      "the loss is 0.423190 and the accuracy is 0.781250\n",
      "the loss is 0.232949 and the accuracy is 0.906250\n",
      "the loss is 0.556613 and the accuracy is 0.718750\n",
      "the loss is 0.274596 and the accuracy is 0.875000\n",
      "the loss is 0.422265 and the accuracy is 0.812500\n",
      "the loss is 0.335501 and the accuracy is 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.276959 and the accuracy is 0.875000\n",
      "the loss is 0.285421 and the accuracy is 0.906250\n",
      "the loss is 0.220286 and the accuracy is 0.937500\n",
      "the loss is 0.279614 and the accuracy is 0.906250\n",
      "the loss is 0.226419 and the accuracy is 0.937500\n",
      "the loss is 0.281242 and the accuracy is 0.875000\n",
      "the loss is 0.266015 and the accuracy is 0.843750\n",
      "the loss is 0.150005 and the accuracy is 0.968750\n",
      "the loss is 0.253462 and the accuracy is 0.875000\n",
      "the loss is 0.230704 and the accuracy is 0.937500\n",
      "the loss is 0.270180 and the accuracy is 0.875000\n",
      "the loss is 0.346762 and the accuracy is 0.875000\n",
      "the loss is 0.374101 and the accuracy is 0.812500\n",
      "the loss is 0.473536 and the accuracy is 0.812500\n",
      "the loss is 0.343936 and the accuracy is 0.875000\n",
      "the loss is 0.307993 and the accuracy is 0.812500\n",
      "the loss is 0.293080 and the accuracy is 0.843750\n",
      "the loss is 0.458133 and the accuracy is 0.781250\n",
      "the loss is 0.222836 and the accuracy is 0.843750\n",
      "the loss is 0.330786 and the accuracy is 0.812500\n",
      "the loss is 0.164349 and the accuracy is 0.937500\n",
      "the loss is 0.133638 and the accuracy is 1.000000\n",
      "the loss is 0.274775 and the accuracy is 0.875000\n",
      "the loss is 0.331294 and the accuracy is 0.875000\n",
      "the loss is 0.148445 and the accuracy is 0.968750\n",
      "the loss is 0.305148 and the accuracy is 0.906250\n",
      "the loss is 0.368578 and the accuracy is 0.812500\n",
      "the loss is 0.389614 and the accuracy is 0.843750\n",
      "the loss is 0.199629 and the accuracy is 0.937500\n",
      "the loss is 0.255041 and the accuracy is 0.875000\n",
      "the loss is 0.304378 and the accuracy is 0.812500\n",
      "the loss is 0.186957 and the accuracy is 0.968750\n",
      "the loss is 0.232581 and the accuracy is 0.906250\n",
      "the loss is 0.427633 and the accuracy is 0.843750\n",
      "the loss is 0.327717 and the accuracy is 0.812500\n",
      "the loss is 0.377280 and the accuracy is 0.812500\n",
      "the loss is 0.388462 and the accuracy is 0.812500\n",
      "the loss is 0.228447 and the accuracy is 0.875000\n",
      "the loss is 0.231798 and the accuracy is 0.875000\n",
      "the loss is 0.332228 and the accuracy is 0.875000\n",
      "the loss is 0.210260 and the accuracy is 0.937500\n",
      "the loss is 0.314401 and the accuracy is 0.843750\n",
      "the loss is 0.193138 and the accuracy is 0.906250\n",
      "the loss is 0.154490 and the accuracy is 0.937500\n",
      "the loss is 0.192191 and the accuracy is 0.906250\n",
      "the loss is 0.237947 and the accuracy is 0.875000\n",
      "the loss is 0.264827 and the accuracy is 0.906250\n",
      "the loss is 0.273915 and the accuracy is 0.875000\n",
      "the loss is 0.406500 and the accuracy is 0.750000\n",
      "the loss is 0.336602 and the accuracy is 0.843750\n",
      "the loss is 0.265099 and the accuracy is 0.843750\n",
      "the loss is 0.240348 and the accuracy is 0.843750\n",
      "the loss is 0.182678 and the accuracy is 0.906250\n",
      "the loss is 0.220116 and the accuracy is 0.937500\n",
      "the loss is 0.497341 and the accuracy is 0.812500\n",
      "the loss is 0.275731 and the accuracy is 0.875000\n",
      "the loss is 0.323800 and the accuracy is 0.843750\n",
      "the loss is 0.243680 and the accuracy is 0.906250\n",
      "the loss is 0.193714 and the accuracy is 0.906250\n",
      "the loss is 0.318977 and the accuracy is 0.875000\n",
      "the loss is 0.295106 and the accuracy is 0.937500\n",
      "the loss is 0.122256 and the accuracy is 0.968750\n",
      "the loss is 0.315742 and the accuracy is 0.781250\n",
      "the loss is 0.226702 and the accuracy is 0.937500\n",
      "the loss is 0.506937 and the accuracy is 0.812500\n",
      "the loss is 0.169847 and the accuracy is 0.937500\n",
      "the loss is 0.425289 and the accuracy is 0.687500\n",
      "the loss is 0.248012 and the accuracy is 0.875000\n",
      "the loss is 0.404571 and the accuracy is 0.781250\n",
      "the loss is 0.372878 and the accuracy is 0.875000\n",
      "the loss is 0.473013 and the accuracy is 0.843750\n",
      "the loss is 0.576449 and the accuracy is 0.750000\n",
      "the loss is 0.281765 and the accuracy is 0.875000\n",
      "the loss is 0.289676 and the accuracy is 0.875000\n",
      "the loss is 0.314483 and the accuracy is 0.875000\n",
      "the loss is 0.167806 and the accuracy is 0.937500\n",
      "the loss is 0.243718 and the accuracy is 0.875000\n",
      "the loss is 0.344362 and the accuracy is 0.843750\n",
      "the loss is 0.210366 and the accuracy is 0.937500\n",
      "the loss is 0.543077 and the accuracy is 0.750000\n",
      "the loss is 0.365079 and the accuracy is 0.875000\n",
      "the loss is 0.323553 and the accuracy is 0.937500\n",
      "the loss is 0.314030 and the accuracy is 0.875000\n",
      "the loss is 0.290015 and the accuracy is 0.875000\n",
      "the loss is 0.200223 and the accuracy is 0.937500\n",
      "the loss is 0.276978 and the accuracy is 0.843750\n",
      "the loss is 0.232500 and the accuracy is 0.937500\n",
      "the loss is 0.352489 and the accuracy is 0.843750\n",
      "the loss is 0.357377 and the accuracy is 0.812500\n",
      "the loss is 0.345932 and the accuracy is 0.875000\n",
      "the loss is 0.268909 and the accuracy is 0.843750\n",
      "the loss is 0.200489 and the accuracy is 0.937500\n",
      "the loss is 0.314722 and the accuracy is 0.875000\n",
      "the loss is 0.164395 and the accuracy is 0.968750\n",
      "the loss is 0.214314 and the accuracy is 0.906250\n",
      "the loss is 0.489737 and the accuracy is 0.781250\n",
      "the loss is 0.314440 and the accuracy is 0.875000\n",
      "the loss is 0.431507 and the accuracy is 0.750000\n",
      "the loss is 0.389465 and the accuracy is 0.875000\n",
      "the loss is 0.262327 and the accuracy is 0.937500\n",
      "the loss is 0.150891 and the accuracy is 0.968750\n",
      "the loss is 0.354410 and the accuracy is 0.812500\n",
      "the loss is 0.173442 and the accuracy is 0.968750\n",
      "the loss is 0.195741 and the accuracy is 0.906250\n",
      "the loss is 0.243941 and the accuracy is 0.906250\n",
      "the loss is 0.221461 and the accuracy is 0.937500\n",
      "the loss is 0.128815 and the accuracy is 0.968750\n",
      "the loss is 0.314243 and the accuracy is 0.812500\n",
      "the loss is 0.170082 and the accuracy is 0.937500\n",
      "the loss is 0.266721 and the accuracy is 0.906250\n",
      "the loss is 0.333815 and the accuracy is 0.812500\n",
      "the loss is 0.332999 and the accuracy is 0.937500\n",
      "the loss is 0.178541 and the accuracy is 0.937500\n",
      "the loss is 0.291289 and the accuracy is 0.843750\n",
      "the loss is 0.313184 and the accuracy is 0.937500\n",
      "the loss is 0.243393 and the accuracy is 0.906250\n",
      "the loss is 0.186997 and the accuracy is 0.937500\n",
      "the loss is 0.253599 and the accuracy is 0.875000\n",
      "the loss is 0.220875 and the accuracy is 0.875000\n",
      "the loss is 0.370843 and the accuracy is 0.843750\n",
      "the loss is 0.297536 and the accuracy is 0.875000\n",
      "the loss is 0.374077 and the accuracy is 0.843750\n",
      "the loss is 0.430067 and the accuracy is 0.812500\n",
      "the loss is 0.494403 and the accuracy is 0.781250\n",
      "the loss is 0.183988 and the accuracy is 0.906250\n",
      "the loss is 0.138872 and the accuracy is 0.937500\n",
      "the loss is 0.263090 and the accuracy is 0.875000\n",
      "the loss is 0.176879 and the accuracy is 0.906250\n",
      "the loss is 0.170530 and the accuracy is 0.937500\n",
      "the loss is 0.246043 and the accuracy is 0.906250\n",
      "the loss is 0.290124 and the accuracy is 0.875000\n",
      "the loss is 0.396478 and the accuracy is 0.781250\n",
      "the loss is 0.363341 and the accuracy is 0.781250\n",
      "the loss is 0.293829 and the accuracy is 0.843750\n",
      "the loss is 0.396115 and the accuracy is 0.781250\n",
      "the loss is 0.248706 and the accuracy is 0.906250\n",
      "the loss is 0.337177 and the accuracy is 0.843750\n",
      "the loss is 0.396837 and the accuracy is 0.781250\n",
      "the loss is 0.354555 and the accuracy is 0.875000\n",
      "the loss is 0.402182 and the accuracy is 0.750000\n",
      "the loss is 0.639511 and the accuracy is 0.781250\n",
      "the loss is 0.376071 and the accuracy is 0.843750\n",
      "the loss is 0.253541 and the accuracy is 0.875000\n",
      "the loss is 0.345612 and the accuracy is 0.812500\n",
      "the loss is 0.298502 and the accuracy is 0.937500\n",
      "the loss is 0.147444 and the accuracy is 0.968750\n",
      "the loss is 0.300000 and the accuracy is 0.906250\n",
      "the loss is 0.272018 and the accuracy is 0.843750\n",
      "the loss is 0.225241 and the accuracy is 0.906250\n",
      "the loss is 0.186409 and the accuracy is 0.937500\n",
      "the loss is 0.271389 and the accuracy is 0.875000\n",
      "the loss is 0.431622 and the accuracy is 0.843750\n",
      "the loss is 0.269194 and the accuracy is 0.875000\n",
      "the loss is 0.207452 and the accuracy is 0.937500\n",
      "the loss is 0.215035 and the accuracy is 0.906250\n",
      "the loss is 0.401230 and the accuracy is 0.781250\n",
      "the loss is 0.146806 and the accuracy is 1.000000\n",
      "the loss is 0.391286 and the accuracy is 0.906250\n",
      "the loss is 0.321286 and the accuracy is 0.812500\n",
      "the loss is 0.197905 and the accuracy is 0.937500\n",
      "the loss is 0.224027 and the accuracy is 0.875000\n",
      "the loss is 0.167509 and the accuracy is 0.968750\n",
      "the loss is 0.234547 and the accuracy is 0.843750\n",
      "the loss is 0.267052 and the accuracy is 0.843750\n",
      "the loss is 0.449654 and the accuracy is 0.906250\n",
      "the loss is 0.330348 and the accuracy is 0.781250\n",
      "the loss is 0.538769 and the accuracy is 0.750000\n",
      "the loss is 0.300591 and the accuracy is 0.875000\n",
      "the loss is 0.331645 and the accuracy is 0.812500\n",
      "the loss is 0.231153 and the accuracy is 0.843750\n",
      "the loss is 0.176782 and the accuracy is 0.937500\n",
      "the loss is 0.387265 and the accuracy is 0.843750\n",
      "the loss is 0.344758 and the accuracy is 0.843750\n",
      "the loss is 0.100641 and the accuracy is 0.968750\n",
      "the loss is 0.203113 and the accuracy is 0.906250\n",
      "the loss is 0.131462 and the accuracy is 0.968750\n",
      "the loss is 0.291752 and the accuracy is 0.875000\n",
      "the loss is 0.253665 and the accuracy is 0.875000\n",
      "the loss is 0.301890 and the accuracy is 0.906250\n",
      "the loss is 0.225452 and the accuracy is 0.937500\n",
      "the loss is 0.181454 and the accuracy is 0.968750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.296870 and the accuracy is 0.843750\n",
      "the loss is 0.419622 and the accuracy is 0.781250\n",
      "the loss is 0.294710 and the accuracy is 0.875000\n",
      "the loss is 0.438719 and the accuracy is 0.843750\n",
      "the loss is 0.245743 and the accuracy is 0.875000\n",
      "the loss is 0.288087 and the accuracy is 0.875000\n",
      "the loss is 0.213283 and the accuracy is 0.906250\n",
      "the loss is 0.518420 and the accuracy is 0.750000\n",
      "the loss is 0.291478 and the accuracy is 0.875000\n",
      "the loss is 0.436139 and the accuracy is 0.812500\n",
      "the loss is 0.164810 and the accuracy is 0.906250\n",
      "the loss is 0.365922 and the accuracy is 0.843750\n",
      "the loss is 0.396884 and the accuracy is 0.750000\n",
      "the loss is 0.296020 and the accuracy is 0.781250\n",
      "the loss is 0.337001 and the accuracy is 0.812500\n",
      "the loss is 0.095298 and the accuracy is 0.968750\n",
      "the loss is 0.323680 and the accuracy is 0.937500\n",
      "the loss is 0.323872 and the accuracy is 0.875000\n",
      "the loss is 0.394686 and the accuracy is 0.812500\n",
      "the loss is 0.300665 and the accuracy is 0.937500\n",
      "the loss is 0.224138 and the accuracy is 0.906250\n",
      "the loss is 0.171330 and the accuracy is 0.937500\n",
      "the loss is 0.359684 and the accuracy is 0.843750\n",
      "the loss is 0.453783 and the accuracy is 0.750000\n",
      "the loss is 0.180961 and the accuracy is 0.906250\n",
      "the loss is 0.199920 and the accuracy is 0.968750\n",
      "the loss is 0.338587 and the accuracy is 0.906250\n",
      "the loss is 0.290471 and the accuracy is 0.812500\n",
      "the loss is 0.473559 and the accuracy is 0.843750\n",
      "the loss is 0.334912 and the accuracy is 0.875000\n",
      "the loss is 0.192919 and the accuracy is 0.875000\n",
      "the loss is 0.244489 and the accuracy is 0.875000\n",
      "the loss is 0.196946 and the accuracy is 0.875000\n",
      "the loss is 0.213909 and the accuracy is 0.875000\n",
      "the loss is 0.170923 and the accuracy is 0.937500\n",
      "the loss is 0.336638 and the accuracy is 0.812500\n",
      "the loss is 0.442353 and the accuracy is 0.843750\n",
      "the loss is 0.394788 and the accuracy is 0.812500\n",
      "the loss is 0.187305 and the accuracy is 0.906250\n",
      "the loss is 0.401809 and the accuracy is 0.843750\n",
      "the loss is 0.236456 and the accuracy is 0.875000\n",
      "the loss is 0.240163 and the accuracy is 0.906250\n",
      "the loss is 0.262694 and the accuracy is 0.906250\n",
      "the loss is 0.205070 and the accuracy is 0.906250\n",
      "the loss is 0.198676 and the accuracy is 0.937500\n",
      "the loss is 0.532292 and the accuracy is 0.812500\n",
      "the loss is 0.270832 and the accuracy is 0.906250\n",
      "the loss is 0.254409 and the accuracy is 0.906250\n",
      "the loss is 0.411723 and the accuracy is 0.843750\n",
      "the loss is 0.141145 and the accuracy is 0.968750\n",
      "the loss is 0.348651 and the accuracy is 0.906250\n",
      "the loss is 0.507825 and the accuracy is 0.781250\n",
      "the loss is 0.436140 and the accuracy is 0.781250\n",
      "the loss is 0.323614 and the accuracy is 0.781250\n",
      "the loss is 0.246436 and the accuracy is 0.906250\n",
      "the loss is 0.360304 and the accuracy is 0.843750\n",
      "the loss is 0.367738 and the accuracy is 0.843750\n",
      "the loss is 0.277688 and the accuracy is 0.875000\n",
      "the loss is 0.522651 and the accuracy is 0.750000\n",
      "the loss is 0.344838 and the accuracy is 0.812500\n",
      "the loss is 0.319718 and the accuracy is 0.812500\n",
      "the loss is 0.218266 and the accuracy is 0.937500\n",
      "the loss is 0.273974 and the accuracy is 0.812500\n",
      "the loss is 0.238697 and the accuracy is 0.906250\n",
      "the loss is 0.315029 and the accuracy is 0.843750\n",
      "the loss is 0.312955 and the accuracy is 0.843750\n",
      "the loss is 0.147860 and the accuracy is 0.968750\n",
      "the loss is 0.225078 and the accuracy is 0.906250\n",
      "the loss is 0.247054 and the accuracy is 0.875000\n",
      "the loss is 0.207385 and the accuracy is 0.875000\n",
      "the loss is 0.475057 and the accuracy is 0.781250\n",
      "the loss is 0.248496 and the accuracy is 0.875000\n",
      "the loss is 0.470185 and the accuracy is 0.781250\n",
      "the loss is 0.287216 and the accuracy is 0.812500\n",
      "the loss is 0.302660 and the accuracy is 0.906250\n",
      "the loss is 0.378265 and the accuracy is 0.781250\n",
      "the loss is 0.272567 and the accuracy is 0.906250\n",
      "the loss is 0.179266 and the accuracy is 0.906250\n",
      "the loss is 0.369853 and the accuracy is 0.875000\n",
      "the loss is 0.316780 and the accuracy is 0.843750\n",
      "the loss is 0.239973 and the accuracy is 0.875000\n",
      "the loss is 0.442508 and the accuracy is 0.750000\n",
      "the loss is 0.351716 and the accuracy is 0.812500\n",
      "the loss is 0.279007 and the accuracy is 0.843750\n",
      "the loss is 0.315834 and the accuracy is 0.812500\n",
      "the loss is 0.307665 and the accuracy is 0.937500\n",
      "the loss is 0.255099 and the accuracy is 0.906250\n",
      "the loss is 0.278944 and the accuracy is 0.812500\n",
      "the loss is 0.403845 and the accuracy is 0.812500\n",
      "the loss is 0.157783 and the accuracy is 0.968750\n",
      "the loss is 0.339145 and the accuracy is 0.906250\n",
      "the loss is 0.383622 and the accuracy is 0.843750\n",
      "the loss is 0.175551 and the accuracy is 0.937500\n",
      "the loss is 0.378513 and the accuracy is 0.781250\n",
      "the loss is 0.289565 and the accuracy is 0.875000\n",
      "the loss is 0.284581 and the accuracy is 0.843750\n",
      "the loss is 0.501884 and the accuracy is 0.875000\n",
      "the loss is 0.315992 and the accuracy is 0.812500\n",
      "the loss is 0.151978 and the accuracy is 0.968750\n",
      "the loss is 0.248080 and the accuracy is 0.906250\n",
      "the loss is 0.328530 and the accuracy is 0.906250\n",
      "the loss is 0.275440 and the accuracy is 0.843750\n",
      "the loss is 0.541762 and the accuracy is 0.781250\n",
      "the loss is 0.266264 and the accuracy is 0.906250\n",
      "the loss is 0.335813 and the accuracy is 0.906250\n",
      "the loss is 0.188258 and the accuracy is 0.906250\n",
      "the loss is 0.147432 and the accuracy is 0.906250\n",
      "the loss is 0.222976 and the accuracy is 0.906250\n",
      "the loss is 0.180246 and the accuracy is 0.968750\n",
      "the loss is 0.265422 and the accuracy is 0.812500\n",
      "the loss is 0.284812 and the accuracy is 0.843750\n",
      "the loss is 0.327233 and the accuracy is 0.875000\n",
      "the loss is 0.180901 and the accuracy is 0.968750\n",
      "the loss is 0.308773 and the accuracy is 0.843750\n",
      "the loss is 0.313774 and the accuracy is 0.906250\n",
      "the loss is 0.204116 and the accuracy is 0.937500\n",
      "the loss is 0.211265 and the accuracy is 0.906250\n",
      "the loss is 0.461280 and the accuracy is 0.750000\n",
      "the loss is 0.297123 and the accuracy is 0.812500\n",
      "the loss is 0.391832 and the accuracy is 0.781250\n",
      "the loss is 0.230398 and the accuracy is 0.906250\n",
      "the loss is 0.584572 and the accuracy is 0.687500\n",
      "the loss is 0.235780 and the accuracy is 0.906250\n",
      "the loss is 0.345987 and the accuracy is 0.843750\n",
      "the loss is 0.184832 and the accuracy is 0.906250\n",
      "the loss is 0.138906 and the accuracy is 1.000000\n",
      "the loss is 0.326840 and the accuracy is 0.875000\n",
      "the loss is 0.112511 and the accuracy is 0.968750\n",
      "the loss is 0.451050 and the accuracy is 0.781250\n",
      "the loss is 0.220041 and the accuracy is 0.875000\n",
      "the loss is 0.234853 and the accuracy is 0.937500\n",
      "the loss is 0.198225 and the accuracy is 0.906250\n",
      "the loss is 0.306901 and the accuracy is 0.781250\n",
      "the loss is 0.133276 and the accuracy is 0.937500\n",
      "the loss is 0.232550 and the accuracy is 0.906250\n",
      "the loss is 0.505213 and the accuracy is 0.781250\n",
      "the loss is 0.490758 and the accuracy is 0.750000\n",
      "the loss is 0.174590 and the accuracy is 0.937500\n",
      "the loss is 0.266310 and the accuracy is 0.875000\n",
      "the loss is 0.190701 and the accuracy is 0.937500\n",
      "the loss is 0.227088 and the accuracy is 0.937500\n",
      "the loss is 0.257930 and the accuracy is 0.906250\n",
      "the loss is 0.319016 and the accuracy is 0.875000\n",
      "the loss is 0.405695 and the accuracy is 0.843750\n",
      "the loss is 0.370537 and the accuracy is 0.781250\n",
      "the loss is 0.205020 and the accuracy is 0.875000\n",
      "the loss is 0.243062 and the accuracy is 0.906250\n",
      "the loss is 0.301231 and the accuracy is 0.843750\n",
      "the loss is 0.221309 and the accuracy is 0.906250\n",
      "the loss is 0.467898 and the accuracy is 0.718750\n",
      "the loss is 0.244778 and the accuracy is 0.968750\n",
      "the loss is 0.459423 and the accuracy is 0.843750\n",
      "the loss is 0.229759 and the accuracy is 0.875000\n",
      "the loss is 0.283802 and the accuracy is 0.812500\n",
      "the loss is 0.529317 and the accuracy is 0.781250\n",
      "the loss is 0.312467 and the accuracy is 0.937500\n",
      "the loss is 0.246692 and the accuracy is 0.906250\n",
      "the loss is 0.189891 and the accuracy is 0.937500\n",
      "the loss is 0.233918 and the accuracy is 0.875000\n",
      "the loss is 0.164802 and the accuracy is 0.968750\n",
      "the loss is 0.208087 and the accuracy is 0.937500\n",
      "the loss is 0.177635 and the accuracy is 0.937500\n",
      "the loss is 0.307847 and the accuracy is 0.875000\n",
      "the loss is 0.285067 and the accuracy is 0.843750\n",
      "the loss is 0.268049 and the accuracy is 0.812500\n",
      "the loss is 0.235130 and the accuracy is 0.937500\n",
      "the loss is 0.310696 and the accuracy is 0.875000\n",
      "the loss is 0.286895 and the accuracy is 0.812500\n",
      "the loss is 0.221716 and the accuracy is 0.906250\n",
      "the loss is 0.306915 and the accuracy is 0.906250\n",
      "the loss is 0.285655 and the accuracy is 0.906250\n",
      "the loss is 0.114447 and the accuracy is 0.968750\n",
      "the loss is 0.260729 and the accuracy is 0.875000\n",
      "the loss is 0.306932 and the accuracy is 0.875000\n",
      "the loss is 0.206851 and the accuracy is 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.424491 and the accuracy is 0.781250\n",
      "the loss is 0.248397 and the accuracy is 0.906250\n",
      "the loss is 0.168414 and the accuracy is 0.906250\n",
      "the loss is 0.362028 and the accuracy is 0.781250\n",
      "the loss is 0.200113 and the accuracy is 0.906250\n",
      "the loss is 0.173073 and the accuracy is 0.937500\n",
      "the loss is 0.252939 and the accuracy is 0.968750\n",
      "the loss is 0.303917 and the accuracy is 0.843750\n",
      "the loss is 0.363710 and the accuracy is 0.875000\n",
      "the loss is 0.264256 and the accuracy is 0.875000\n",
      "the loss is 0.298914 and the accuracy is 0.875000\n",
      "the loss is 0.309204 and the accuracy is 0.906250\n",
      "the loss is 0.203727 and the accuracy is 0.906250\n",
      "the loss is 0.526046 and the accuracy is 0.750000\n",
      "the loss is 0.351900 and the accuracy is 0.812500\n",
      "the loss is 0.301121 and the accuracy is 0.875000\n",
      "the loss is 0.183260 and the accuracy is 0.937500\n",
      "the loss is 0.306491 and the accuracy is 0.875000\n",
      "the loss is 0.180960 and the accuracy is 0.906250\n",
      "the loss is 0.345950 and the accuracy is 0.843750\n",
      "the loss is 0.342706 and the accuracy is 0.812500\n",
      "the loss is 0.348899 and the accuracy is 0.875000\n",
      "the loss is 0.487846 and the accuracy is 0.812500\n",
      "the loss is 0.347247 and the accuracy is 0.906250\n",
      "the loss is 0.183641 and the accuracy is 0.968750\n",
      "the loss is 0.187944 and the accuracy is 0.937500\n",
      "the loss is 0.207729 and the accuracy is 0.937500\n",
      "the loss is 0.286823 and the accuracy is 0.906250\n",
      "the loss is 0.448754 and the accuracy is 0.843750\n",
      "the loss is 0.296232 and the accuracy is 0.875000\n",
      "the loss is 0.269459 and the accuracy is 0.812500\n",
      "the loss is 0.328249 and the accuracy is 0.875000\n",
      "the loss is 0.501655 and the accuracy is 0.781250\n",
      "the loss is 0.257852 and the accuracy is 0.906250\n",
      "the loss is 0.451115 and the accuracy is 0.781250\n",
      "the loss is 0.408375 and the accuracy is 0.812500\n",
      "the loss is 0.250250 and the accuracy is 0.906250\n",
      "the loss is 0.334644 and the accuracy is 0.875000\n",
      "the loss is 0.199906 and the accuracy is 0.906250\n",
      "the loss is 0.301203 and the accuracy is 0.875000\n",
      "the loss is 0.180278 and the accuracy is 0.937500\n",
      "the loss is 0.315364 and the accuracy is 0.906250\n",
      "the loss is 0.436625 and the accuracy is 0.843750\n",
      "the loss is 0.248810 and the accuracy is 0.875000\n",
      "the loss is 0.389204 and the accuracy is 0.843750\n",
      "the loss is 0.178562 and the accuracy is 0.968750\n",
      "the loss is 0.260958 and the accuracy is 0.937500\n",
      "the loss is 0.378605 and the accuracy is 0.875000\n",
      "the loss is 0.410836 and the accuracy is 0.687500\n",
      "the loss is 0.416826 and the accuracy is 0.843750\n",
      "the loss is 0.468540 and the accuracy is 0.781250\n",
      "the loss is 0.287358 and the accuracy is 0.843750\n",
      "the loss is 0.289068 and the accuracy is 0.781250\n",
      "the loss is 0.243074 and the accuracy is 0.906250\n",
      "the loss is 0.310224 and the accuracy is 0.812500\n",
      "the loss is 0.318882 and the accuracy is 0.750000\n",
      "the loss is 0.106191 and the accuracy is 0.968750\n",
      "the loss is 0.254533 and the accuracy is 0.937500\n",
      "the loss is 0.569064 and the accuracy is 0.843750\n",
      "the loss is 0.419762 and the accuracy is 0.781250\n",
      "the loss is 0.328072 and the accuracy is 0.937500\n",
      "the loss is 0.201619 and the accuracy is 0.875000\n",
      "the loss is 0.323410 and the accuracy is 0.906250\n",
      "the loss is 0.305604 and the accuracy is 0.812500\n",
      "the loss is 0.235765 and the accuracy is 0.937500\n",
      "the loss is 0.159106 and the accuracy is 0.937500\n",
      "the loss is 0.247303 and the accuracy is 0.906250\n",
      "the loss is 0.352750 and the accuracy is 0.812500\n",
      "the loss is 0.228950 and the accuracy is 0.937500\n",
      "the loss is 0.336484 and the accuracy is 0.812500\n",
      "the loss is 0.369764 and the accuracy is 0.875000\n",
      "the loss is 0.365852 and the accuracy is 0.875000\n",
      "the loss is 0.400296 and the accuracy is 0.843750\n",
      "the loss is 0.285531 and the accuracy is 0.875000\n",
      "the loss is 0.421133 and the accuracy is 0.812500\n",
      "the loss is 0.375477 and the accuracy is 0.812500\n",
      "the loss is 0.177636 and the accuracy is 0.968750\n",
      "the loss is 0.321686 and the accuracy is 0.875000\n",
      "the loss is 0.254084 and the accuracy is 0.875000\n",
      "the loss is 0.234063 and the accuracy is 0.875000\n",
      "the loss is 0.388367 and the accuracy is 0.781250\n",
      "the loss is 0.262329 and the accuracy is 0.906250\n",
      "the loss is 0.190469 and the accuracy is 0.968750\n",
      "the loss is 0.279126 and the accuracy is 0.875000\n",
      "the loss is 0.261142 and the accuracy is 0.843750\n",
      "the loss is 0.208865 and the accuracy is 0.937500\n",
      "the loss is 0.510360 and the accuracy is 0.843750\n",
      "the loss is 0.488023 and the accuracy is 0.875000\n",
      "the loss is 0.175345 and the accuracy is 0.937500\n",
      "the loss is 0.296548 and the accuracy is 0.875000\n",
      "the loss is 0.257221 and the accuracy is 0.906250\n",
      "the loss is 0.365899 and the accuracy is 0.875000\n",
      "the loss is 0.273259 and the accuracy is 0.812500\n",
      "the loss is 0.214768 and the accuracy is 0.906250\n",
      "the loss is 0.212904 and the accuracy is 0.937500\n",
      "the loss is 0.308694 and the accuracy is 0.843750\n",
      "the loss is 0.182479 and the accuracy is 0.937500\n",
      "the loss is 0.140820 and the accuracy is 0.968750\n",
      "the loss is 0.347668 and the accuracy is 0.812500\n",
      "the loss is 0.221933 and the accuracy is 0.937500\n",
      "the loss is 0.267417 and the accuracy is 0.875000\n",
      "the loss is 0.326282 and the accuracy is 0.781250\n",
      "the loss is 0.484853 and the accuracy is 0.687500\n",
      "the loss is 0.232958 and the accuracy is 0.906250\n",
      "the loss is 0.167209 and the accuracy is 0.937500\n",
      "the loss is 0.322798 and the accuracy is 0.781250\n",
      "the loss is 0.376695 and the accuracy is 0.906250\n",
      "the loss is 0.453071 and the accuracy is 0.812500\n",
      "the loss is 0.295483 and the accuracy is 0.812500\n",
      "the loss is 0.278566 and the accuracy is 0.875000\n",
      "the loss is 0.400031 and the accuracy is 0.843750\n",
      "the loss is 0.360603 and the accuracy is 0.812500\n",
      "the loss is 0.216036 and the accuracy is 0.906250\n",
      "the loss is 0.219507 and the accuracy is 0.906250\n",
      "the loss is 0.360459 and the accuracy is 0.875000\n",
      "the loss is 0.097235 and the accuracy is 0.937500\n",
      "the loss is 0.435339 and the accuracy is 0.812500\n",
      "the loss is 0.319180 and the accuracy is 0.812500\n",
      "the loss is 0.261719 and the accuracy is 0.875000\n",
      "the loss is 0.455043 and the accuracy is 0.812500\n",
      "the loss is 0.186768 and the accuracy is 0.937500\n",
      "the loss is 0.337544 and the accuracy is 0.843750\n",
      "the loss is 0.402932 and the accuracy is 0.750000\n",
      "the loss is 0.340221 and the accuracy is 0.812500\n",
      "the loss is 0.184064 and the accuracy is 0.968750\n",
      "the loss is 0.431741 and the accuracy is 0.718750\n",
      "the loss is 0.248914 and the accuracy is 0.843750\n",
      "the loss is 0.238851 and the accuracy is 0.875000\n",
      "the loss is 0.322490 and the accuracy is 0.812500\n",
      "the loss is 0.403857 and the accuracy is 0.812500\n",
      "the loss is 0.294029 and the accuracy is 0.906250\n",
      "the loss is 0.203387 and the accuracy is 0.937500\n",
      "the loss is 0.456638 and the accuracy is 0.843750\n",
      "the loss is 0.272064 and the accuracy is 0.875000\n",
      "the loss is 0.125295 and the accuracy is 0.968750\n",
      "the loss is 0.128588 and the accuracy is 0.968750\n",
      "the loss is 0.245449 and the accuracy is 0.875000\n",
      "the loss is 0.348693 and the accuracy is 0.875000\n",
      "the loss is 0.411600 and the accuracy is 0.812500\n",
      "the loss is 0.123372 and the accuracy is 0.968750\n",
      "the loss is 0.297630 and the accuracy is 0.875000\n",
      "the loss is 0.186275 and the accuracy is 0.937500\n",
      "the loss is 0.217551 and the accuracy is 0.906250\n",
      "the loss is 0.256772 and the accuracy is 0.906250\n",
      "the loss is 0.243281 and the accuracy is 0.906250\n",
      "the loss is 0.304917 and the accuracy is 0.843750\n",
      "the loss is 0.322484 and the accuracy is 0.843750\n",
      "the loss is 0.292129 and the accuracy is 0.875000\n",
      "the loss is 0.391394 and the accuracy is 0.843750\n",
      "the loss is 0.219910 and the accuracy is 0.875000\n",
      "the loss is 0.223264 and the accuracy is 0.937500\n",
      "the loss is 0.291566 and the accuracy is 0.875000\n",
      "the loss is 0.360404 and the accuracy is 0.718750\n",
      "the loss is 0.249605 and the accuracy is 0.875000\n",
      "the loss is 0.190771 and the accuracy is 0.937500\n",
      "the loss is 0.378450 and the accuracy is 0.812500\n",
      "the loss is 0.344970 and the accuracy is 0.875000\n",
      "the loss is 0.270535 and the accuracy is 0.875000\n",
      "the loss is 0.304575 and the accuracy is 0.781250\n",
      "the loss is 0.252125 and the accuracy is 0.937500\n",
      "the loss is 0.313802 and the accuracy is 0.906250\n",
      "the loss is 0.250720 and the accuracy is 0.875000\n",
      "the loss is 0.361627 and the accuracy is 0.812500\n",
      "the loss is 0.358431 and the accuracy is 0.937500\n",
      "the loss is 0.219189 and the accuracy is 0.875000\n",
      "the loss is 0.337834 and the accuracy is 0.843750\n",
      "the loss is 0.266591 and the accuracy is 0.906250\n",
      "the loss is 0.240102 and the accuracy is 0.875000\n",
      "the loss is 0.335540 and the accuracy is 0.875000\n",
      "the loss is 0.258671 and the accuracy is 0.906250\n",
      "the loss is 0.348868 and the accuracy is 0.781250\n",
      "the loss is 0.314673 and the accuracy is 0.812500\n",
      "the loss is 0.150031 and the accuracy is 0.906250\n",
      "the loss is 0.235681 and the accuracy is 0.812500\n",
      "the loss is 0.327778 and the accuracy is 0.906250\n",
      "the loss is 0.352069 and the accuracy is 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.171142 and the accuracy is 0.937500\n",
      "the loss is 0.543116 and the accuracy is 0.718750\n",
      "the loss is 0.224898 and the accuracy is 0.937500\n",
      "the loss is 0.312811 and the accuracy is 0.843750\n",
      "the loss is 0.211532 and the accuracy is 0.875000\n",
      "the loss is 0.208169 and the accuracy is 0.906250\n",
      "the loss is 0.336828 and the accuracy is 0.875000\n",
      "the loss is 0.373418 and the accuracy is 0.781250\n",
      "the loss is 0.235101 and the accuracy is 0.875000\n",
      "the loss is 0.120948 and the accuracy is 0.968750\n",
      "the loss is 0.303481 and the accuracy is 0.937500\n",
      "the loss is 0.101168 and the accuracy is 0.968750\n",
      "the loss is 0.313410 and the accuracy is 0.812500\n",
      "the loss is 0.381940 and the accuracy is 0.843750\n",
      "the loss is 0.247790 and the accuracy is 0.875000\n",
      "the loss is 0.423135 and the accuracy is 0.781250\n",
      "the loss is 0.279121 and the accuracy is 0.906250\n",
      "the loss is 0.144938 and the accuracy is 0.968750\n",
      "the loss is 0.371505 and the accuracy is 0.843750\n",
      "the loss is 0.464617 and the accuracy is 0.875000\n",
      "the loss is 0.336652 and the accuracy is 0.812500\n",
      "the loss is 0.242523 and the accuracy is 0.906250\n",
      "the loss is 0.406791 and the accuracy is 0.843750\n",
      "the loss is 0.307827 and the accuracy is 0.812500\n",
      "the loss is 0.295475 and the accuracy is 0.843750\n",
      "the loss is 0.391662 and the accuracy is 0.812500\n",
      "the loss is 0.453629 and the accuracy is 0.781250\n",
      "the loss is 0.214422 and the accuracy is 0.937500\n",
      "the loss is 0.143379 and the accuracy is 0.968750\n",
      "the loss is 0.291399 and the accuracy is 0.937500\n",
      "the loss is 0.169014 and the accuracy is 0.937500\n",
      "the loss is 0.248275 and the accuracy is 0.906250\n",
      "the loss is 0.136819 and the accuracy is 0.968750\n",
      "the loss is 0.581327 and the accuracy is 0.812500\n",
      "the loss is 0.299108 and the accuracy is 0.843750\n",
      "the loss is 0.311511 and the accuracy is 0.812500\n",
      "the loss is 0.321438 and the accuracy is 0.906250\n",
      "the loss is 0.313902 and the accuracy is 0.875000\n",
      "the loss is 0.249374 and the accuracy is 0.812500\n",
      "the loss is 0.167591 and the accuracy is 0.906250\n",
      "the loss is 0.346062 and the accuracy is 0.812500\n",
      "the loss is 0.336262 and the accuracy is 0.781250\n",
      "the loss is 0.093069 and the accuracy is 1.000000\n",
      "the loss is 0.328596 and the accuracy is 0.843750\n",
      "the loss is 0.127643 and the accuracy is 0.968750\n",
      "the loss is 0.300637 and the accuracy is 0.875000\n",
      "the loss is 0.498712 and the accuracy is 0.843750\n",
      "the loss is 0.431815 and the accuracy is 0.812500\n",
      "the loss is 0.196395 and the accuracy is 0.937500\n",
      "the loss is 0.222863 and the accuracy is 0.875000\n",
      "the loss is 0.472346 and the accuracy is 0.781250\n",
      "the loss is 0.285022 and the accuracy is 0.906250\n",
      "the loss is 0.286045 and the accuracy is 0.875000\n",
      "the loss is 0.239695 and the accuracy is 0.906250\n",
      "the loss is 0.330253 and the accuracy is 0.875000\n",
      "the loss is 0.225815 and the accuracy is 0.937500\n",
      "the loss is 0.229022 and the accuracy is 0.937500\n",
      "the loss is 0.321756 and the accuracy is 0.906250\n",
      "the loss is 0.285585 and the accuracy is 0.937500\n",
      "the loss is 0.342133 and the accuracy is 0.812500\n",
      "the loss is 0.145409 and the accuracy is 0.937500\n",
      "the loss is 0.332618 and the accuracy is 0.875000\n",
      "the loss is 0.330186 and the accuracy is 0.937500\n",
      "the loss is 0.180285 and the accuracy is 0.937500\n",
      "the loss is 0.197799 and the accuracy is 0.937500\n",
      "the loss is 0.374953 and the accuracy is 0.843750\n",
      "the loss is 0.256936 and the accuracy is 0.906250\n",
      "the loss is 0.423260 and the accuracy is 0.750000\n",
      "the loss is 0.226594 and the accuracy is 0.843750\n",
      "the loss is 0.312998 and the accuracy is 0.937500\n",
      "the loss is 0.223646 and the accuracy is 0.906250\n",
      "the loss is 0.427262 and the accuracy is 0.781250\n",
      "the loss is 0.302101 and the accuracy is 0.875000\n",
      "the loss is 0.166990 and the accuracy is 0.937500\n",
      "the loss is 0.191872 and the accuracy is 0.937500\n",
      "the loss is 0.322133 and the accuracy is 0.875000\n",
      "the loss is 0.337770 and the accuracy is 0.843750\n",
      "the loss is 0.196347 and the accuracy is 0.906250\n",
      "the loss is 0.242050 and the accuracy is 0.937500\n",
      "the loss is 0.314277 and the accuracy is 0.843750\n",
      "the loss is 0.167084 and the accuracy is 0.968750\n",
      "the loss is 0.260175 and the accuracy is 0.906250\n",
      "the loss is 0.148144 and the accuracy is 0.968750\n",
      "the loss is 0.656860 and the accuracy is 0.718750\n",
      "the loss is 0.360588 and the accuracy is 0.843750\n",
      "the loss is 0.446710 and the accuracy is 0.843750\n",
      "the loss is 0.380827 and the accuracy is 0.843750\n",
      "the loss is 0.385531 and the accuracy is 0.875000\n",
      "the loss is 0.188746 and the accuracy is 0.937500\n",
      "the loss is 0.408175 and the accuracy is 0.718750\n",
      "the loss is 0.404041 and the accuracy is 0.781250\n",
      "the loss is 0.210194 and the accuracy is 0.906250\n",
      "the loss is 0.437895 and the accuracy is 0.812500\n",
      "the loss is 0.297286 and the accuracy is 0.812500\n",
      "the loss is 0.504879 and the accuracy is 0.812500\n",
      "the loss is 0.167403 and the accuracy is 0.937500\n",
      "the loss is 0.417490 and the accuracy is 0.812500\n",
      "the loss is 0.336720 and the accuracy is 0.812500\n",
      "the loss is 0.325827 and the accuracy is 0.906250\n",
      "the loss is 0.334450 and the accuracy is 0.843750\n",
      "the loss is 0.444542 and the accuracy is 0.812500\n",
      "the loss is 0.240435 and the accuracy is 0.812500\n",
      "the loss is 0.311587 and the accuracy is 0.875000\n",
      "the loss is 0.141760 and the accuracy is 0.968750\n",
      "the loss is 0.315685 and the accuracy is 0.843750\n",
      "the loss is 0.198682 and the accuracy is 0.875000\n",
      "the loss is 0.174064 and the accuracy is 0.937500\n",
      "the loss is 0.213181 and the accuracy is 0.937500\n",
      "the loss is 0.272758 and the accuracy is 0.843750\n",
      "the loss is 0.420382 and the accuracy is 0.781250\n",
      "the loss is 0.334498 and the accuracy is 0.812500\n",
      "the loss is 0.325921 and the accuracy is 0.843750\n",
      "the loss is 0.263023 and the accuracy is 0.906250\n",
      "the loss is 0.233839 and the accuracy is 0.906250\n",
      "the loss is 0.279197 and the accuracy is 0.875000\n",
      "the loss is 0.348370 and the accuracy is 0.875000\n",
      "the loss is 0.227358 and the accuracy is 0.937500\n",
      "the loss is 0.319287 and the accuracy is 0.875000\n",
      "the loss is 0.241983 and the accuracy is 0.843750\n",
      "the loss is 0.182418 and the accuracy is 0.937500\n",
      "the loss is 0.292294 and the accuracy is 0.875000\n",
      "the loss is 0.237209 and the accuracy is 0.906250\n",
      "the loss is 0.278166 and the accuracy is 0.906250\n",
      "the loss is 0.302826 and the accuracy is 0.875000\n",
      "the loss is 0.295752 and the accuracy is 0.875000\n",
      "the loss is 0.454181 and the accuracy is 0.812500\n",
      "the loss is 0.303515 and the accuracy is 0.937500\n",
      "the loss is 0.354545 and the accuracy is 0.781250\n",
      "the loss is 0.379506 and the accuracy is 0.875000\n",
      "the loss is 0.345077 and the accuracy is 0.781250\n",
      "the loss is 0.227285 and the accuracy is 0.906250\n",
      "the loss is 0.271193 and the accuracy is 0.843750\n",
      "the loss is 0.301228 and the accuracy is 0.843750\n",
      "the loss is 0.285817 and the accuracy is 0.906250\n",
      "the loss is 0.441076 and the accuracy is 0.843750\n",
      "the loss is 0.214154 and the accuracy is 0.968750\n",
      "the loss is 0.406746 and the accuracy is 0.812500\n",
      "the loss is 0.287851 and the accuracy is 0.906250\n",
      "the loss is 0.271342 and the accuracy is 0.843750\n",
      "the loss is 0.231436 and the accuracy is 0.906250\n",
      "the loss is 0.316418 and the accuracy is 0.875000\n",
      "the loss is 0.239650 and the accuracy is 0.937500\n",
      "the loss is 0.434426 and the accuracy is 0.875000\n",
      "the loss is 0.332179 and the accuracy is 0.812500\n",
      "the loss is 0.231428 and the accuracy is 0.906250\n",
      "the loss is 0.398917 and the accuracy is 0.781250\n",
      "the loss is 0.520019 and the accuracy is 0.812500\n",
      "the loss is 0.190878 and the accuracy is 0.906250\n",
      "the loss is 0.315965 and the accuracy is 0.812500\n",
      "the loss is 0.161679 and the accuracy is 0.968750\n",
      "the loss is 0.227192 and the accuracy is 0.875000\n",
      "the loss is 0.149581 and the accuracy is 0.968750\n",
      "the loss is 0.263917 and the accuracy is 0.812500\n",
      "the loss is 0.379828 and the accuracy is 0.843750\n",
      "the loss is 0.338264 and the accuracy is 0.875000\n",
      "the loss is 0.254145 and the accuracy is 0.937500\n",
      "the loss is 0.398273 and the accuracy is 0.812500\n",
      "the loss is 0.190492 and the accuracy is 0.937500\n",
      "the loss is 0.334780 and the accuracy is 0.843750\n",
      "the loss is 0.254206 and the accuracy is 0.843750\n",
      "the loss is 0.378479 and the accuracy is 0.843750\n",
      "the loss is 0.320386 and the accuracy is 0.875000\n",
      "the loss is 0.311093 and the accuracy is 0.812500\n",
      "the loss is 0.296868 and the accuracy is 0.843750\n",
      "the loss is 0.362495 and the accuracy is 0.843750\n",
      "the loss is 0.309991 and the accuracy is 0.875000\n",
      "the loss is 0.318010 and the accuracy is 0.875000\n",
      "the loss is 0.228754 and the accuracy is 0.843750\n",
      "the loss is 0.292821 and the accuracy is 0.906250\n",
      "the loss is 0.203138 and the accuracy is 0.937500\n",
      "the loss is 0.115376 and the accuracy is 0.968750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.542986 and the accuracy is 0.781250\n",
      "the loss is 0.274997 and the accuracy is 0.843750\n",
      "the loss is 0.281216 and the accuracy is 0.937500\n",
      "the loss is 0.149956 and the accuracy is 0.968750\n",
      "the loss is 0.163349 and the accuracy is 0.937500\n",
      "the loss is 0.301550 and the accuracy is 0.875000\n",
      "the loss is 0.416338 and the accuracy is 0.812500\n",
      "the loss is 0.479064 and the accuracy is 0.812500\n",
      "the loss is 0.357353 and the accuracy is 0.906250\n",
      "the loss is 0.351376 and the accuracy is 0.781250\n",
      "the loss is 0.339586 and the accuracy is 0.843750\n",
      "the loss is 0.378808 and the accuracy is 0.843750\n",
      "the loss is 0.255923 and the accuracy is 0.906250\n",
      "the loss is 0.316078 and the accuracy is 0.843750\n",
      "the loss is 0.531897 and the accuracy is 0.750000\n",
      "the loss is 0.323853 and the accuracy is 0.812500\n",
      "the loss is 0.186898 and the accuracy is 0.937500\n",
      "the loss is 0.366851 and the accuracy is 0.781250\n",
      "the loss is 0.259466 and the accuracy is 0.875000\n",
      "the loss is 0.164955 and the accuracy is 0.906250\n",
      "the loss is 0.156614 and the accuracy is 0.937500\n",
      "the loss is 0.399587 and the accuracy is 0.843750\n",
      "the loss is 0.283001 and the accuracy is 0.875000\n",
      "the loss is 0.419674 and the accuracy is 0.781250\n",
      "the loss is 0.385008 and the accuracy is 0.781250\n",
      "the loss is 0.361532 and the accuracy is 0.781250\n",
      "the loss is 0.464160 and the accuracy is 0.812500\n",
      "the loss is 0.222452 and the accuracy is 0.937500\n",
      "the loss is 0.260626 and the accuracy is 0.812500\n",
      "the loss is 0.177760 and the accuracy is 0.968750\n",
      "the loss is 0.195997 and the accuracy is 0.875000\n",
      "the loss is 0.146514 and the accuracy is 0.968750\n",
      "the loss is 0.146334 and the accuracy is 0.937500\n",
      "the loss is 0.117694 and the accuracy is 0.968750\n",
      "the loss is 0.201979 and the accuracy is 0.875000\n",
      "the loss is 0.152960 and the accuracy is 0.968750\n",
      "the loss is 0.358476 and the accuracy is 0.781250\n",
      "the loss is 0.234260 and the accuracy is 0.906250\n",
      "the loss is 0.359553 and the accuracy is 0.843750\n",
      "the loss is 0.283200 and the accuracy is 0.906250\n",
      "the loss is 0.349576 and the accuracy is 0.812500\n",
      "the loss is 0.176218 and the accuracy is 0.937500\n",
      "the loss is 0.314340 and the accuracy is 0.843750\n",
      "the loss is 0.177902 and the accuracy is 0.906250\n",
      "the loss is 0.280979 and the accuracy is 0.875000\n",
      "the loss is 0.338001 and the accuracy is 0.843750\n",
      "the loss is 0.329805 and the accuracy is 0.937500\n",
      "the loss is 0.347246 and the accuracy is 0.875000\n",
      "the loss is 0.276525 and the accuracy is 0.937500\n",
      "the loss is 0.360310 and the accuracy is 0.875000\n",
      "the loss is 0.589692 and the accuracy is 0.750000\n",
      "the loss is 0.386334 and the accuracy is 0.750000\n",
      "the loss is 0.244493 and the accuracy is 0.875000\n",
      "the loss is 0.306385 and the accuracy is 0.875000\n",
      "the loss is 0.455763 and the accuracy is 0.781250\n",
      "the loss is 0.151956 and the accuracy is 0.937500\n",
      "the loss is 0.296023 and the accuracy is 0.875000\n",
      "the loss is 0.102114 and the accuracy is 0.968750\n",
      "the loss is 0.307953 and the accuracy is 0.812500\n",
      "the loss is 0.216808 and the accuracy is 0.906250\n",
      "the loss is 0.492346 and the accuracy is 0.781250\n",
      "the loss is 0.277172 and the accuracy is 0.875000\n",
      "the loss is 0.354117 and the accuracy is 0.906250\n",
      "the loss is 0.194091 and the accuracy is 0.937500\n",
      "the loss is 0.446377 and the accuracy is 0.750000\n",
      "the loss is 0.165621 and the accuracy is 0.937500\n",
      "the loss is 0.476946 and the accuracy is 0.781250\n",
      "the loss is 0.252875 and the accuracy is 0.875000\n",
      "the loss is 0.130585 and the accuracy is 0.937500\n",
      "the loss is 0.178170 and the accuracy is 0.937500\n",
      "the loss is 0.340500 and the accuracy is 0.812500\n",
      "the loss is 0.262037 and the accuracy is 0.875000\n",
      "the loss is 0.274196 and the accuracy is 0.906250\n",
      "the loss is 0.337884 and the accuracy is 0.875000\n",
      "the loss is 0.274670 and the accuracy is 0.937500\n",
      "the loss is 0.363123 and the accuracy is 0.843750\n",
      "the loss is 0.210475 and the accuracy is 0.906250\n",
      "the loss is 0.259015 and the accuracy is 0.843750\n",
      "the loss is 0.247410 and the accuracy is 0.937500\n",
      "the loss is 0.328568 and the accuracy is 0.843750\n",
      "the loss is 0.148185 and the accuracy is 0.968750\n",
      "the loss is 0.193499 and the accuracy is 0.937500\n",
      "the loss is 0.442782 and the accuracy is 0.781250\n",
      "the loss is 0.358132 and the accuracy is 0.843750\n",
      "the loss is 0.335810 and the accuracy is 0.843750\n",
      "the loss is 0.396170 and the accuracy is 0.750000\n",
      "the loss is 0.297302 and the accuracy is 0.812500\n",
      "the loss is 0.167047 and the accuracy is 0.937500\n",
      "the loss is 0.406006 and the accuracy is 0.812500\n",
      "the loss is 0.135160 and the accuracy is 0.968750\n",
      "the loss is 0.315722 and the accuracy is 0.843750\n",
      "the loss is 0.362542 and the accuracy is 0.875000\n",
      "the loss is 0.198499 and the accuracy is 0.968750\n",
      "the loss is 0.218481 and the accuracy is 0.875000\n",
      "the loss is 0.162544 and the accuracy is 0.968750\n",
      "the loss is 0.259572 and the accuracy is 0.843750\n",
      "the loss is 0.323091 and the accuracy is 0.843750\n",
      "the loss is 0.408100 and the accuracy is 0.812500\n",
      "the loss is 0.268227 and the accuracy is 0.843750\n",
      "the loss is 0.341955 and the accuracy is 0.875000\n",
      "the loss is 0.310417 and the accuracy is 0.875000\n",
      "the loss is 0.437864 and the accuracy is 0.812500\n",
      "the loss is 0.186662 and the accuracy is 0.906250\n",
      "the loss is 0.376092 and the accuracy is 0.843750\n",
      "the loss is 0.290202 and the accuracy is 0.906250\n",
      "the loss is 0.391321 and the accuracy is 0.843750\n",
      "the loss is 0.126650 and the accuracy is 0.937500\n",
      "the loss is 0.297582 and the accuracy is 0.906250\n",
      "the loss is 0.290328 and the accuracy is 0.812500\n",
      "the loss is 0.250884 and the accuracy is 0.906250\n",
      "the loss is 0.229393 and the accuracy is 0.937500\n",
      "the loss is 0.147581 and the accuracy is 0.968750\n",
      "the loss is 0.240632 and the accuracy is 0.875000\n",
      "the loss is 0.314349 and the accuracy is 0.906250\n",
      "the loss is 0.301171 and the accuracy is 0.843750\n",
      "the loss is 0.244538 and the accuracy is 0.906250\n",
      "the loss is 0.423254 and the accuracy is 0.843750\n",
      "the loss is 0.255542 and the accuracy is 0.875000\n",
      "the loss is 0.218514 and the accuracy is 0.937500\n",
      "the loss is 0.268615 and the accuracy is 0.937500\n",
      "the loss is 0.220874 and the accuracy is 0.906250\n",
      "the loss is 0.334010 and the accuracy is 0.875000\n",
      "the loss is 0.180740 and the accuracy is 0.937500\n",
      "the loss is 0.310335 and the accuracy is 0.843750\n",
      "the loss is 0.204501 and the accuracy is 0.906250\n",
      "the loss is 0.382253 and the accuracy is 0.750000\n",
      "the loss is 0.322221 and the accuracy is 0.937500\n",
      "the loss is 0.273833 and the accuracy is 0.906250\n",
      "the loss is 0.208937 and the accuracy is 0.906250\n",
      "the loss is 0.365692 and the accuracy is 0.812500\n",
      "the loss is 0.163845 and the accuracy is 0.937500\n",
      "the loss is 0.305281 and the accuracy is 0.843750\n",
      "the loss is 0.470166 and the accuracy is 0.750000\n",
      "the loss is 0.455101 and the accuracy is 0.750000\n",
      "the loss is 0.279429 and the accuracy is 0.875000\n",
      "the loss is 0.290324 and the accuracy is 0.812500\n",
      "the loss is 0.260112 and the accuracy is 0.937500\n",
      "the loss is 0.308027 and the accuracy is 0.906250\n",
      "the loss is 0.126263 and the accuracy is 0.968750\n",
      "the loss is 0.349217 and the accuracy is 0.812500\n",
      "the loss is 0.620601 and the accuracy is 0.781250\n",
      "the loss is 0.494931 and the accuracy is 0.781250\n",
      "the loss is 0.397056 and the accuracy is 0.750000\n",
      "the loss is 0.396739 and the accuracy is 0.781250\n",
      "the loss is 0.330607 and the accuracy is 0.781250\n",
      "the loss is 0.473169 and the accuracy is 0.812500\n",
      "the loss is 0.197425 and the accuracy is 0.937500\n",
      "the loss is 0.121903 and the accuracy is 0.937500\n",
      "the loss is 0.435921 and the accuracy is 0.812500\n",
      "the loss is 0.446098 and the accuracy is 0.812500\n",
      "the loss is 0.182873 and the accuracy is 0.937500\n",
      "the loss is 0.431130 and the accuracy is 0.750000\n",
      "the loss is 0.129013 and the accuracy is 1.000000\n",
      "the loss is 0.287372 and the accuracy is 0.843750\n",
      "the loss is 0.405423 and the accuracy is 0.781250\n",
      "the loss is 0.226499 and the accuracy is 0.906250\n",
      "the loss is 0.219293 and the accuracy is 0.906250\n",
      "the loss is 0.310251 and the accuracy is 0.843750\n",
      "the loss is 0.239299 and the accuracy is 0.906250\n",
      "the loss is 0.180620 and the accuracy is 0.906250\n",
      "the loss is 0.314176 and the accuracy is 0.843750\n",
      "the loss is 0.159750 and the accuracy is 0.968750\n",
      "the loss is 0.173470 and the accuracy is 0.968750\n",
      "the loss is 0.133972 and the accuracy is 0.968750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.295349 and the accuracy is 0.906250\n",
      "the loss is 0.170732 and the accuracy is 0.937500\n",
      "the loss is 0.182986 and the accuracy is 0.937500\n",
      "the loss is 0.420540 and the accuracy is 0.781250\n",
      "the loss is 0.695193 and the accuracy is 0.718750\n",
      "the loss is 0.200346 and the accuracy is 0.937500\n",
      "the loss is 0.358980 and the accuracy is 0.906250\n",
      "the loss is 0.146665 and the accuracy is 0.968750\n",
      "the loss is 0.468214 and the accuracy is 0.843750\n",
      "the loss is 0.364442 and the accuracy is 0.875000\n",
      "the loss is 0.125642 and the accuracy is 1.000000\n",
      "the loss is 0.261398 and the accuracy is 0.968750\n",
      "the loss is 0.241460 and the accuracy is 0.875000\n",
      "the loss is 0.321579 and the accuracy is 0.843750\n",
      "the loss is 0.245797 and the accuracy is 0.906250\n",
      "the loss is 0.270228 and the accuracy is 0.906250\n",
      "the loss is 0.291653 and the accuracy is 0.875000\n",
      "the loss is 0.227845 and the accuracy is 0.968750\n",
      "the loss is 0.248359 and the accuracy is 0.906250\n",
      "the loss is 0.435122 and the accuracy is 0.781250\n",
      "the loss is 0.297404 and the accuracy is 0.843750\n",
      "the loss is 0.435663 and the accuracy is 0.812500\n",
      "the loss is 0.195978 and the accuracy is 0.968750\n",
      "the loss is 0.159578 and the accuracy is 0.937500\n",
      "the loss is 0.168143 and the accuracy is 0.937500\n",
      "the loss is 0.228889 and the accuracy is 0.937500\n",
      "the loss is 0.233713 and the accuracy is 0.906250\n",
      "the loss is 0.560158 and the accuracy is 0.687500\n",
      "the loss is 0.203356 and the accuracy is 0.906250\n",
      "the loss is 0.154288 and the accuracy is 0.968750\n",
      "the loss is 0.377334 and the accuracy is 0.843750\n",
      "the loss is 0.183501 and the accuracy is 0.906250\n",
      "the loss is 0.398803 and the accuracy is 0.718750\n",
      "the loss is 0.237542 and the accuracy is 0.843750\n",
      "the loss is 0.401774 and the accuracy is 0.906250\n",
      "the loss is 0.317008 and the accuracy is 0.843750\n",
      "the loss is 0.296033 and the accuracy is 0.875000\n",
      "the loss is 0.352162 and the accuracy is 0.812500\n",
      "the loss is 0.433878 and the accuracy is 0.781250\n",
      "the loss is 0.271263 and the accuracy is 0.812500\n",
      "the loss is 0.145352 and the accuracy is 0.906250\n",
      "the loss is 0.270070 and the accuracy is 0.875000\n",
      "the loss is 0.262343 and the accuracy is 0.875000\n",
      "the loss is 0.283823 and the accuracy is 0.937500\n",
      "the loss is 0.395724 and the accuracy is 0.812500\n",
      "the loss is 0.308240 and the accuracy is 0.843750\n",
      "the loss is 0.315817 and the accuracy is 0.937500\n",
      "the loss is 0.419926 and the accuracy is 0.812500\n",
      "the loss is 0.316920 and the accuracy is 0.750000\n",
      "the loss is 0.364878 and the accuracy is 0.781250\n",
      "the loss is 0.176848 and the accuracy is 0.937500\n",
      "the loss is 0.283692 and the accuracy is 0.906250\n",
      "the loss is 0.254375 and the accuracy is 0.875000\n",
      "the loss is 0.235358 and the accuracy is 0.843750\n",
      "the loss is 0.292326 and the accuracy is 0.875000\n",
      "the loss is 0.302216 and the accuracy is 0.875000\n",
      "the loss is 0.281702 and the accuracy is 0.875000\n",
      "the loss is 0.374232 and the accuracy is 0.812500\n",
      "the loss is 0.150857 and the accuracy is 1.000000\n",
      "the loss is 0.432376 and the accuracy is 0.781250\n",
      "the loss is 0.274083 and the accuracy is 0.875000\n",
      "the loss is 0.371981 and the accuracy is 0.843750\n",
      "the loss is 0.264675 and the accuracy is 0.875000\n",
      "the loss is 0.316425 and the accuracy is 0.812500\n",
      "the loss is 0.187762 and the accuracy is 0.937500\n",
      "the loss is 0.319492 and the accuracy is 0.906250\n",
      "the loss is 0.246119 and the accuracy is 0.875000\n",
      "the loss is 0.302417 and the accuracy is 0.843750\n",
      "the loss is 0.309930 and the accuracy is 0.906250\n",
      "the loss is 0.235233 and the accuracy is 0.906250\n",
      "the loss is 0.200721 and the accuracy is 0.968750\n",
      "the loss is 0.478296 and the accuracy is 0.687500\n",
      "the loss is 0.285232 and the accuracy is 0.875000\n",
      "the loss is 0.423038 and the accuracy is 0.875000\n",
      "the loss is 0.473005 and the accuracy is 0.718750\n",
      "the loss is 0.533745 and the accuracy is 0.718750\n",
      "the loss is 0.351518 and the accuracy is 0.843750\n",
      "the loss is 0.362708 and the accuracy is 0.843750\n",
      "the loss is 0.192864 and the accuracy is 0.937500\n",
      "the loss is 0.137413 and the accuracy is 0.968750\n",
      "the loss is 0.334284 and the accuracy is 0.812500\n",
      "the loss is 0.382538 and the accuracy is 0.875000\n",
      "the loss is 0.287896 and the accuracy is 0.843750\n",
      "the loss is 0.235033 and the accuracy is 0.906250\n",
      "the loss is 0.442750 and the accuracy is 0.750000\n",
      "the loss is 0.290191 and the accuracy is 0.906250\n",
      "the loss is 0.132602 and the accuracy is 0.968750\n",
      "the loss is 0.440733 and the accuracy is 0.750000\n",
      "the loss is 0.361455 and the accuracy is 0.843750\n",
      "the loss is 0.358198 and the accuracy is 0.843750\n",
      "the loss is 0.313851 and the accuracy is 0.843750\n",
      "the loss is 0.203223 and the accuracy is 0.875000\n",
      "the loss is 0.225775 and the accuracy is 0.875000\n",
      "the loss is 0.264417 and the accuracy is 0.875000\n",
      "the loss is 0.202110 and the accuracy is 0.937500\n",
      "the loss is 0.312983 and the accuracy is 0.875000\n",
      "the loss is 0.254353 and the accuracy is 0.906250\n",
      "the loss is 0.389490 and the accuracy is 0.843750\n",
      "the loss is 0.435949 and the accuracy is 0.843750\n",
      "the loss is 0.275429 and the accuracy is 0.875000\n",
      "the loss is 0.268247 and the accuracy is 0.843750\n",
      "the loss is 0.336154 and the accuracy is 0.843750\n",
      "the loss is 0.356472 and the accuracy is 0.843750\n",
      "the loss is 0.205966 and the accuracy is 0.875000\n",
      "the loss is 0.247524 and the accuracy is 0.906250\n",
      "the loss is 0.162879 and the accuracy is 0.937500\n",
      "the loss is 0.108098 and the accuracy is 0.968750\n",
      "the loss is 0.329681 and the accuracy is 0.906250\n",
      "the loss is 0.303742 and the accuracy is 0.875000\n",
      "the loss is 0.225642 and the accuracy is 0.843750\n",
      "the loss is 0.312182 and the accuracy is 0.812500\n",
      "the loss is 0.153502 and the accuracy is 0.968750\n",
      "the loss is 0.236692 and the accuracy is 0.875000\n",
      "the loss is 0.388379 and the accuracy is 0.718750\n",
      "the loss is 0.225023 and the accuracy is 0.906250\n",
      "the loss is 0.335011 and the accuracy is 0.875000\n",
      "the loss is 0.303368 and the accuracy is 0.812500\n",
      "the loss is 0.443766 and the accuracy is 0.812500\n",
      "the loss is 0.272252 and the accuracy is 0.906250\n",
      "the loss is 0.219359 and the accuracy is 0.875000\n",
      "the loss is 0.182408 and the accuracy is 0.906250\n",
      "the loss is 0.322155 and the accuracy is 0.875000\n",
      "the loss is 0.177429 and the accuracy is 0.937500\n",
      "the loss is 0.196271 and the accuracy is 0.937500\n",
      "the loss is 0.318576 and the accuracy is 0.875000\n",
      "the loss is 0.313034 and the accuracy is 0.781250\n",
      "the loss is 0.218674 and the accuracy is 0.906250\n",
      "the loss is 0.239520 and the accuracy is 0.875000\n",
      "the loss is 0.197703 and the accuracy is 0.968750\n",
      "the loss is 0.415871 and the accuracy is 0.781250\n",
      "the loss is 0.190981 and the accuracy is 0.937500\n",
      "the loss is 0.318500 and the accuracy is 0.875000\n",
      "the loss is 0.494791 and the accuracy is 0.750000\n",
      "the loss is 0.260760 and the accuracy is 0.906250\n",
      "the loss is 0.367006 and the accuracy is 0.843750\n",
      "the loss is 0.143565 and the accuracy is 0.968750\n",
      "the loss is 0.341814 and the accuracy is 0.843750\n",
      "the loss is 0.241677 and the accuracy is 0.875000\n",
      "the loss is 0.230029 and the accuracy is 0.937500\n",
      "the loss is 0.479609 and the accuracy is 0.781250\n",
      "the loss is 0.323775 and the accuracy is 0.781250\n",
      "the loss is 0.454655 and the accuracy is 0.781250\n",
      "the loss is 0.163199 and the accuracy is 0.968750\n",
      "the loss is 0.299297 and the accuracy is 0.843750\n",
      "the loss is 0.410903 and the accuracy is 0.843750\n",
      "the loss is 0.134866 and the accuracy is 0.968750\n",
      "the loss is 0.188975 and the accuracy is 0.937500\n",
      "the loss is 0.261055 and the accuracy is 0.875000\n",
      "the loss is 0.198254 and the accuracy is 0.937500\n",
      "the loss is 0.211581 and the accuracy is 0.875000\n",
      "the loss is 0.434131 and the accuracy is 0.750000\n",
      "the loss is 0.247737 and the accuracy is 0.875000\n",
      "the loss is 0.215637 and the accuracy is 0.937500\n",
      "the loss is 0.356147 and the accuracy is 0.843750\n",
      "the loss is 0.491498 and the accuracy is 0.781250\n",
      "the loss is 0.328903 and the accuracy is 0.812500\n",
      "the loss is 0.339917 and the accuracy is 0.812500\n",
      "the loss is 0.349014 and the accuracy is 0.875000\n",
      "the loss is 0.186388 and the accuracy is 0.937500\n",
      "the loss is 0.228709 and the accuracy is 0.906250\n",
      "the loss is 0.454675 and the accuracy is 0.812500\n",
      "the loss is 0.459762 and the accuracy is 0.750000\n",
      "the loss is 0.223627 and the accuracy is 0.875000\n",
      "the loss is 0.236033 and the accuracy is 0.906250\n",
      "the loss is 0.209180 and the accuracy is 0.937500\n",
      "the loss is 0.222330 and the accuracy is 0.906250\n",
      "the loss is 0.352222 and the accuracy is 0.906250\n",
      "the loss is 0.457806 and the accuracy is 0.781250\n",
      "the loss is 0.202563 and the accuracy is 0.968750\n",
      "the loss is 0.241882 and the accuracy is 0.906250\n",
      "the loss is 0.292434 and the accuracy is 0.812500\n",
      "the loss is 0.196372 and the accuracy is 0.875000\n",
      "the loss is 0.300856 and the accuracy is 0.875000\n",
      "the loss is 0.425244 and the accuracy is 0.843750\n",
      "the loss is 0.321031 and the accuracy is 0.875000\n",
      "the loss is 0.268584 and the accuracy is 0.906250\n",
      "the loss is 0.213896 and the accuracy is 0.906250\n",
      "the loss is 0.309820 and the accuracy is 0.843750\n",
      "the loss is 0.132728 and the accuracy is 0.968750\n",
      "the loss is 0.348221 and the accuracy is 0.781250\n",
      "the loss is 0.516861 and the accuracy is 0.781250\n",
      "the loss is 0.184351 and the accuracy is 0.906250\n",
      "the loss is 0.174518 and the accuracy is 0.906250\n",
      "the loss is 0.298008 and the accuracy is 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.277211 and the accuracy is 0.875000\n",
      "the loss is 0.311363 and the accuracy is 0.906250\n",
      "the loss is 0.322756 and the accuracy is 0.875000\n",
      "the loss is 0.535643 and the accuracy is 0.812500\n",
      "the loss is 0.298431 and the accuracy is 0.875000\n",
      "the loss is 0.239779 and the accuracy is 0.875000\n",
      "the loss is 0.277040 and the accuracy is 0.875000\n",
      "the loss is 0.226808 and the accuracy is 0.937500\n",
      "the loss is 0.217962 and the accuracy is 0.906250\n",
      "the loss is 0.258391 and the accuracy is 0.875000\n",
      "the loss is 0.422551 and the accuracy is 0.812500\n",
      "the loss is 0.195996 and the accuracy is 0.906250\n",
      "the loss is 0.262550 and the accuracy is 0.906250\n",
      "the loss is 0.213328 and the accuracy is 0.906250\n",
      "the loss is 0.318398 and the accuracy is 0.812500\n",
      "the loss is 0.282241 and the accuracy is 0.875000\n",
      "the loss is 0.389232 and the accuracy is 0.812500\n",
      "the loss is 0.337798 and the accuracy is 0.875000\n",
      "the loss is 0.315688 and the accuracy is 0.843750\n",
      "the loss is 0.240386 and the accuracy is 0.875000\n",
      "the loss is 0.289951 and the accuracy is 0.906250\n",
      "the loss is 0.297868 and the accuracy is 0.906250\n",
      "the loss is 0.198232 and the accuracy is 0.906250\n",
      "the loss is 0.154200 and the accuracy is 0.937500\n",
      "the loss is 0.344734 and the accuracy is 0.875000\n",
      "the loss is 0.272895 and the accuracy is 0.906250\n",
      "the loss is 0.214512 and the accuracy is 0.906250\n",
      "the loss is 0.422696 and the accuracy is 0.843750\n",
      "the loss is 0.245246 and the accuracy is 0.875000\n",
      "the loss is 0.313742 and the accuracy is 0.781250\n",
      "the loss is 0.347122 and the accuracy is 0.875000\n",
      "the loss is 0.325154 and the accuracy is 0.843750\n",
      "the loss is 0.267476 and the accuracy is 0.843750\n",
      "the loss is 0.529067 and the accuracy is 0.812500\n",
      "the loss is 0.285910 and the accuracy is 0.875000\n",
      "the loss is 0.478086 and the accuracy is 0.781250\n",
      "the loss is 0.376409 and the accuracy is 0.843750\n",
      "the loss is 0.348969 and the accuracy is 0.812500\n",
      "the loss is 0.209901 and the accuracy is 0.906250\n",
      "the loss is 0.295359 and the accuracy is 0.843750\n",
      "the loss is 0.388164 and the accuracy is 0.875000\n",
      "the loss is 0.487735 and the accuracy is 0.812500\n",
      "the loss is 0.314104 and the accuracy is 0.937500\n",
      "the loss is 0.248108 and the accuracy is 0.843750\n",
      "the loss is 0.365019 and the accuracy is 0.843750\n",
      "the loss is 0.226848 and the accuracy is 0.937500\n",
      "the loss is 0.143449 and the accuracy is 0.968750\n",
      "the loss is 0.327800 and the accuracy is 0.812500\n",
      "the loss is 0.242416 and the accuracy is 0.937500\n",
      "the loss is 0.297875 and the accuracy is 0.812500\n",
      "the loss is 0.330291 and the accuracy is 0.906250\n",
      "the loss is 0.294679 and the accuracy is 0.875000\n",
      "the loss is 0.150375 and the accuracy is 0.937500\n",
      "the loss is 0.234512 and the accuracy is 0.875000\n",
      "the loss is 0.235468 and the accuracy is 0.875000\n",
      "the loss is 0.230461 and the accuracy is 0.937500\n",
      "the loss is 0.341900 and the accuracy is 0.875000\n",
      "the loss is 0.261421 and the accuracy is 0.875000\n",
      "the loss is 0.327752 and the accuracy is 0.843750\n",
      "the loss is 0.410681 and the accuracy is 0.843750\n",
      "the loss is 0.193722 and the accuracy is 0.937500\n",
      "the loss is 0.133088 and the accuracy is 0.968750\n",
      "the loss is 0.246430 and the accuracy is 0.875000\n",
      "the loss is 0.388795 and the accuracy is 0.781250\n",
      "the loss is 0.549800 and the accuracy is 0.781250\n",
      "the loss is 0.224904 and the accuracy is 0.937500\n",
      "the loss is 0.388376 and the accuracy is 0.812500\n",
      "the loss is 0.368493 and the accuracy is 0.875000\n",
      "the loss is 0.261196 and the accuracy is 0.906250\n",
      "the loss is 0.344945 and the accuracy is 0.812500\n",
      "the loss is 0.212859 and the accuracy is 0.906250\n",
      "the loss is 0.384661 and the accuracy is 0.781250\n",
      "the loss is 0.504496 and the accuracy is 0.843750\n",
      "the loss is 0.218068 and the accuracy is 0.875000\n",
      "the loss is 0.218694 and the accuracy is 0.906250\n",
      "the loss is 0.244371 and the accuracy is 0.906250\n",
      "the loss is 0.526357 and the accuracy is 0.781250\n",
      "the loss is 0.244910 and the accuracy is 0.843750\n",
      "the loss is 0.438540 and the accuracy is 0.781250\n",
      "the loss is 0.165421 and the accuracy is 0.937500\n",
      "the loss is 0.209871 and the accuracy is 0.906250\n",
      "the loss is 0.398787 and the accuracy is 0.812500\n",
      "the loss is 0.279085 and the accuracy is 0.843750\n",
      "the loss is 0.255164 and the accuracy is 0.906250\n",
      "the loss is 0.235206 and the accuracy is 0.875000\n",
      "the loss is 0.128168 and the accuracy is 0.968750\n",
      "the loss is 0.277205 and the accuracy is 0.875000\n",
      "the loss is 0.354581 and the accuracy is 0.906250\n",
      "the loss is 0.292923 and the accuracy is 0.781250\n",
      "the loss is 0.397913 and the accuracy is 0.906250\n",
      "the loss is 0.167605 and the accuracy is 0.937500\n",
      "the loss is 0.116546 and the accuracy is 0.968750\n",
      "the loss is 0.427583 and the accuracy is 0.843750\n",
      "the loss is 0.281382 and the accuracy is 0.843750\n",
      "the loss is 0.321658 and the accuracy is 0.843750\n",
      "the loss is 0.386002 and the accuracy is 0.875000\n",
      "the loss is 0.502838 and the accuracy is 0.781250\n",
      "the loss is 0.376799 and the accuracy is 0.812500\n",
      "the loss is 0.384146 and the accuracy is 0.812500\n",
      "the loss is 0.180587 and the accuracy is 0.937500\n",
      "the loss is 0.263165 and the accuracy is 0.875000\n",
      "the loss is 0.311766 and the accuracy is 0.875000\n",
      "the loss is 0.247257 and the accuracy is 0.937500\n",
      "the loss is 0.183463 and the accuracy is 0.937500\n",
      "the loss is 0.259990 and the accuracy is 0.937500\n",
      "the loss is 0.332232 and the accuracy is 0.812500\n",
      "the loss is 0.407418 and the accuracy is 0.906250\n",
      "the loss is 0.217800 and the accuracy is 0.906250\n",
      "the loss is 0.292327 and the accuracy is 0.843750\n",
      "the loss is 0.364708 and the accuracy is 0.875000\n",
      "the loss is 0.207186 and the accuracy is 0.937500\n",
      "the loss is 0.624490 and the accuracy is 0.781250\n",
      "the loss is 0.287538 and the accuracy is 0.906250\n",
      "the loss is 0.466148 and the accuracy is 0.812500\n",
      "the loss is 0.349131 and the accuracy is 0.781250\n",
      "the loss is 0.316841 and the accuracy is 0.843750\n",
      "the loss is 0.177526 and the accuracy is 0.937500\n",
      "the loss is 0.223485 and the accuracy is 0.906250\n",
      "the loss is 0.263770 and the accuracy is 0.812500\n",
      "the loss is 0.280409 and the accuracy is 0.875000\n",
      "the loss is 0.197334 and the accuracy is 0.843750\n",
      "the loss is 0.192739 and the accuracy is 0.906250\n",
      "the loss is 0.272555 and the accuracy is 0.812500\n",
      "the loss is 0.185951 and the accuracy is 0.906250\n",
      "the loss is 0.260825 and the accuracy is 0.812500\n",
      "the loss is 0.267089 and the accuracy is 0.843750\n",
      "the loss is 0.201930 and the accuracy is 0.906250\n",
      "the loss is 0.303650 and the accuracy is 0.875000\n",
      "the loss is 0.448860 and the accuracy is 0.812500\n",
      "the loss is 0.254107 and the accuracy is 0.906250\n",
      "the loss is 0.190487 and the accuracy is 0.937500\n",
      "the loss is 0.465181 and the accuracy is 0.875000\n",
      "the loss is 0.450225 and the accuracy is 0.875000\n",
      "the loss is 0.157039 and the accuracy is 0.968750\n",
      "the loss is 0.313178 and the accuracy is 0.843750\n",
      "the loss is 0.412052 and the accuracy is 0.843750\n",
      "the loss is 0.328982 and the accuracy is 0.812500\n",
      "the loss is 0.255209 and the accuracy is 0.906250\n",
      "the loss is 0.168391 and the accuracy is 0.968750\n",
      "the loss is 0.174856 and the accuracy is 0.968750\n",
      "the loss is 0.357875 and the accuracy is 0.906250\n",
      "the loss is 0.384067 and the accuracy is 0.812500\n",
      "the loss is 0.163946 and the accuracy is 0.906250\n",
      "the loss is 0.319360 and the accuracy is 0.812500\n",
      "the loss is 0.384790 and the accuracy is 0.812500\n",
      "the loss is 0.369707 and the accuracy is 0.843750\n",
      "the loss is 0.392261 and the accuracy is 0.875000\n",
      "the loss is 0.176713 and the accuracy is 0.906250\n",
      "the loss is 0.440897 and the accuracy is 0.781250\n",
      "the loss is 0.308237 and the accuracy is 0.906250\n",
      "the loss is 0.351022 and the accuracy is 0.843750\n",
      "the loss is 0.300271 and the accuracy is 0.843750\n",
      "the loss is 0.189432 and the accuracy is 0.937500\n",
      "the loss is 0.153626 and the accuracy is 0.968750\n",
      "the loss is 0.311923 and the accuracy is 0.843750\n",
      "the loss is 0.239225 and the accuracy is 0.906250\n",
      "the loss is 0.409077 and the accuracy is 0.843750\n",
      "the loss is 0.301839 and the accuracy is 0.812500\n",
      "the loss is 0.233175 and the accuracy is 0.906250\n",
      "the loss is 0.338832 and the accuracy is 0.875000\n",
      "the loss is 0.265793 and the accuracy is 0.906250\n",
      "the loss is 0.218689 and the accuracy is 0.906250\n",
      "the loss is 0.262648 and the accuracy is 0.843750\n",
      "the loss is 0.267660 and the accuracy is 0.875000\n",
      "the loss is 0.273833 and the accuracy is 0.937500\n",
      "the loss is 0.309074 and the accuracy is 0.906250\n",
      "the loss is 0.294013 and the accuracy is 0.812500\n",
      "the loss is 0.185086 and the accuracy is 0.937500\n",
      "the loss is 0.354378 and the accuracy is 0.812500\n",
      "the loss is 0.325755 and the accuracy is 0.843750\n",
      "the loss is 0.431634 and the accuracy is 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.359528 and the accuracy is 0.781250\n",
      "the loss is 0.214198 and the accuracy is 0.875000\n",
      "the loss is 0.303959 and the accuracy is 0.812500\n",
      "the loss is 0.225242 and the accuracy is 0.906250\n",
      "the loss is 0.193798 and the accuracy is 0.906250\n",
      "the loss is 0.291202 and the accuracy is 0.875000\n",
      "the loss is 0.332154 and the accuracy is 0.875000\n",
      "the loss is 0.307921 and the accuracy is 0.843750\n",
      "the loss is 0.275951 and the accuracy is 0.906250\n",
      "the loss is 0.442009 and the accuracy is 0.781250\n",
      "the loss is 0.261699 and the accuracy is 0.875000\n",
      "the loss is 0.210541 and the accuracy is 0.906250\n",
      "the loss is 0.257933 and the accuracy is 0.906250\n",
      "the loss is 0.191557 and the accuracy is 0.906250\n",
      "the loss is 0.232648 and the accuracy is 0.906250\n",
      "the loss is 0.479441 and the accuracy is 0.843750\n",
      "the loss is 0.411432 and the accuracy is 0.812500\n",
      "the loss is 0.321354 and the accuracy is 0.875000\n",
      "the loss is 0.280373 and the accuracy is 0.843750\n",
      "the loss is 0.285255 and the accuracy is 0.843750\n",
      "the loss is 0.181498 and the accuracy is 0.937500\n",
      "the loss is 0.239117 and the accuracy is 0.843750\n",
      "the loss is 0.293810 and the accuracy is 0.906250\n",
      "the loss is 0.304489 and the accuracy is 0.875000\n",
      "the loss is 0.301938 and the accuracy is 0.781250\n",
      "the loss is 0.204535 and the accuracy is 0.906250\n",
      "the loss is 0.193994 and the accuracy is 0.937500\n",
      "the loss is 0.216559 and the accuracy is 0.937500\n",
      "the loss is 0.316053 and the accuracy is 0.875000\n",
      "the loss is 0.329466 and the accuracy is 0.875000\n",
      "the loss is 0.298928 and the accuracy is 0.906250\n",
      "the loss is 0.290867 and the accuracy is 0.843750\n",
      "the loss is 0.194375 and the accuracy is 0.937500\n",
      "the loss is 0.264511 and the accuracy is 0.875000\n",
      "the loss is 0.238068 and the accuracy is 0.906250\n",
      "the loss is 0.281396 and the accuracy is 0.843750\n",
      "the loss is 0.321138 and the accuracy is 0.843750\n",
      "the loss is 0.244315 and the accuracy is 0.875000\n",
      "the loss is 0.342809 and the accuracy is 0.875000\n",
      "the loss is 0.295752 and the accuracy is 0.812500\n",
      "the loss is 0.148827 and the accuracy is 0.937500\n",
      "the loss is 0.184728 and the accuracy is 0.875000\n",
      "the loss is 0.206975 and the accuracy is 0.843750\n",
      "the loss is 0.238411 and the accuracy is 0.937500\n",
      "the loss is 0.273538 and the accuracy is 0.875000\n",
      "the loss is 0.238019 and the accuracy is 0.937500\n",
      "the loss is 0.246911 and the accuracy is 0.937500\n",
      "the loss is 0.245950 and the accuracy is 0.875000\n",
      "the loss is 0.421812 and the accuracy is 0.843750\n",
      "the loss is 0.330888 and the accuracy is 0.812500\n",
      "the loss is 0.341392 and the accuracy is 0.906250\n",
      "the loss is 0.307832 and the accuracy is 0.937500\n",
      "the loss is 0.246762 and the accuracy is 0.875000\n",
      "the loss is 0.297220 and the accuracy is 0.875000\n",
      "the loss is 0.269559 and the accuracy is 0.875000\n",
      "the loss is 0.566852 and the accuracy is 0.750000\n",
      "the loss is 0.311784 and the accuracy is 0.875000\n",
      "the loss is 0.352493 and the accuracy is 0.843750\n",
      "the loss is 0.441748 and the accuracy is 0.750000\n",
      "the loss is 0.276506 and the accuracy is 0.843750\n",
      "the loss is 0.227459 and the accuracy is 0.906250\n",
      "the loss is 0.278712 and the accuracy is 0.906250\n",
      "the loss is 0.248126 and the accuracy is 0.843750\n",
      "the loss is 0.200889 and the accuracy is 0.875000\n",
      "the loss is 0.297242 and the accuracy is 0.843750\n",
      "the loss is 0.267891 and the accuracy is 0.937500\n",
      "the loss is 0.227456 and the accuracy is 0.937500\n",
      "the loss is 0.225556 and the accuracy is 0.906250\n",
      "the loss is 0.319620 and the accuracy is 0.875000\n",
      "the loss is 0.257711 and the accuracy is 0.875000\n",
      "the loss is 0.154752 and the accuracy is 0.968750\n",
      "the loss is 0.367571 and the accuracy is 0.906250\n",
      "the loss is 0.310314 and the accuracy is 0.875000\n",
      "the loss is 0.264860 and the accuracy is 0.875000\n",
      "the loss is 0.289072 and the accuracy is 0.812500\n",
      "the loss is 0.171861 and the accuracy is 0.937500\n",
      "the loss is 0.289133 and the accuracy is 0.875000\n",
      "the loss is 0.247943 and the accuracy is 0.906250\n",
      "the loss is 0.249220 and the accuracy is 0.906250\n",
      "the loss is 0.483975 and the accuracy is 0.781250\n",
      "the loss is 0.501897 and the accuracy is 0.812500\n",
      "the loss is 0.280341 and the accuracy is 0.937500\n",
      "the loss is 0.242116 and the accuracy is 0.937500\n",
      "the loss is 0.221421 and the accuracy is 0.906250\n",
      "the loss is 0.242904 and the accuracy is 0.906250\n",
      "the loss is 0.297839 and the accuracy is 0.906250\n",
      "the loss is 0.445329 and the accuracy is 0.843750\n",
      "the loss is 0.419195 and the accuracy is 0.750000\n",
      "the loss is 0.331480 and the accuracy is 0.812500\n",
      "the loss is 0.438738 and the accuracy is 0.843750\n",
      "the loss is 0.334109 and the accuracy is 0.843750\n",
      "the loss is 0.249449 and the accuracy is 0.875000\n",
      "the loss is 0.397728 and the accuracy is 0.812500\n",
      "the loss is 0.336030 and the accuracy is 0.781250\n",
      "the loss is 0.300712 and the accuracy is 0.843750\n",
      "the loss is 0.174202 and the accuracy is 0.906250\n",
      "the loss is 0.578167 and the accuracy is 0.718750\n",
      "the loss is 0.261204 and the accuracy is 0.906250\n",
      "the loss is 0.241500 and the accuracy is 0.875000\n",
      "the loss is 0.431139 and the accuracy is 0.812500\n",
      "the loss is 0.237902 and the accuracy is 0.906250\n",
      "the loss is 0.244971 and the accuracy is 0.906250\n",
      "the loss is 0.317456 and the accuracy is 0.812500\n",
      "the loss is 0.348998 and the accuracy is 0.843750\n",
      "the loss is 0.084488 and the accuracy is 1.000000\n",
      "the loss is 0.192020 and the accuracy is 0.906250\n",
      "the loss is 0.393982 and the accuracy is 0.750000\n",
      "the loss is 0.223303 and the accuracy is 0.906250\n",
      "the loss is 0.366403 and the accuracy is 0.843750\n",
      "the loss is 0.405515 and the accuracy is 0.843750\n",
      "the loss is 0.252440 and the accuracy is 0.875000\n",
      "the loss is 0.345551 and the accuracy is 0.781250\n",
      "the loss is 0.237351 and the accuracy is 0.875000\n",
      "the loss is 0.299612 and the accuracy is 0.875000\n",
      "the loss is 0.458134 and the accuracy is 0.875000\n",
      "the loss is 0.241498 and the accuracy is 0.843750\n",
      "the loss is 0.286934 and the accuracy is 0.906250\n",
      "the loss is 0.154924 and the accuracy is 0.937500\n",
      "the loss is 0.362107 and the accuracy is 0.875000\n",
      "the loss is 0.240406 and the accuracy is 0.875000\n",
      "the loss is 0.244114 and the accuracy is 0.906250\n",
      "the loss is 0.398637 and the accuracy is 0.812500\n",
      "the loss is 0.336537 and the accuracy is 0.875000\n",
      "the loss is 0.532384 and the accuracy is 0.781250\n",
      "the loss is 0.235496 and the accuracy is 0.875000\n",
      "the loss is 0.233064 and the accuracy is 0.906250\n",
      "the loss is 0.387837 and the accuracy is 0.843750\n",
      "the loss is 0.116980 and the accuracy is 1.000000\n",
      "the loss is 0.244091 and the accuracy is 0.875000\n",
      "the loss is 0.334743 and the accuracy is 0.843750\n",
      "the loss is 0.479659 and the accuracy is 0.750000\n",
      "the loss is 0.257206 and the accuracy is 0.843750\n",
      "the loss is 0.215512 and the accuracy is 0.875000\n",
      "the loss is 0.310980 and the accuracy is 0.875000\n",
      "the loss is 0.403582 and the accuracy is 0.781250\n",
      "the loss is 0.275067 and the accuracy is 0.875000\n",
      "the loss is 0.504016 and the accuracy is 0.781250\n",
      "the loss is 0.419068 and the accuracy is 0.843750\n",
      "the loss is 0.283213 and the accuracy is 0.875000\n",
      "the loss is 0.302686 and the accuracy is 0.875000\n",
      "the loss is 0.175743 and the accuracy is 0.968750\n",
      "the loss is 0.355692 and the accuracy is 0.843750\n",
      "the loss is 0.256506 and the accuracy is 0.875000\n",
      "the loss is 0.162436 and the accuracy is 0.906250\n",
      "the loss is 0.294448 and the accuracy is 0.906250\n",
      "the loss is 0.301975 and the accuracy is 0.875000\n",
      "the loss is 0.341046 and the accuracy is 0.937500\n",
      "the loss is 0.541160 and the accuracy is 0.843750\n",
      "the loss is 0.231671 and the accuracy is 0.937500\n",
      "the loss is 0.239299 and the accuracy is 0.875000\n",
      "the loss is 0.222154 and the accuracy is 0.906250\n",
      "the loss is 0.476970 and the accuracy is 0.781250\n",
      "the loss is 0.282051 and the accuracy is 0.875000\n",
      "the loss is 0.225938 and the accuracy is 0.906250\n",
      "the loss is 0.345624 and the accuracy is 0.906250\n",
      "the loss is 0.384285 and the accuracy is 0.843750\n",
      "the loss is 0.264224 and the accuracy is 0.875000\n",
      "the loss is 0.213048 and the accuracy is 0.906250\n",
      "the loss is 0.384346 and the accuracy is 0.875000\n",
      "the loss is 0.296808 and the accuracy is 0.843750\n",
      "the loss is 0.199932 and the accuracy is 0.937500\n",
      "the loss is 0.314274 and the accuracy is 0.875000\n",
      "the loss is 0.364709 and the accuracy is 0.750000\n",
      "the loss is 0.330099 and the accuracy is 0.843750\n",
      "the loss is 0.197596 and the accuracy is 0.937500\n",
      "the loss is 0.158487 and the accuracy is 0.937500\n",
      "the loss is 0.228798 and the accuracy is 0.875000\n",
      "the loss is 0.417360 and the accuracy is 0.812500\n",
      "the loss is 0.273357 and the accuracy is 0.875000\n",
      "the loss is 0.227892 and the accuracy is 0.937500\n",
      "the loss is 0.259906 and the accuracy is 0.875000\n",
      "the loss is 0.360013 and the accuracy is 0.812500\n",
      "the loss is 0.250168 and the accuracy is 0.875000\n",
      "the loss is 0.171403 and the accuracy is 0.937500\n",
      "the loss is 0.298606 and the accuracy is 0.812500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.244935 and the accuracy is 0.875000\n",
      "the loss is 0.354229 and the accuracy is 0.875000\n",
      "the loss is 0.197051 and the accuracy is 0.875000\n",
      "the loss is 0.330413 and the accuracy is 0.843750\n",
      "the loss is 0.331459 and the accuracy is 0.875000\n",
      "the loss is 0.326534 and the accuracy is 0.812500\n",
      "the loss is 0.387134 and the accuracy is 0.875000\n",
      "the loss is 0.277977 and the accuracy is 0.875000\n",
      "the loss is 0.285085 and the accuracy is 0.843750\n",
      "the loss is 0.310230 and the accuracy is 0.875000\n",
      "the loss is 0.359064 and the accuracy is 0.843750\n",
      "the loss is 0.393494 and the accuracy is 0.812500\n",
      "the loss is 0.345414 and the accuracy is 0.906250\n",
      "the loss is 0.225009 and the accuracy is 0.937500\n",
      "the loss is 0.322793 and the accuracy is 0.843750\n",
      "the loss is 0.440421 and the accuracy is 0.875000\n",
      "the loss is 0.257104 and the accuracy is 0.906250\n",
      "the loss is 0.202565 and the accuracy is 0.906250\n",
      "the loss is 0.438981 and the accuracy is 0.781250\n",
      "the loss is 0.268514 and the accuracy is 0.906250\n",
      "the loss is 0.240682 and the accuracy is 0.875000\n",
      "the loss is 0.323536 and the accuracy is 0.875000\n",
      "the loss is 0.234503 and the accuracy is 0.906250\n",
      "the loss is 0.274999 and the accuracy is 0.875000\n",
      "the loss is 0.443111 and the accuracy is 0.875000\n",
      "the loss is 0.436304 and the accuracy is 0.843750\n",
      "the loss is 0.249390 and the accuracy is 0.906250\n",
      "the loss is 0.428348 and the accuracy is 0.750000\n",
      "the loss is 0.308242 and the accuracy is 0.906250\n",
      "the loss is 0.363766 and the accuracy is 0.812500\n",
      "the loss is 0.260073 and the accuracy is 0.906250\n",
      "the loss is 0.191256 and the accuracy is 0.937500\n",
      "the loss is 0.375982 and the accuracy is 0.843750\n",
      "the loss is 0.337109 and the accuracy is 0.906250\n",
      "the loss is 0.367944 and the accuracy is 0.750000\n",
      "the loss is 0.146689 and the accuracy is 0.968750\n",
      "the loss is 0.466739 and the accuracy is 0.781250\n",
      "the loss is 0.262886 and the accuracy is 0.843750\n",
      "the loss is 0.238139 and the accuracy is 0.875000\n",
      "the loss is 0.181246 and the accuracy is 0.937500\n",
      "the loss is 0.277337 and the accuracy is 0.875000\n",
      "the loss is 0.346194 and the accuracy is 0.906250\n",
      "the loss is 0.298869 and the accuracy is 0.875000\n",
      "the loss is 0.202649 and the accuracy is 0.906250\n",
      "the loss is 0.212690 and the accuracy is 0.937500\n",
      "the loss is 0.236170 and the accuracy is 0.906250\n",
      "the loss is 0.307252 and the accuracy is 0.781250\n",
      "the loss is 0.428124 and the accuracy is 0.718750\n",
      "the loss is 0.195620 and the accuracy is 0.906250\n",
      "the loss is 0.370186 and the accuracy is 0.843750\n",
      "the loss is 0.447805 and the accuracy is 0.781250\n",
      "the loss is 0.209286 and the accuracy is 0.906250\n",
      "the loss is 0.267327 and the accuracy is 0.906250\n",
      "the loss is 0.543266 and the accuracy is 0.656250\n",
      "the loss is 0.222773 and the accuracy is 0.937500\n",
      "the loss is 0.440373 and the accuracy is 0.781250\n",
      "the loss is 0.444952 and the accuracy is 0.781250\n",
      "the loss is 0.247566 and the accuracy is 0.937500\n",
      "the loss is 0.304105 and the accuracy is 0.812500\n",
      "the loss is 0.214412 and the accuracy is 0.906250\n",
      "the loss is 0.273149 and the accuracy is 0.875000\n",
      "the loss is 0.191804 and the accuracy is 0.937500\n",
      "the loss is 0.269317 and the accuracy is 0.906250\n",
      "the loss is 0.265388 and the accuracy is 0.875000\n",
      "the loss is 0.304184 and the accuracy is 0.906250\n",
      "the loss is 0.265556 and the accuracy is 0.875000\n",
      "the loss is 0.209430 and the accuracy is 0.875000\n",
      "the loss is 0.098972 and the accuracy is 1.000000\n",
      "the loss is 0.148568 and the accuracy is 0.937500\n",
      "the loss is 0.252572 and the accuracy is 0.968750\n",
      "the loss is 0.268600 and the accuracy is 0.875000\n",
      "the loss is 0.170200 and the accuracy is 0.968750\n",
      "the loss is 0.219530 and the accuracy is 0.937500\n",
      "the loss is 0.215453 and the accuracy is 0.875000\n",
      "the loss is 0.391036 and the accuracy is 0.875000\n",
      "the loss is 0.377699 and the accuracy is 0.781250\n",
      "the loss is 0.211409 and the accuracy is 0.906250\n",
      "the loss is 0.283744 and the accuracy is 0.843750\n",
      "the loss is 0.169805 and the accuracy is 0.906250\n",
      "the loss is 0.246689 and the accuracy is 0.875000\n",
      "the loss is 0.166502 and the accuracy is 0.875000\n",
      "the loss is 0.339244 and the accuracy is 0.843750\n",
      "the loss is 0.664673 and the accuracy is 0.781250\n",
      "the loss is 0.411769 and the accuracy is 0.781250\n",
      "the loss is 0.274904 and the accuracy is 0.906250\n",
      "the loss is 0.174036 and the accuracy is 0.906250\n",
      "the loss is 0.188587 and the accuracy is 0.968750\n",
      "the loss is 0.409011 and the accuracy is 0.812500\n",
      "the loss is 0.185270 and the accuracy is 0.875000\n",
      "the loss is 0.453181 and the accuracy is 0.843750\n",
      "the loss is 0.291274 and the accuracy is 0.875000\n",
      "the loss is 0.248253 and the accuracy is 0.843750\n",
      "the loss is 0.382088 and the accuracy is 0.875000\n",
      "the loss is 0.221803 and the accuracy is 0.937500\n",
      "the loss is 0.219544 and the accuracy is 0.843750\n",
      "the loss is 0.348193 and the accuracy is 0.843750\n",
      "the loss is 0.150588 and the accuracy is 0.906250\n",
      "the loss is 0.267465 and the accuracy is 0.875000\n",
      "the loss is 0.191703 and the accuracy is 0.937500\n",
      "the loss is 0.257167 and the accuracy is 0.812500\n",
      "the loss is 0.446065 and the accuracy is 0.812500\n",
      "the loss is 0.286531 and the accuracy is 0.843750\n",
      "the loss is 0.198546 and the accuracy is 0.875000\n",
      "the loss is 0.232984 and the accuracy is 0.906250\n",
      "the loss is 0.300247 and the accuracy is 0.875000\n",
      "the loss is 0.210928 and the accuracy is 0.875000\n",
      "the loss is 0.419820 and the accuracy is 0.750000\n",
      "the loss is 0.300081 and the accuracy is 0.843750\n",
      "the loss is 0.376306 and the accuracy is 0.781250\n",
      "the loss is 0.233246 and the accuracy is 0.875000\n",
      "the loss is 0.260833 and the accuracy is 0.875000\n",
      "the loss is 0.244972 and the accuracy is 0.906250\n",
      "the loss is 0.221055 and the accuracy is 0.937500\n",
      "the loss is 0.270644 and the accuracy is 0.906250\n",
      "the loss is 0.572869 and the accuracy is 0.750000\n",
      "the loss is 0.137064 and the accuracy is 0.937500\n",
      "the loss is 0.277664 and the accuracy is 0.875000\n",
      "the loss is 0.193724 and the accuracy is 0.968750\n",
      "the loss is 0.336681 and the accuracy is 0.843750\n",
      "the loss is 0.359471 and the accuracy is 0.875000\n",
      "the loss is 0.180842 and the accuracy is 0.906250\n",
      "the loss is 0.385686 and the accuracy is 0.875000\n",
      "the loss is 0.311945 and the accuracy is 0.875000\n",
      "the loss is 0.369229 and the accuracy is 0.843750\n",
      "the loss is 0.175203 and the accuracy is 0.968750\n",
      "the loss is 0.228100 and the accuracy is 0.906250\n",
      "the loss is 0.379181 and the accuracy is 0.906250\n",
      "the loss is 0.265654 and the accuracy is 0.843750\n",
      "the loss is 0.215162 and the accuracy is 0.906250\n",
      "the loss is 0.326918 and the accuracy is 0.812500\n",
      "the loss is 0.358572 and the accuracy is 0.812500\n",
      "the loss is 0.300068 and the accuracy is 0.875000\n",
      "the loss is 0.232670 and the accuracy is 0.875000\n",
      "the loss is 0.181970 and the accuracy is 0.937500\n",
      "the loss is 0.371949 and the accuracy is 0.875000\n",
      "the loss is 0.370919 and the accuracy is 0.875000\n",
      "the loss is 0.321234 and the accuracy is 0.843750\n",
      "the loss is 0.191562 and the accuracy is 0.937500\n",
      "the loss is 0.206184 and the accuracy is 0.906250\n",
      "the loss is 0.172530 and the accuracy is 0.937500\n",
      "the loss is 0.157504 and the accuracy is 0.906250\n",
      "the loss is 0.428055 and the accuracy is 0.843750\n",
      "the loss is 0.434606 and the accuracy is 0.812500\n",
      "the loss is 0.229033 and the accuracy is 0.937500\n",
      "the loss is 0.231499 and the accuracy is 0.906250\n",
      "the loss is 0.416302 and the accuracy is 0.843750\n",
      "the loss is 0.255354 and the accuracy is 0.875000\n",
      "the loss is 0.736323 and the accuracy is 0.750000\n",
      "the loss is 0.416375 and the accuracy is 0.750000\n",
      "the loss is 0.263970 and the accuracy is 0.906250\n",
      "the loss is 0.321133 and the accuracy is 0.875000\n",
      "the loss is 0.257630 and the accuracy is 0.937500\n",
      "the loss is 0.309970 and the accuracy is 0.812500\n",
      "the loss is 0.300517 and the accuracy is 0.843750\n",
      "the loss is 0.224371 and the accuracy is 0.906250\n",
      "the loss is 0.278117 and the accuracy is 0.843750\n",
      "the loss is 0.269911 and the accuracy is 0.875000\n",
      "the loss is 0.321833 and the accuracy is 0.875000\n",
      "the loss is 0.168945 and the accuracy is 0.937500\n",
      "the loss is 0.214956 and the accuracy is 0.906250\n",
      "the loss is 0.204178 and the accuracy is 0.906250\n",
      "the loss is 0.419178 and the accuracy is 0.843750\n",
      "the loss is 0.546217 and the accuracy is 0.843750\n",
      "the loss is 0.100817 and the accuracy is 1.000000\n",
      "the loss is 0.245907 and the accuracy is 0.937500\n",
      "the loss is 0.130187 and the accuracy is 0.968750\n",
      "the loss is 0.360855 and the accuracy is 0.781250\n",
      "the loss is 0.147681 and the accuracy is 0.937500\n",
      "the loss is 0.283499 and the accuracy is 0.875000\n",
      "the loss is 0.343984 and the accuracy is 0.812500\n",
      "the loss is 0.239593 and the accuracy is 0.937500\n",
      "the loss is 0.245505 and the accuracy is 0.875000\n",
      "the loss is 0.427208 and the accuracy is 0.750000\n",
      "the loss is 0.258093 and the accuracy is 0.906250\n",
      "the loss is 0.300702 and the accuracy is 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.334268 and the accuracy is 0.875000\n",
      "the loss is 0.251766 and the accuracy is 0.843750\n",
      "the loss is 0.237435 and the accuracy is 0.906250\n",
      "the loss is 0.140713 and the accuracy is 0.937500\n",
      "the loss is 0.310258 and the accuracy is 0.843750\n",
      "the loss is 0.246717 and the accuracy is 0.875000\n",
      "the loss is 0.356962 and the accuracy is 0.750000\n",
      "the loss is 0.407652 and the accuracy is 0.781250\n",
      "the loss is 0.345997 and the accuracy is 0.843750\n",
      "the loss is 0.330447 and the accuracy is 0.875000\n",
      "the loss is 0.265062 and the accuracy is 0.906250\n",
      "the loss is 0.206917 and the accuracy is 0.937500\n",
      "the loss is 0.349836 and the accuracy is 0.906250\n",
      "the loss is 0.305942 and the accuracy is 0.843750\n",
      "the loss is 0.531654 and the accuracy is 0.781250\n",
      "the loss is 0.310182 and the accuracy is 0.937500\n",
      "the loss is 0.210728 and the accuracy is 0.906250\n",
      "the loss is 0.239447 and the accuracy is 0.906250\n",
      "the loss is 0.303379 and the accuracy is 0.875000\n",
      "the loss is 0.304574 and the accuracy is 0.843750\n",
      "the loss is 0.255412 and the accuracy is 0.875000\n",
      "the loss is 0.436031 and the accuracy is 0.781250\n",
      "the loss is 0.257350 and the accuracy is 0.906250\n",
      "the loss is 0.494890 and the accuracy is 0.718750\n",
      "the loss is 0.141655 and the accuracy is 0.937500\n",
      "the loss is 0.339911 and the accuracy is 0.843750\n",
      "the loss is 0.272574 and the accuracy is 0.906250\n",
      "the loss is 0.277865 and the accuracy is 0.906250\n",
      "the loss is 0.287840 and the accuracy is 0.906250\n",
      "the loss is 0.242384 and the accuracy is 0.875000\n",
      "the loss is 0.280146 and the accuracy is 0.875000\n",
      "the loss is 0.197635 and the accuracy is 0.937500\n",
      "the loss is 0.333597 and the accuracy is 0.906250\n",
      "the loss is 0.325774 and the accuracy is 0.906250\n",
      "the loss is 0.229694 and the accuracy is 0.906250\n",
      "the loss is 0.241621 and the accuracy is 0.937500\n",
      "the loss is 0.193318 and the accuracy is 0.906250\n",
      "the loss is 0.433038 and the accuracy is 0.812500\n",
      "the loss is 0.298815 and the accuracy is 0.843750\n",
      "the loss is 0.249203 and the accuracy is 0.875000\n",
      "the loss is 0.212770 and the accuracy is 0.875000\n",
      "the loss is 0.369763 and the accuracy is 0.812500\n",
      "the loss is 0.383785 and the accuracy is 0.906250\n",
      "the loss is 0.183021 and the accuracy is 0.906250\n",
      "the loss is 0.217919 and the accuracy is 0.906250\n",
      "the loss is 0.441162 and the accuracy is 0.718750\n",
      "the loss is 0.358148 and the accuracy is 0.812500\n",
      "the loss is 0.140353 and the accuracy is 0.968750\n",
      "the loss is 0.463817 and the accuracy is 0.812500\n",
      "the loss is 0.311098 and the accuracy is 0.843750\n",
      "the loss is 0.556866 and the accuracy is 0.718750\n",
      "the loss is 0.242940 and the accuracy is 0.875000\n",
      "the loss is 0.245512 and the accuracy is 0.937500\n",
      "the loss is 0.173829 and the accuracy is 0.906250\n",
      "the loss is 0.335911 and the accuracy is 0.843750\n",
      "the loss is 0.274040 and the accuracy is 0.875000\n",
      "the loss is 0.481428 and the accuracy is 0.781250\n",
      "the loss is 0.415847 and the accuracy is 0.781250\n",
      "the loss is 0.428669 and the accuracy is 0.906250\n",
      "the loss is 0.188193 and the accuracy is 0.906250\n",
      "the loss is 0.180352 and the accuracy is 0.968750\n",
      "the loss is 0.387680 and the accuracy is 0.812500\n",
      "the loss is 0.206728 and the accuracy is 0.906250\n",
      "the loss is 0.193171 and the accuracy is 0.843750\n",
      "the loss is 0.332622 and the accuracy is 0.843750\n",
      "the loss is 0.334137 and the accuracy is 0.781250\n",
      "the loss is 0.164424 and the accuracy is 0.937500\n",
      "the loss is 0.276403 and the accuracy is 0.875000\n",
      "the loss is 0.220529 and the accuracy is 0.875000\n",
      "the loss is 0.201125 and the accuracy is 0.875000\n",
      "the loss is 0.148475 and the accuracy is 0.937500\n",
      "the loss is 0.324338 and the accuracy is 0.812500\n",
      "the loss is 0.362169 and the accuracy is 0.812500\n",
      "the loss is 0.287393 and the accuracy is 0.843750\n",
      "the loss is 0.267530 and the accuracy is 0.875000\n",
      "the loss is 0.286617 and the accuracy is 0.875000\n",
      "the loss is 0.402609 and the accuracy is 0.812500\n",
      "the loss is 0.224340 and the accuracy is 0.906250\n",
      "the loss is 0.250139 and the accuracy is 0.906250\n",
      "the loss is 0.329819 and the accuracy is 0.875000\n",
      "the loss is 0.354285 and the accuracy is 0.906250\n",
      "the loss is 0.313498 and the accuracy is 0.843750\n",
      "the loss is 0.227756 and the accuracy is 0.906250\n",
      "the loss is 0.187187 and the accuracy is 0.937500\n",
      "the loss is 0.446304 and the accuracy is 0.781250\n",
      "the loss is 0.700694 and the accuracy is 0.750000\n",
      "the loss is 0.351165 and the accuracy is 0.875000\n",
      "the loss is 0.347366 and the accuracy is 0.875000\n",
      "the loss is 0.148841 and the accuracy is 1.000000\n",
      "the loss is 0.286323 and the accuracy is 0.875000\n",
      "the loss is 0.456768 and the accuracy is 0.781250\n",
      "the loss is 0.228381 and the accuracy is 0.875000\n",
      "the loss is 0.352553 and the accuracy is 0.875000\n",
      "the loss is 0.529029 and the accuracy is 0.718750\n",
      "the loss is 0.481974 and the accuracy is 0.781250\n",
      "the loss is 0.245824 and the accuracy is 0.906250\n",
      "the loss is 0.298088 and the accuracy is 0.812500\n",
      "the loss is 0.277257 and the accuracy is 0.875000\n",
      "the loss is 0.210311 and the accuracy is 0.937500\n",
      "the loss is 0.161207 and the accuracy is 0.968750\n",
      "the loss is 0.216553 and the accuracy is 0.906250\n",
      "the loss is 0.501447 and the accuracy is 0.812500\n",
      "the loss is 0.201203 and the accuracy is 0.968750\n",
      "the loss is 0.199607 and the accuracy is 0.906250\n",
      "the loss is 0.380539 and the accuracy is 0.812500\n",
      "the loss is 0.317142 and the accuracy is 0.843750\n",
      "the loss is 0.229961 and the accuracy is 0.875000\n",
      "the loss is 0.208821 and the accuracy is 0.968750\n",
      "the loss is 0.170017 and the accuracy is 0.937500\n",
      "the loss is 0.230269 and the accuracy is 0.937500\n",
      "the loss is 0.397129 and the accuracy is 0.812500\n",
      "the loss is 0.417112 and the accuracy is 0.875000\n",
      "the loss is 0.307756 and the accuracy is 0.875000\n",
      "the loss is 0.321146 and the accuracy is 0.843750\n",
      "the loss is 0.229701 and the accuracy is 0.906250\n",
      "the loss is 0.156509 and the accuracy is 0.906250\n",
      "the loss is 0.169722 and the accuracy is 0.937500\n",
      "the loss is 0.293850 and the accuracy is 0.937500\n",
      "the loss is 0.208096 and the accuracy is 0.875000\n",
      "the loss is 0.186805 and the accuracy is 0.968750\n",
      "the loss is 0.372341 and the accuracy is 0.843750\n",
      "the loss is 0.278555 and the accuracy is 0.875000\n",
      "the loss is 0.533336 and the accuracy is 0.812500\n",
      "the loss is 0.191888 and the accuracy is 0.937500\n",
      "the loss is 0.362335 and the accuracy is 0.843750\n",
      "the loss is 0.159058 and the accuracy is 0.906250\n",
      "the loss is 0.344628 and the accuracy is 0.875000\n",
      "the loss is 0.276318 and the accuracy is 0.906250\n",
      "the loss is 0.332606 and the accuracy is 0.812500\n",
      "the loss is 0.409489 and the accuracy is 0.843750\n",
      "the loss is 0.200123 and the accuracy is 0.906250\n",
      "the loss is 0.285086 and the accuracy is 0.906250\n",
      "the loss is 0.307541 and the accuracy is 0.875000\n",
      "the loss is 0.282713 and the accuracy is 0.843750\n",
      "the loss is 0.327774 and the accuracy is 0.843750\n",
      "the loss is 0.192284 and the accuracy is 0.968750\n",
      "the loss is 0.227849 and the accuracy is 0.906250\n",
      "the loss is 0.359971 and the accuracy is 0.906250\n",
      "the loss is 0.218497 and the accuracy is 0.875000\n",
      "the loss is 0.288410 and the accuracy is 0.812500\n",
      "the loss is 0.249332 and the accuracy is 0.875000\n",
      "the loss is 0.247939 and the accuracy is 0.875000\n",
      "the loss is 0.263471 and the accuracy is 0.843750\n",
      "the loss is 0.616565 and the accuracy is 0.687500\n",
      "the loss is 0.196170 and the accuracy is 0.968750\n",
      "the loss is 0.418605 and the accuracy is 0.843750\n",
      "the loss is 0.313134 and the accuracy is 0.843750\n",
      "the loss is 0.416597 and the accuracy is 0.812500\n",
      "the loss is 0.315495 and the accuracy is 0.843750\n",
      "the loss is 0.192951 and the accuracy is 0.937500\n",
      "the loss is 0.144252 and the accuracy is 0.937500\n",
      "the loss is 0.304296 and the accuracy is 0.937500\n",
      "the loss is 0.269553 and the accuracy is 0.906250\n",
      "the loss is 0.157071 and the accuracy is 0.968750\n",
      "the loss is 0.296967 and the accuracy is 0.906250\n",
      "the loss is 0.239629 and the accuracy is 0.875000\n",
      "the loss is 0.342007 and the accuracy is 0.843750\n",
      "the loss is 0.401022 and the accuracy is 0.781250\n",
      "the loss is 0.270747 and the accuracy is 0.875000\n",
      "the loss is 0.208624 and the accuracy is 0.906250\n",
      "the loss is 0.188822 and the accuracy is 0.937500\n",
      "the loss is 0.287243 and the accuracy is 0.875000\n",
      "the loss is 0.196989 and the accuracy is 0.937500\n",
      "the loss is 0.287562 and the accuracy is 0.843750\n",
      "the loss is 0.245125 and the accuracy is 0.875000\n",
      "the loss is 0.230002 and the accuracy is 0.906250\n",
      "the loss is 0.461386 and the accuracy is 0.750000\n",
      "the loss is 0.221484 and the accuracy is 0.875000\n",
      "the loss is 0.380161 and the accuracy is 0.812500\n",
      "the loss is 0.533667 and the accuracy is 0.750000\n",
      "the loss is 0.195984 and the accuracy is 0.937500\n",
      "the loss is 0.158797 and the accuracy is 0.968750\n",
      "the loss is 0.360991 and the accuracy is 0.843750\n",
      "the loss is 0.252131 and the accuracy is 0.906250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.275609 and the accuracy is 0.843750\n",
      "the loss is 0.350517 and the accuracy is 0.812500\n",
      "the loss is 0.288205 and the accuracy is 0.875000\n",
      "the loss is 0.287565 and the accuracy is 0.843750\n",
      "the loss is 0.373052 and the accuracy is 0.843750\n",
      "the loss is 0.303226 and the accuracy is 0.781250\n",
      "the loss is 0.217268 and the accuracy is 0.906250\n",
      "the loss is 0.393538 and the accuracy is 0.843750\n",
      "the loss is 0.317952 and the accuracy is 0.843750\n",
      "the loss is 0.320880 and the accuracy is 0.812500\n",
      "the loss is 0.403589 and the accuracy is 0.906250\n",
      "the loss is 0.304029 and the accuracy is 0.843750\n",
      "the loss is 0.406244 and the accuracy is 0.843750\n",
      "the loss is 0.186580 and the accuracy is 0.968750\n",
      "the loss is 0.205703 and the accuracy is 0.906250\n",
      "the loss is 0.276897 and the accuracy is 0.906250\n",
      "the loss is 0.225439 and the accuracy is 0.937500\n",
      "the loss is 0.304076 and the accuracy is 0.906250\n",
      "the loss is 0.210379 and the accuracy is 0.906250\n",
      "the loss is 0.193559 and the accuracy is 0.843750\n",
      "the loss is 0.313751 and the accuracy is 0.875000\n",
      "the loss is 0.169928 and the accuracy is 0.968750\n",
      "the loss is 0.350184 and the accuracy is 0.812500\n",
      "the loss is 0.396965 and the accuracy is 0.843750\n",
      "the loss is 0.194844 and the accuracy is 0.875000\n",
      "the loss is 0.227429 and the accuracy is 0.875000\n",
      "the loss is 0.303990 and the accuracy is 0.875000\n",
      "the loss is 0.338857 and the accuracy is 0.781250\n",
      "the loss is 0.344820 and the accuracy is 0.812500\n",
      "the loss is 0.207267 and the accuracy is 0.906250\n",
      "the loss is 0.314019 and the accuracy is 0.843750\n",
      "the loss is 0.411267 and the accuracy is 0.843750\n",
      "the loss is 0.389373 and the accuracy is 0.781250\n",
      "the loss is 0.289179 and the accuracy is 0.812500\n",
      "the loss is 0.321218 and the accuracy is 0.906250\n",
      "the loss is 0.291206 and the accuracy is 0.843750\n",
      "the loss is 0.182308 and the accuracy is 0.937500\n",
      "the loss is 0.157880 and the accuracy is 0.968750\n",
      "the loss is 0.296517 and the accuracy is 0.812500\n",
      "the loss is 0.277563 and the accuracy is 0.875000\n",
      "the loss is 0.329489 and the accuracy is 0.875000\n",
      "the loss is 0.276109 and the accuracy is 0.875000\n",
      "the loss is 0.081374 and the accuracy is 1.000000\n",
      "the loss is 0.348731 and the accuracy is 0.875000\n",
      "the loss is 0.293134 and the accuracy is 0.812500\n",
      "the loss is 0.266978 and the accuracy is 0.875000\n",
      "the loss is 0.425096 and the accuracy is 0.812500\n",
      "the loss is 0.303875 and the accuracy is 0.875000\n",
      "the loss is 0.202658 and the accuracy is 0.875000\n",
      "the loss is 0.134390 and the accuracy is 0.968750\n",
      "the loss is 0.150669 and the accuracy is 0.937500\n",
      "the loss is 0.336024 and the accuracy is 0.906250\n",
      "the loss is 0.379126 and the accuracy is 0.875000\n",
      "the loss is 0.280283 and the accuracy is 0.906250\n",
      "the loss is 0.446544 and the accuracy is 0.812500\n",
      "the loss is 0.397408 and the accuracy is 0.875000\n",
      "the loss is 0.282500 and the accuracy is 0.875000\n",
      "the loss is 0.258812 and the accuracy is 0.843750\n",
      "the loss is 0.268787 and the accuracy is 0.875000\n",
      "the loss is 0.322729 and the accuracy is 0.906250\n",
      "the loss is 0.276640 and the accuracy is 0.906250\n",
      "the loss is 0.258329 and the accuracy is 0.906250\n",
      "the loss is 0.371670 and the accuracy is 0.875000\n",
      "the loss is 0.621994 and the accuracy is 0.750000\n",
      "the loss is 0.251276 and the accuracy is 0.906250\n",
      "the loss is 0.345752 and the accuracy is 0.843750\n",
      "the loss is 0.236245 and the accuracy is 0.875000\n",
      "the loss is 0.203618 and the accuracy is 0.937500\n",
      "the loss is 0.239161 and the accuracy is 0.812500\n",
      "the loss is 0.172281 and the accuracy is 0.906250\n",
      "the loss is 0.303955 and the accuracy is 0.937500\n",
      "the loss is 0.540392 and the accuracy is 0.781250\n",
      "the loss is 0.298593 and the accuracy is 0.906250\n",
      "the loss is 0.294310 and the accuracy is 0.875000\n",
      "the loss is 0.420481 and the accuracy is 0.812500\n",
      "the loss is 0.275962 and the accuracy is 0.875000\n",
      "the loss is 0.374790 and the accuracy is 0.906250\n",
      "the loss is 0.468995 and the accuracy is 0.812500\n",
      "the loss is 0.279157 and the accuracy is 0.875000\n",
      "the loss is 0.138979 and the accuracy is 0.906250\n",
      "the loss is 0.304686 and the accuracy is 0.875000\n",
      "the loss is 0.375908 and the accuracy is 0.906250\n",
      "the loss is 0.329492 and the accuracy is 0.812500\n",
      "the loss is 0.200549 and the accuracy is 0.843750\n",
      "the loss is 0.230667 and the accuracy is 0.968750\n",
      "the loss is 0.305274 and the accuracy is 0.906250\n",
      "the loss is 0.243910 and the accuracy is 0.937500\n",
      "the loss is 0.344246 and the accuracy is 0.843750\n",
      "the loss is 0.505016 and the accuracy is 0.750000\n",
      "the loss is 0.470428 and the accuracy is 0.843750\n",
      "the loss is 0.230856 and the accuracy is 0.906250\n",
      "the loss is 0.299779 and the accuracy is 0.875000\n",
      "the loss is 0.169206 and the accuracy is 0.968750\n",
      "the loss is 0.337352 and the accuracy is 0.812500\n",
      "the loss is 0.126098 and the accuracy is 0.937500\n",
      "the loss is 0.330255 and the accuracy is 0.843750\n",
      "the loss is 0.298285 and the accuracy is 0.812500\n",
      "the loss is 0.242175 and the accuracy is 0.906250\n",
      "the loss is 0.194727 and the accuracy is 0.937500\n",
      "the loss is 0.435895 and the accuracy is 0.781250\n",
      "the loss is 0.258564 and the accuracy is 0.843750\n",
      "the loss is 0.353539 and the accuracy is 0.843750\n",
      "the loss is 0.320234 and the accuracy is 0.843750\n",
      "the loss is 0.151871 and the accuracy is 1.000000\n",
      "the loss is 0.382598 and the accuracy is 0.812500\n",
      "the loss is 0.143455 and the accuracy is 0.968750\n",
      "the loss is 0.168021 and the accuracy is 0.968750\n",
      "the loss is 0.175726 and the accuracy is 0.937500\n",
      "the loss is 0.273270 and the accuracy is 0.906250\n",
      "the loss is 0.257966 and the accuracy is 0.906250\n",
      "the loss is 0.330094 and the accuracy is 0.812500\n",
      "the loss is 0.167025 and the accuracy is 0.937500\n",
      "the loss is 0.183411 and the accuracy is 0.906250\n",
      "the loss is 0.581318 and the accuracy is 0.656250\n",
      "the loss is 0.237316 and the accuracy is 0.906250\n",
      "the loss is 0.271533 and the accuracy is 0.906250\n",
      "the loss is 0.366296 and the accuracy is 0.781250\n",
      "the loss is 0.370787 and the accuracy is 0.812500\n",
      "the loss is 0.300403 and the accuracy is 0.875000\n",
      "the loss is 0.325107 and the accuracy is 0.875000\n",
      "the loss is 0.248746 and the accuracy is 0.906250\n",
      "the loss is 0.270436 and the accuracy is 0.875000\n",
      "the loss is 0.137022 and the accuracy is 0.968750\n",
      "the loss is 0.284729 and the accuracy is 0.843750\n",
      "the loss is 0.474394 and the accuracy is 0.750000\n",
      "the loss is 0.267035 and the accuracy is 0.906250\n",
      "the loss is 0.275053 and the accuracy is 0.875000\n",
      "the loss is 0.430335 and the accuracy is 0.812500\n",
      "the loss is 0.297415 and the accuracy is 0.812500\n",
      "the loss is 0.302547 and the accuracy is 0.875000\n",
      "the loss is 0.306674 and the accuracy is 0.875000\n",
      "the loss is 0.266106 and the accuracy is 0.937500\n",
      "the loss is 0.179170 and the accuracy is 0.906250\n",
      "the loss is 0.357771 and the accuracy is 0.843750\n",
      "the loss is 0.323006 and the accuracy is 0.906250\n",
      "the loss is 0.234334 and the accuracy is 0.875000\n",
      "the loss is 0.552512 and the accuracy is 0.687500\n",
      "the loss is 0.362211 and the accuracy is 0.812500\n",
      "the loss is 0.196269 and the accuracy is 0.906250\n",
      "the loss is 0.205371 and the accuracy is 0.906250\n",
      "the loss is 0.359637 and the accuracy is 0.812500\n",
      "the loss is 0.348137 and the accuracy is 0.781250\n",
      "the loss is 0.320124 and the accuracy is 0.875000\n",
      "the loss is 0.279968 and the accuracy is 0.843750\n",
      "the loss is 0.169712 and the accuracy is 0.937500\n",
      "the loss is 0.348897 and the accuracy is 0.843750\n",
      "the loss is 0.231455 and the accuracy is 0.906250\n",
      "the loss is 0.360930 and the accuracy is 0.843750\n",
      "the loss is 0.239952 and the accuracy is 0.875000\n",
      "the loss is 0.325027 and the accuracy is 0.937500\n",
      "the loss is 0.160376 and the accuracy is 1.000000\n",
      "the loss is 0.300324 and the accuracy is 0.906250\n",
      "the loss is 0.194430 and the accuracy is 0.937500\n",
      "the loss is 0.424659 and the accuracy is 0.781250\n",
      "the loss is 0.344919 and the accuracy is 0.812500\n",
      "the loss is 0.101618 and the accuracy is 0.968750\n",
      "the loss is 0.177902 and the accuracy is 0.937500\n",
      "the loss is 0.306032 and the accuracy is 0.906250\n",
      "the loss is 0.324649 and the accuracy is 0.843750\n",
      "the loss is 0.484292 and the accuracy is 0.843750\n",
      "the loss is 0.548398 and the accuracy is 0.750000\n",
      "the loss is 0.319268 and the accuracy is 0.843750\n",
      "the loss is 0.284822 and the accuracy is 0.843750\n",
      "the loss is 0.256271 and the accuracy is 0.875000\n",
      "the loss is 0.246473 and the accuracy is 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.211977 and the accuracy is 0.875000\n",
      "the loss is 0.435070 and the accuracy is 0.781250\n",
      "the loss is 0.287151 and the accuracy is 0.875000\n",
      "the loss is 0.305585 and the accuracy is 0.875000\n",
      "the loss is 0.174543 and the accuracy is 0.937500\n",
      "the loss is 0.194193 and the accuracy is 0.937500\n",
      "the loss is 0.323530 and the accuracy is 0.843750\n",
      "the loss is 0.390204 and the accuracy is 0.875000\n",
      "the loss is 0.293795 and the accuracy is 0.875000\n",
      "the loss is 0.393265 and the accuracy is 0.843750\n",
      "the loss is 0.245816 and the accuracy is 0.843750\n",
      "the loss is 0.293629 and the accuracy is 0.812500\n",
      "the loss is 0.252605 and the accuracy is 0.937500\n",
      "the loss is 0.206394 and the accuracy is 0.906250\n",
      "the loss is 0.332581 and the accuracy is 0.843750\n",
      "the loss is 0.354538 and the accuracy is 0.875000\n",
      "the loss is 0.358874 and the accuracy is 0.843750\n",
      "the loss is 0.189990 and the accuracy is 0.906250\n",
      "the loss is 0.200371 and the accuracy is 0.906250\n",
      "the loss is 0.335292 and the accuracy is 0.843750\n",
      "the loss is 0.121188 and the accuracy is 0.937500\n",
      "the loss is 0.306807 and the accuracy is 0.875000\n",
      "the loss is 0.292108 and the accuracy is 0.906250\n",
      "the loss is 0.111852 and the accuracy is 1.000000\n",
      "the loss is 0.230399 and the accuracy is 0.937500\n",
      "the loss is 0.292601 and the accuracy is 0.843750\n",
      "the loss is 0.450339 and the accuracy is 0.843750\n",
      "the loss is 0.389042 and the accuracy is 0.812500\n",
      "the loss is 0.304954 and the accuracy is 0.843750\n",
      "the loss is 0.319057 and the accuracy is 0.875000\n",
      "the loss is 0.284783 and the accuracy is 0.843750\n",
      "the loss is 0.415567 and the accuracy is 0.843750\n",
      "the loss is 0.430011 and the accuracy is 0.875000\n",
      "the loss is 0.306810 and the accuracy is 0.875000\n",
      "the loss is 0.355697 and the accuracy is 0.812500\n",
      "the loss is 0.447554 and the accuracy is 0.843750\n",
      "the loss is 0.158397 and the accuracy is 0.937500\n",
      "the loss is 0.282450 and the accuracy is 0.843750\n",
      "the loss is 0.400667 and the accuracy is 0.875000\n",
      "the loss is 0.193688 and the accuracy is 0.937500\n",
      "the loss is 0.195603 and the accuracy is 0.906250\n",
      "the loss is 0.378597 and the accuracy is 0.812500\n",
      "the loss is 0.160497 and the accuracy is 0.937500\n",
      "the loss is 0.430338 and the accuracy is 0.718750\n",
      "the loss is 0.183058 and the accuracy is 0.937500\n",
      "the loss is 0.329256 and the accuracy is 0.843750\n",
      "the loss is 0.426127 and the accuracy is 0.781250\n",
      "the loss is 0.444501 and the accuracy is 0.750000\n",
      "the loss is 0.188798 and the accuracy is 0.937500\n",
      "the loss is 0.173874 and the accuracy is 0.937500\n",
      "the loss is 0.175974 and the accuracy is 0.906250\n",
      "the loss is 0.311138 and the accuracy is 0.875000\n",
      "the loss is 0.247288 and the accuracy is 0.843750\n",
      "the loss is 0.300479 and the accuracy is 0.843750\n",
      "the loss is 0.218495 and the accuracy is 0.875000\n",
      "the loss is 0.354463 and the accuracy is 0.843750\n",
      "the loss is 0.330052 and the accuracy is 0.937500\n",
      "the loss is 0.163310 and the accuracy is 0.906250\n",
      "the loss is 0.386284 and the accuracy is 0.843750\n",
      "the loss is 0.297021 and the accuracy is 0.812500\n",
      "the loss is 0.207936 and the accuracy is 0.937500\n",
      "the loss is 0.539157 and the accuracy is 0.750000\n",
      "the loss is 0.327726 and the accuracy is 0.843750\n",
      "the loss is 0.297856 and the accuracy is 0.843750\n",
      "the loss is 0.358801 and the accuracy is 0.843750\n",
      "the loss is 0.287930 and the accuracy is 0.843750\n",
      "the loss is 0.190801 and the accuracy is 0.906250\n",
      "the loss is 0.253970 and the accuracy is 0.906250\n",
      "the loss is 0.234282 and the accuracy is 0.906250\n",
      "the loss is 0.208934 and the accuracy is 0.937500\n",
      "the loss is 0.182669 and the accuracy is 0.906250\n",
      "the loss is 0.388630 and the accuracy is 0.781250\n",
      "the loss is 0.377315 and the accuracy is 0.812500\n",
      "the loss is 0.298628 and the accuracy is 0.843750\n",
      "the loss is 0.416941 and the accuracy is 0.843750\n",
      "the loss is 0.226398 and the accuracy is 0.906250\n",
      "the loss is 0.400087 and the accuracy is 0.875000\n",
      "the loss is 0.173736 and the accuracy is 0.937500\n",
      "the loss is 0.226696 and the accuracy is 0.875000\n",
      "the loss is 0.371194 and the accuracy is 0.843750\n",
      "the loss is 0.234384 and the accuracy is 0.875000\n",
      "the loss is 0.191512 and the accuracy is 0.937500\n",
      "the loss is 0.345741 and the accuracy is 0.812500\n",
      "the loss is 0.324007 and the accuracy is 0.906250\n",
      "the loss is 0.230397 and the accuracy is 0.875000\n",
      "the loss is 0.307754 and the accuracy is 0.875000\n",
      "the loss is 0.296725 and the accuracy is 0.843750\n",
      "the loss is 0.237268 and the accuracy is 0.875000\n",
      "the loss is 0.199391 and the accuracy is 0.843750\n",
      "the loss is 0.205064 and the accuracy is 0.906250\n",
      "the loss is 0.302199 and the accuracy is 0.875000\n",
      "the loss is 0.391122 and the accuracy is 0.875000\n",
      "the loss is 0.283271 and the accuracy is 0.875000\n",
      "the loss is 0.266312 and the accuracy is 0.875000\n",
      "the loss is 0.210439 and the accuracy is 0.937500\n",
      "the loss is 0.272444 and the accuracy is 0.906250\n",
      "the loss is 0.435686 and the accuracy is 0.843750\n",
      "the loss is 0.409232 and the accuracy is 0.750000\n",
      "the loss is 0.363548 and the accuracy is 0.843750\n",
      "the loss is 0.514918 and the accuracy is 0.843750\n",
      "the loss is 0.409787 and the accuracy is 0.843750\n",
      "the loss is 0.379283 and the accuracy is 0.875000\n",
      "the loss is 0.480751 and the accuracy is 0.812500\n",
      "the loss is 0.248723 and the accuracy is 0.875000\n",
      "the loss is 0.440308 and the accuracy is 0.750000\n",
      "the loss is 0.313789 and the accuracy is 0.875000\n",
      "the loss is 0.217605 and the accuracy is 0.968750\n",
      "the loss is 0.218669 and the accuracy is 0.875000\n",
      "the loss is 0.463201 and the accuracy is 0.812500\n",
      "the loss is 0.281738 and the accuracy is 0.875000\n",
      "the loss is 0.212537 and the accuracy is 0.937500\n",
      "the loss is 0.244294 and the accuracy is 0.875000\n",
      "the loss is 0.537596 and the accuracy is 0.781250\n",
      "the loss is 0.289543 and the accuracy is 0.906250\n",
      "the loss is 0.305848 and the accuracy is 0.843750\n",
      "the loss is 0.154389 and the accuracy is 1.000000\n",
      "the loss is 0.294750 and the accuracy is 0.906250\n",
      "the loss is 0.352169 and the accuracy is 0.781250\n",
      "the loss is 0.376880 and the accuracy is 0.906250\n",
      "the loss is 0.267240 and the accuracy is 0.906250\n",
      "the loss is 0.240505 and the accuracy is 0.906250\n",
      "the loss is 0.252868 and the accuracy is 0.812500\n",
      "the loss is 0.250481 and the accuracy is 0.906250\n",
      "the loss is 0.263144 and the accuracy is 0.906250\n",
      "the loss is 0.237828 and the accuracy is 0.875000\n",
      "the loss is 0.494964 and the accuracy is 0.750000\n",
      "the loss is 0.387622 and the accuracy is 0.812500\n",
      "the loss is 0.375510 and the accuracy is 0.843750\n",
      "the loss is 0.300442 and the accuracy is 0.843750\n",
      "the loss is 0.154387 and the accuracy is 0.968750\n",
      "the loss is 0.312300 and the accuracy is 0.875000\n",
      "the loss is 0.262901 and the accuracy is 0.843750\n",
      "the loss is 0.268841 and the accuracy is 0.875000\n",
      "the loss is 0.244063 and the accuracy is 0.906250\n",
      "the loss is 0.415519 and the accuracy is 0.875000\n",
      "the loss is 0.385456 and the accuracy is 0.812500\n",
      "the loss is 0.358594 and the accuracy is 0.812500\n",
      "the loss is 0.294549 and the accuracy is 0.937500\n",
      "the loss is 0.196053 and the accuracy is 0.906250\n",
      "the loss is 0.253897 and the accuracy is 0.906250\n",
      "the loss is 0.214714 and the accuracy is 0.906250\n",
      "the loss is 0.295452 and the accuracy is 0.875000\n",
      "the loss is 0.260255 and the accuracy is 0.937500\n",
      "the loss is 0.095946 and the accuracy is 1.000000\n",
      "the loss is 0.311671 and the accuracy is 0.843750\n",
      "the loss is 0.266318 and the accuracy is 0.875000\n",
      "the loss is 0.273458 and the accuracy is 0.875000\n",
      "the loss is 0.561638 and the accuracy is 0.812500\n",
      "the loss is 0.248902 and the accuracy is 0.875000\n",
      "the loss is 0.147494 and the accuracy is 0.968750\n",
      "the loss is 0.307071 and the accuracy is 0.843750\n",
      "the loss is 0.358456 and the accuracy is 0.875000\n",
      "the loss is 0.235818 and the accuracy is 0.906250\n",
      "the loss is 0.305527 and the accuracy is 0.875000\n",
      "the loss is 0.264549 and the accuracy is 0.875000\n",
      "the loss is 0.209039 and the accuracy is 0.937500\n",
      "the loss is 0.411682 and the accuracy is 0.812500\n",
      "the loss is 0.218093 and the accuracy is 0.937500\n",
      "the loss is 0.203641 and the accuracy is 0.906250\n",
      "the loss is 0.273787 and the accuracy is 0.843750\n",
      "the loss is 0.282788 and the accuracy is 0.875000\n",
      "the loss is 0.279781 and the accuracy is 0.875000\n",
      "the loss is 0.400572 and the accuracy is 0.843750\n",
      "the loss is 0.346897 and the accuracy is 0.812500\n",
      "the loss is 0.447187 and the accuracy is 0.812500\n",
      "the loss is 0.385505 and the accuracy is 0.843750\n",
      "the loss is 0.224076 and the accuracy is 0.937500\n",
      "the loss is 0.330158 and the accuracy is 0.906250\n",
      "the loss is 0.291845 and the accuracy is 0.781250\n",
      "the loss is 0.200656 and the accuracy is 0.937500\n",
      "the loss is 0.212230 and the accuracy is 0.906250\n",
      "the loss is 0.309522 and the accuracy is 0.812500\n",
      "the loss is 0.294896 and the accuracy is 0.937500\n",
      "the loss is 0.414970 and the accuracy is 0.812500\n",
      "the loss is 0.373085 and the accuracy is 0.781250\n",
      "the loss is 0.193109 and the accuracy is 0.875000\n",
      "the loss is 0.322127 and the accuracy is 0.843750\n",
      "the loss is 0.402296 and the accuracy is 0.812500\n",
      "the loss is 0.136247 and the accuracy is 0.968750\n",
      "the loss is 0.263231 and the accuracy is 0.875000\n",
      "the loss is 0.261804 and the accuracy is 0.843750\n",
      "the loss is 0.471698 and the accuracy is 0.718750\n",
      "the loss is 0.269602 and the accuracy is 0.843750\n",
      "the loss is 0.344416 and the accuracy is 0.843750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.202776 and the accuracy is 0.968750\n",
      "the loss is 0.149459 and the accuracy is 0.937500\n",
      "the loss is 0.261134 and the accuracy is 0.843750\n",
      "the loss is 0.267755 and the accuracy is 0.843750\n",
      "the loss is 0.158545 and the accuracy is 0.937500\n",
      "the loss is 0.771020 and the accuracy is 0.718750\n",
      "the loss is 0.207466 and the accuracy is 0.937500\n",
      "the loss is 0.203219 and the accuracy is 0.906250\n",
      "the loss is 0.282308 and the accuracy is 0.875000\n",
      "the loss is 0.287653 and the accuracy is 0.843750\n",
      "the loss is 0.117455 and the accuracy is 0.968750\n",
      "the loss is 0.126776 and the accuracy is 0.968750\n",
      "the loss is 0.234253 and the accuracy is 0.906250\n",
      "the loss is 0.352357 and the accuracy is 0.843750\n",
      "the loss is 0.206742 and the accuracy is 0.906250\n",
      "the loss is 0.273794 and the accuracy is 0.875000\n",
      "the loss is 0.214737 and the accuracy is 0.906250\n",
      "the loss is 0.298937 and the accuracy is 0.812500\n",
      "the loss is 0.293574 and the accuracy is 0.875000\n",
      "the loss is 0.372654 and the accuracy is 0.812500\n",
      "the loss is 0.222800 and the accuracy is 0.906250\n",
      "the loss is 0.231403 and the accuracy is 0.875000\n",
      "the loss is 0.279465 and the accuracy is 0.906250\n",
      "the loss is 0.263430 and the accuracy is 0.843750\n",
      "the loss is 0.389882 and the accuracy is 0.812500\n",
      "the loss is 0.319569 and the accuracy is 0.812500\n",
      "the loss is 0.285755 and the accuracy is 0.875000\n",
      "the loss is 0.345162 and the accuracy is 0.875000\n",
      "the loss is 0.227027 and the accuracy is 0.906250\n",
      "the loss is 0.212585 and the accuracy is 0.968750\n",
      "the loss is 0.343136 and the accuracy is 0.843750\n",
      "the loss is 0.164216 and the accuracy is 0.937500\n",
      "the loss is 0.361665 and the accuracy is 0.875000\n",
      "the loss is 0.243454 and the accuracy is 0.875000\n",
      "the loss is 0.316689 and the accuracy is 0.843750\n",
      "the loss is 0.296002 and the accuracy is 0.843750\n",
      "the loss is 0.248934 and the accuracy is 0.875000\n",
      "the loss is 0.191036 and the accuracy is 0.875000\n",
      "the loss is 0.432301 and the accuracy is 0.843750\n",
      "the loss is 0.369875 and the accuracy is 0.843750\n",
      "the loss is 0.232217 and the accuracy is 0.937500\n",
      "the loss is 0.157205 and the accuracy is 0.937500\n",
      "the loss is 0.300487 and the accuracy is 0.812500\n",
      "the loss is 0.402865 and the accuracy is 0.781250\n",
      "the loss is 0.236312 and the accuracy is 0.937500\n",
      "the loss is 0.251143 and the accuracy is 0.906250\n",
      "the loss is 0.405626 and the accuracy is 0.781250\n",
      "the loss is 0.351326 and the accuracy is 0.843750\n",
      "the loss is 0.480625 and the accuracy is 0.875000\n",
      "the loss is 0.516482 and the accuracy is 0.750000\n",
      "the loss is 0.566475 and the accuracy is 0.812500\n",
      "the loss is 0.250761 and the accuracy is 0.843750\n",
      "the loss is 0.341397 and the accuracy is 0.843750\n",
      "the loss is 0.275449 and the accuracy is 0.812500\n",
      "the loss is 0.427540 and the accuracy is 0.843750\n",
      "the loss is 0.174919 and the accuracy is 0.937500\n",
      "the loss is 0.228124 and the accuracy is 0.875000\n",
      "the loss is 0.408788 and the accuracy is 0.843750\n",
      "the loss is 0.125614 and the accuracy is 0.937500\n",
      "the loss is 0.286238 and the accuracy is 0.906250\n",
      "the loss is 0.325088 and the accuracy is 0.875000\n",
      "the loss is 0.298806 and the accuracy is 0.843750\n",
      "the loss is 0.165849 and the accuracy is 0.937500\n",
      "the loss is 0.548220 and the accuracy is 0.687500\n",
      "the loss is 0.324344 and the accuracy is 0.937500\n",
      "the loss is 0.369696 and the accuracy is 0.718750\n",
      "the loss is 0.278035 and the accuracy is 0.906250\n",
      "the loss is 0.198613 and the accuracy is 0.937500\n",
      "the loss is 0.246151 and the accuracy is 0.937500\n",
      "the loss is 0.371571 and the accuracy is 0.843750\n",
      "the loss is 0.299824 and the accuracy is 0.843750\n",
      "the loss is 0.193001 and the accuracy is 0.937500\n",
      "the loss is 0.349461 and the accuracy is 0.875000\n",
      "the loss is 0.336939 and the accuracy is 0.906250\n",
      "the loss is 0.206319 and the accuracy is 0.906250\n",
      "the loss is 0.227493 and the accuracy is 0.906250\n",
      "the loss is 0.321170 and the accuracy is 0.781250\n",
      "the loss is 0.331890 and the accuracy is 0.843750\n",
      "the loss is 0.192620 and the accuracy is 0.937500\n",
      "the loss is 0.479417 and the accuracy is 0.812500\n",
      "the loss is 0.390715 and the accuracy is 0.843750\n",
      "the loss is 0.160157 and the accuracy is 0.968750\n",
      "the loss is 0.399706 and the accuracy is 0.875000\n",
      "the loss is 0.379635 and the accuracy is 0.781250\n",
      "the loss is 0.365946 and the accuracy is 0.875000\n",
      "the loss is 0.191107 and the accuracy is 0.937500\n",
      "the loss is 0.336091 and the accuracy is 0.843750\n",
      "the loss is 0.174164 and the accuracy is 0.937500\n",
      "the loss is 0.388646 and the accuracy is 0.781250\n",
      "the loss is 0.218046 and the accuracy is 0.875000\n",
      "the loss is 0.281000 and the accuracy is 0.906250\n",
      "the loss is 0.186642 and the accuracy is 0.968750\n",
      "the loss is 0.295226 and the accuracy is 0.843750\n",
      "the loss is 0.126133 and the accuracy is 0.937500\n",
      "the loss is 0.377875 and the accuracy is 0.718750\n",
      "the loss is 0.414798 and the accuracy is 0.875000\n",
      "the loss is 0.272616 and the accuracy is 0.875000\n",
      "the loss is 0.237042 and the accuracy is 0.937500\n",
      "the loss is 0.412439 and the accuracy is 0.843750\n",
      "the loss is 0.397853 and the accuracy is 0.843750\n",
      "the loss is 0.134520 and the accuracy is 0.968750\n",
      "the loss is 0.361885 and the accuracy is 0.875000\n",
      "the loss is 0.241364 and the accuracy is 0.937500\n",
      "the loss is 0.208907 and the accuracy is 0.906250\n",
      "the loss is 0.236349 and the accuracy is 0.875000\n",
      "the loss is 0.180265 and the accuracy is 0.937500\n",
      "the loss is 0.408196 and the accuracy is 0.843750\n",
      "the loss is 0.228969 and the accuracy is 0.906250\n",
      "the loss is 0.242043 and the accuracy is 0.906250\n",
      "the loss is 0.182600 and the accuracy is 0.937500\n",
      "the loss is 0.538994 and the accuracy is 0.718750\n",
      "the loss is 0.526595 and the accuracy is 0.843750\n",
      "the loss is 0.333728 and the accuracy is 0.812500\n",
      "the loss is 0.386537 and the accuracy is 0.843750\n",
      "the loss is 0.235546 and the accuracy is 0.875000\n",
      "the loss is 0.215236 and the accuracy is 0.937500\n",
      "the loss is 0.273050 and the accuracy is 0.906250\n",
      "the loss is 0.434620 and the accuracy is 0.750000\n",
      "the loss is 0.359216 and the accuracy is 0.781250\n",
      "the loss is 0.317674 and the accuracy is 0.906250\n",
      "the loss is 0.167239 and the accuracy is 0.968750\n",
      "the loss is 0.391988 and the accuracy is 0.750000\n",
      "the loss is 0.116047 and the accuracy is 1.000000\n",
      "the loss is 0.225605 and the accuracy is 0.875000\n",
      "the loss is 0.262357 and the accuracy is 0.812500\n",
      "the loss is 0.191775 and the accuracy is 0.906250\n",
      "the loss is 0.522135 and the accuracy is 0.812500\n",
      "the loss is 0.138833 and the accuracy is 0.968750\n",
      "the loss is 0.344232 and the accuracy is 0.843750\n",
      "the loss is 0.175780 and the accuracy is 0.906250\n",
      "the loss is 0.332876 and the accuracy is 0.875000\n",
      "the loss is 0.218942 and the accuracy is 0.906250\n",
      "the loss is 0.314274 and the accuracy is 0.843750\n",
      "the loss is 0.116502 and the accuracy is 1.000000\n",
      "the loss is 0.168031 and the accuracy is 0.937500\n",
      "the loss is 0.278461 and the accuracy is 0.843750\n",
      "the loss is 0.275053 and the accuracy is 0.906250\n",
      "the loss is 0.250338 and the accuracy is 0.875000\n",
      "the loss is 0.271389 and the accuracy is 0.937500\n",
      "the loss is 0.249293 and the accuracy is 0.843750\n",
      "the loss is 0.229639 and the accuracy is 0.937500\n",
      "the loss is 0.436088 and the accuracy is 0.812500\n",
      "the loss is 0.374904 and the accuracy is 0.812500\n",
      "the loss is 0.237014 and the accuracy is 0.843750\n",
      "the loss is 0.144702 and the accuracy is 0.968750\n",
      "the loss is 0.376400 and the accuracy is 0.812500\n",
      "the loss is 0.599125 and the accuracy is 0.812500\n",
      "the loss is 0.314432 and the accuracy is 0.843750\n",
      "the loss is 0.372635 and the accuracy is 0.875000\n",
      "the loss is 0.209655 and the accuracy is 0.906250\n",
      "the loss is 0.505928 and the accuracy is 0.781250\n",
      "the loss is 0.236367 and the accuracy is 0.875000\n",
      "the loss is 0.286971 and the accuracy is 0.906250\n",
      "the loss is 0.381201 and the accuracy is 0.843750\n",
      "the loss is 0.305526 and the accuracy is 0.843750\n",
      "the loss is 0.377585 and the accuracy is 0.812500\n",
      "the loss is 0.243246 and the accuracy is 0.937500\n",
      "the loss is 0.187184 and the accuracy is 0.906250\n",
      "the loss is 0.203058 and the accuracy is 0.875000\n",
      "the loss is 0.193254 and the accuracy is 0.937500\n",
      "the loss is 0.253395 and the accuracy is 0.906250\n",
      "the loss is 0.198185 and the accuracy is 0.906250\n",
      "the loss is 0.362042 and the accuracy is 0.812500\n",
      "the loss is 0.336133 and the accuracy is 0.812500\n",
      "the loss is 0.310861 and the accuracy is 0.875000\n",
      "the loss is 0.318232 and the accuracy is 0.843750\n",
      "the loss is 0.321674 and the accuracy is 0.843750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.391925 and the accuracy is 0.906250\n",
      "the loss is 0.309072 and the accuracy is 0.937500\n",
      "the loss is 0.415897 and the accuracy is 0.812500\n",
      "the loss is 0.272814 and the accuracy is 0.937500\n",
      "the loss is 0.375510 and the accuracy is 0.812500\n",
      "the loss is 0.180553 and the accuracy is 0.937500\n",
      "the loss is 0.309107 and the accuracy is 0.906250\n",
      "the loss is 0.247481 and the accuracy is 0.875000\n",
      "the loss is 0.426857 and the accuracy is 0.843750\n",
      "the loss is 0.231220 and the accuracy is 0.875000\n",
      "the loss is 0.464046 and the accuracy is 0.843750\n",
      "the loss is 0.364570 and the accuracy is 0.843750\n",
      "the loss is 0.215723 and the accuracy is 0.906250\n",
      "the loss is 0.469562 and the accuracy is 0.812500\n",
      "the loss is 0.301598 and the accuracy is 0.875000\n",
      "the loss is 0.246739 and the accuracy is 0.875000\n",
      "the loss is 0.120555 and the accuracy is 0.968750\n",
      "the loss is 0.238390 and the accuracy is 0.875000\n",
      "the loss is 0.322574 and the accuracy is 0.781250\n",
      "the loss is 0.390050 and the accuracy is 0.875000\n",
      "the loss is 0.330178 and the accuracy is 0.812500\n",
      "the loss is 0.207781 and the accuracy is 0.937500\n",
      "the loss is 0.418882 and the accuracy is 0.781250\n",
      "the loss is 0.262419 and the accuracy is 0.906250\n",
      "the loss is 0.276544 and the accuracy is 0.812500\n",
      "the loss is 0.316427 and the accuracy is 0.812500\n",
      "the loss is 0.438343 and the accuracy is 0.781250\n",
      "the loss is 0.127415 and the accuracy is 0.937500\n",
      "the loss is 0.219006 and the accuracy is 0.937500\n",
      "the loss is 0.181692 and the accuracy is 0.937500\n",
      "the loss is 0.442856 and the accuracy is 0.781250\n",
      "the loss is 0.370258 and the accuracy is 0.812500\n",
      "the loss is 0.170802 and the accuracy is 0.906250\n",
      "the loss is 0.282323 and the accuracy is 0.937500\n",
      "the loss is 0.223463 and the accuracy is 0.875000\n",
      "the loss is 0.348586 and the accuracy is 0.843750\n",
      "the loss is 0.089722 and the accuracy is 0.968750\n",
      "the loss is 0.407953 and the accuracy is 0.812500\n",
      "the loss is 0.275787 and the accuracy is 0.906250\n",
      "the loss is 0.418530 and the accuracy is 0.875000\n",
      "the loss is 0.319349 and the accuracy is 0.875000\n",
      "the loss is 0.281316 and the accuracy is 0.875000\n",
      "the loss is 0.395385 and the accuracy is 0.812500\n",
      "the loss is 0.241566 and the accuracy is 0.906250\n",
      "the loss is 0.382017 and the accuracy is 0.812500\n",
      "the loss is 0.268938 and the accuracy is 0.937500\n",
      "the loss is 0.348497 and the accuracy is 0.812500\n",
      "the loss is 0.311346 and the accuracy is 0.812500\n",
      "the loss is 0.344087 and the accuracy is 0.843750\n",
      "the loss is 0.233569 and the accuracy is 0.875000\n",
      "the loss is 0.267203 and the accuracy is 0.937500\n",
      "the loss is 0.286338 and the accuracy is 0.875000\n",
      "the loss is 0.546679 and the accuracy is 0.750000\n",
      "the loss is 0.178786 and the accuracy is 0.937500\n",
      "the loss is 0.177787 and the accuracy is 0.906250\n",
      "the loss is 0.463538 and the accuracy is 0.781250\n",
      "the loss is 0.328785 and the accuracy is 0.843750\n",
      "the loss is 0.309433 and the accuracy is 0.812500\n",
      "the loss is 0.527386 and the accuracy is 0.750000\n",
      "the loss is 0.197009 and the accuracy is 0.906250\n",
      "the loss is 0.345138 and the accuracy is 0.843750\n",
      "the loss is 0.289054 and the accuracy is 0.906250\n",
      "the loss is 0.277336 and the accuracy is 0.843750\n",
      "the loss is 0.339345 and the accuracy is 0.843750\n",
      "the loss is 0.224969 and the accuracy is 0.906250\n",
      "the loss is 0.275794 and the accuracy is 0.843750\n",
      "the loss is 0.469170 and the accuracy is 0.781250\n",
      "the loss is 0.240010 and the accuracy is 0.843750\n",
      "the loss is 0.216847 and the accuracy is 0.875000\n",
      "the loss is 0.218195 and the accuracy is 0.875000\n",
      "the loss is 0.220008 and the accuracy is 0.875000\n",
      "the loss is 0.292290 and the accuracy is 0.875000\n",
      "the loss is 0.178644 and the accuracy is 0.968750\n",
      "the loss is 0.227656 and the accuracy is 0.937500\n",
      "the loss is 0.229780 and the accuracy is 0.937500\n",
      "the loss is 0.275473 and the accuracy is 0.875000\n",
      "the loss is 0.333086 and the accuracy is 0.843750\n",
      "the loss is 0.165644 and the accuracy is 0.937500\n",
      "the loss is 0.277847 and the accuracy is 0.875000\n",
      "the loss is 0.311563 and the accuracy is 0.875000\n",
      "the loss is 0.371911 and the accuracy is 0.843750\n",
      "the loss is 0.196746 and the accuracy is 0.937500\n",
      "the loss is 0.236128 and the accuracy is 0.875000\n",
      "the loss is 0.206060 and the accuracy is 0.875000\n",
      "the loss is 0.321687 and the accuracy is 0.875000\n",
      "the loss is 0.084170 and the accuracy is 0.968750\n",
      "the loss is 0.295363 and the accuracy is 0.843750\n",
      "the loss is 0.440193 and the accuracy is 0.781250\n",
      "the loss is 0.250352 and the accuracy is 0.843750\n",
      "the loss is 0.434026 and the accuracy is 0.875000\n",
      "the loss is 0.264912 and the accuracy is 0.843750\n",
      "the loss is 0.330688 and the accuracy is 0.843750\n",
      "the loss is 0.259856 and the accuracy is 0.875000\n",
      "the loss is 0.263224 and the accuracy is 0.937500\n",
      "the loss is 0.179253 and the accuracy is 0.937500\n",
      "the loss is 0.247562 and the accuracy is 0.937500\n",
      "the loss is 0.195856 and the accuracy is 0.906250\n",
      "the loss is 0.252040 and the accuracy is 0.906250\n",
      "the loss is 0.327644 and the accuracy is 0.843750\n",
      "the loss is 0.167761 and the accuracy is 0.968750\n",
      "the loss is 0.207076 and the accuracy is 0.937500\n",
      "the loss is 0.262593 and the accuracy is 0.812500\n",
      "the loss is 0.435442 and the accuracy is 0.812500\n",
      "the loss is 0.108866 and the accuracy is 0.937500\n",
      "the loss is 0.322855 and the accuracy is 0.843750\n",
      "the loss is 0.212480 and the accuracy is 0.906250\n",
      "the loss is 0.288617 and the accuracy is 0.875000\n",
      "the loss is 0.339196 and the accuracy is 0.843750\n",
      "the loss is 0.410325 and the accuracy is 0.812500\n",
      "the loss is 0.224085 and the accuracy is 0.906250\n",
      "the loss is 0.185738 and the accuracy is 0.937500\n",
      "the loss is 0.294296 and the accuracy is 0.843750\n",
      "the loss is 0.296371 and the accuracy is 0.906250\n",
      "the loss is 0.455559 and the accuracy is 0.843750\n",
      "the loss is 0.318139 and the accuracy is 0.812500\n",
      "the loss is 0.344227 and the accuracy is 0.875000\n",
      "the loss is 0.402234 and the accuracy is 0.843750\n",
      "the loss is 0.376828 and the accuracy is 0.812500\n",
      "the loss is 0.502681 and the accuracy is 0.843750\n",
      "the loss is 0.141919 and the accuracy is 0.937500\n",
      "the loss is 0.593521 and the accuracy is 0.843750\n",
      "the loss is 0.205336 and the accuracy is 0.843750\n",
      "the loss is 0.268659 and the accuracy is 0.843750\n",
      "the loss is 0.295432 and the accuracy is 0.843750\n",
      "the loss is 0.304493 and the accuracy is 0.843750\n",
      "the loss is 0.312028 and the accuracy is 0.875000\n",
      "the loss is 0.255549 and the accuracy is 0.906250\n",
      "the loss is 0.155640 and the accuracy is 0.937500\n",
      "the loss is 0.523644 and the accuracy is 0.812500\n",
      "the loss is 0.235598 and the accuracy is 0.875000\n",
      "the loss is 0.346560 and the accuracy is 0.812500\n",
      "the loss is 0.496204 and the accuracy is 0.812500\n",
      "the loss is 0.350316 and the accuracy is 0.781250\n",
      "the loss is 0.277982 and the accuracy is 0.906250\n",
      "the loss is 0.225369 and the accuracy is 0.875000\n",
      "the loss is 0.193805 and the accuracy is 0.906250\n",
      "the loss is 0.215656 and the accuracy is 0.875000\n",
      "the loss is 0.146779 and the accuracy is 1.000000\n",
      "the loss is 0.390827 and the accuracy is 0.875000\n",
      "the loss is 0.457689 and the accuracy is 0.843750\n",
      "the loss is 0.377516 and the accuracy is 0.781250\n",
      "the loss is 0.581117 and the accuracy is 0.718750\n",
      "the loss is 0.257725 and the accuracy is 0.906250\n",
      "the loss is 0.384648 and the accuracy is 0.875000\n",
      "the loss is 0.423568 and the accuracy is 0.781250\n",
      "the loss is 0.367998 and the accuracy is 0.875000\n",
      "the loss is 0.233452 and the accuracy is 0.937500\n",
      "the loss is 0.230862 and the accuracy is 0.906250\n",
      "the loss is 0.187885 and the accuracy is 0.906250\n",
      "the loss is 0.390569 and the accuracy is 0.843750\n",
      "the loss is 0.327430 and the accuracy is 0.843750\n",
      "the loss is 0.455507 and the accuracy is 0.781250\n",
      "the loss is 0.248220 and the accuracy is 0.843750\n",
      "the loss is 0.139593 and the accuracy is 0.968750\n",
      "the loss is 0.342947 and the accuracy is 0.843750\n",
      "the loss is 0.346464 and the accuracy is 0.812500\n",
      "the loss is 0.197930 and the accuracy is 0.937500\n",
      "the loss is 0.224028 and the accuracy is 0.875000\n",
      "the loss is 0.121206 and the accuracy is 0.968750\n",
      "the loss is 0.328146 and the accuracy is 0.812500\n",
      "the loss is 0.274746 and the accuracy is 0.906250\n",
      "the loss is 0.320789 and the accuracy is 0.843750\n",
      "the loss is 0.196583 and the accuracy is 0.937500\n",
      "the loss is 0.535847 and the accuracy is 0.687500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.156236 and the accuracy is 0.968750\n",
      "the loss is 0.278249 and the accuracy is 0.906250\n",
      "the loss is 0.180052 and the accuracy is 0.937500\n",
      "the loss is 0.176518 and the accuracy is 0.937500\n",
      "the loss is 0.183196 and the accuracy is 0.968750\n",
      "the loss is 0.280791 and the accuracy is 0.875000\n",
      "the loss is 0.383301 and the accuracy is 0.812500\n",
      "the loss is 0.219458 and the accuracy is 0.906250\n",
      "the loss is 0.415104 and the accuracy is 0.875000\n",
      "the loss is 0.310182 and the accuracy is 0.875000\n",
      "the loss is 0.277007 and the accuracy is 0.875000\n",
      "the loss is 0.116641 and the accuracy is 0.968750\n",
      "the loss is 0.269258 and the accuracy is 0.906250\n",
      "the loss is 0.178826 and the accuracy is 0.937500\n",
      "the loss is 0.206946 and the accuracy is 0.968750\n",
      "the loss is 0.283247 and the accuracy is 0.843750\n",
      "the loss is 0.380614 and the accuracy is 0.875000\n",
      "the loss is 0.296028 and the accuracy is 0.875000\n",
      "the loss is 0.274971 and the accuracy is 0.843750\n",
      "the loss is 0.210572 and the accuracy is 0.875000\n",
      "the loss is 0.377596 and the accuracy is 0.843750\n",
      "the loss is 0.256462 and the accuracy is 0.843750\n",
      "the loss is 0.321711 and the accuracy is 0.843750\n",
      "the loss is 0.403266 and the accuracy is 0.781250\n",
      "the loss is 0.269308 and the accuracy is 0.843750\n",
      "the loss is 0.174072 and the accuracy is 0.937500\n",
      "the loss is 0.492274 and the accuracy is 0.781250\n",
      "the loss is 0.306249 and the accuracy is 0.843750\n",
      "the loss is 0.237191 and the accuracy is 0.906250\n",
      "the loss is 0.201541 and the accuracy is 0.906250\n",
      "the loss is 0.186398 and the accuracy is 0.906250\n",
      "the loss is 0.379254 and the accuracy is 0.843750\n",
      "the loss is 0.286985 and the accuracy is 0.843750\n",
      "the loss is 0.134394 and the accuracy is 0.968750\n",
      "the loss is 0.384035 and the accuracy is 0.750000\n",
      "the loss is 0.238316 and the accuracy is 0.937500\n",
      "the loss is 0.274390 and the accuracy is 0.906250\n",
      "the loss is 0.338494 and the accuracy is 0.906250\n",
      "the loss is 0.228829 and the accuracy is 0.875000\n",
      "the loss is 0.171752 and the accuracy is 0.937500\n",
      "the loss is 0.141887 and the accuracy is 0.937500\n",
      "the loss is 0.239838 and the accuracy is 0.875000\n",
      "the loss is 0.282321 and the accuracy is 0.875000\n",
      "the loss is 0.256027 and the accuracy is 0.875000\n",
      "the loss is 0.425118 and the accuracy is 0.875000\n",
      "the loss is 0.220491 and the accuracy is 0.937500\n",
      "the loss is 0.420492 and the accuracy is 0.812500\n",
      "the loss is 0.385169 and the accuracy is 0.781250\n",
      "the loss is 0.199347 and the accuracy is 0.937500\n",
      "the loss is 0.409147 and the accuracy is 0.875000\n",
      "the loss is 0.244880 and the accuracy is 0.812500\n",
      "the loss is 0.234749 and the accuracy is 0.875000\n",
      "the loss is 0.325560 and the accuracy is 0.906250\n",
      "the loss is 0.406147 and the accuracy is 0.781250\n",
      "the loss is 0.196266 and the accuracy is 0.875000\n",
      "the loss is 0.298681 and the accuracy is 0.875000\n",
      "the loss is 0.288230 and the accuracy is 0.875000\n",
      "the loss is 0.387113 and the accuracy is 0.875000\n",
      "the loss is 0.385285 and the accuracy is 0.875000\n",
      "the loss is 0.331746 and the accuracy is 0.875000\n",
      "the loss is 0.478702 and the accuracy is 0.750000\n",
      "the loss is 0.303818 and the accuracy is 0.812500\n",
      "the loss is 0.442362 and the accuracy is 0.781250\n",
      "the loss is 0.265706 and the accuracy is 0.875000\n",
      "the loss is 0.223471 and the accuracy is 0.937500\n",
      "the loss is 0.144864 and the accuracy is 0.968750\n",
      "the loss is 0.161043 and the accuracy is 0.906250\n",
      "the loss is 0.251265 and the accuracy is 0.875000\n",
      "the loss is 0.251796 and the accuracy is 0.875000\n",
      "the loss is 0.349996 and the accuracy is 0.843750\n",
      "the loss is 0.183961 and the accuracy is 0.906250\n",
      "the loss is 0.270867 and the accuracy is 0.843750\n",
      "the loss is 0.379650 and the accuracy is 0.843750\n",
      "the loss is 0.409499 and the accuracy is 0.781250\n",
      "the loss is 0.286709 and the accuracy is 0.843750\n",
      "the loss is 0.206650 and the accuracy is 0.875000\n",
      "the loss is 0.256639 and the accuracy is 0.875000\n",
      "the loss is 0.383649 and the accuracy is 0.812500\n",
      "the loss is 0.410081 and the accuracy is 0.750000\n",
      "the loss is 0.194609 and the accuracy is 0.968750\n",
      "the loss is 0.325046 and the accuracy is 0.906250\n",
      "the loss is 0.217764 and the accuracy is 0.937500\n",
      "the loss is 0.189043 and the accuracy is 0.906250\n",
      "the loss is 0.321997 and the accuracy is 0.875000\n",
      "the loss is 0.341696 and the accuracy is 0.906250\n",
      "the loss is 0.405905 and the accuracy is 0.843750\n",
      "the loss is 0.496315 and the accuracy is 0.812500\n",
      "the loss is 0.462835 and the accuracy is 0.750000\n",
      "the loss is 0.160311 and the accuracy is 0.937500\n",
      "the loss is 0.287268 and the accuracy is 0.875000\n",
      "the loss is 0.311088 and the accuracy is 0.843750\n",
      "the loss is 0.152365 and the accuracy is 0.968750\n",
      "the loss is 0.174713 and the accuracy is 0.875000\n",
      "the loss is 0.345109 and the accuracy is 0.781250\n",
      "the loss is 0.181247 and the accuracy is 0.906250\n",
      "the loss is 0.195898 and the accuracy is 0.937500\n",
      "the loss is 0.398954 and the accuracy is 0.875000\n",
      "the loss is 0.279044 and the accuracy is 0.812500\n",
      "the loss is 0.289785 and the accuracy is 0.843750\n",
      "the loss is 0.412807 and the accuracy is 0.843750\n",
      "the loss is 0.183323 and the accuracy is 0.937500\n",
      "the loss is 0.285904 and the accuracy is 0.875000\n",
      "the loss is 0.256377 and the accuracy is 0.906250\n",
      "the loss is 0.291633 and the accuracy is 0.906250\n",
      "the loss is 0.269041 and the accuracy is 0.875000\n",
      "the loss is 0.172277 and the accuracy is 0.937500\n",
      "the loss is 0.255126 and the accuracy is 0.875000\n",
      "the loss is 0.200425 and the accuracy is 0.906250\n",
      "the loss is 0.361083 and the accuracy is 0.843750\n",
      "the loss is 0.263203 and the accuracy is 0.906250\n",
      "the loss is 0.251021 and the accuracy is 0.875000\n",
      "the loss is 0.296956 and the accuracy is 0.937500\n",
      "the loss is 0.387195 and the accuracy is 0.843750\n",
      "the loss is 0.387514 and the accuracy is 0.812500\n",
      "the loss is 0.335979 and the accuracy is 0.875000\n",
      "the loss is 0.444168 and the accuracy is 0.875000\n",
      "the loss is 0.091598 and the accuracy is 1.000000\n",
      "the loss is 0.365692 and the accuracy is 0.843750\n",
      "the loss is 0.445104 and the accuracy is 0.781250\n",
      "the loss is 0.339689 and the accuracy is 0.843750\n",
      "the loss is 0.306455 and the accuracy is 0.812500\n",
      "the loss is 0.164743 and the accuracy is 0.906250\n",
      "the loss is 0.349898 and the accuracy is 0.812500\n",
      "the loss is 0.503011 and the accuracy is 0.781250\n",
      "the loss is 0.359077 and the accuracy is 0.843750\n",
      "the loss is 0.277803 and the accuracy is 0.843750\n",
      "the loss is 0.395179 and the accuracy is 0.812500\n",
      "the loss is 0.473676 and the accuracy is 0.812500\n",
      "the loss is 0.325437 and the accuracy is 0.906250\n",
      "the loss is 0.268814 and the accuracy is 0.906250\n",
      "the loss is 0.220215 and the accuracy is 0.968750\n",
      "the loss is 0.208699 and the accuracy is 0.906250\n",
      "the loss is 0.228553 and the accuracy is 0.906250\n",
      "the loss is 0.218891 and the accuracy is 0.937500\n",
      "the loss is 0.322129 and the accuracy is 0.906250\n",
      "the loss is 0.211322 and the accuracy is 0.906250\n",
      "the loss is 0.243055 and the accuracy is 0.906250\n",
      "the loss is 0.203250 and the accuracy is 0.937500\n",
      "the loss is 0.517264 and the accuracy is 0.687500\n",
      "the loss is 0.485872 and the accuracy is 0.781250\n",
      "the loss is 0.402549 and the accuracy is 0.812500\n",
      "the loss is 0.312221 and the accuracy is 0.812500\n",
      "the loss is 0.238977 and the accuracy is 0.875000\n",
      "the loss is 0.204591 and the accuracy is 0.937500\n",
      "the loss is 0.304666 and the accuracy is 0.843750\n",
      "the loss is 0.204358 and the accuracy is 0.906250\n",
      "the loss is 0.162099 and the accuracy is 0.968750\n",
      "the loss is 0.325922 and the accuracy is 0.906250\n",
      "the loss is 0.454598 and the accuracy is 0.812500\n",
      "the loss is 0.357864 and the accuracy is 0.812500\n",
      "the loss is 0.335997 and the accuracy is 0.843750\n",
      "the loss is 0.252162 and the accuracy is 0.812500\n",
      "the loss is 0.338210 and the accuracy is 0.906250\n",
      "the loss is 0.286477 and the accuracy is 0.843750\n",
      "the loss is 0.253728 and the accuracy is 0.875000\n",
      "the loss is 0.222993 and the accuracy is 0.843750\n",
      "the loss is 0.269468 and the accuracy is 0.843750\n",
      "the loss is 0.149998 and the accuracy is 0.968750\n",
      "the loss is 0.360591 and the accuracy is 0.781250\n",
      "the loss is 0.268212 and the accuracy is 0.875000\n",
      "the loss is 0.302494 and the accuracy is 0.906250\n",
      "the loss is 0.231904 and the accuracy is 0.843750\n",
      "the loss is 0.321791 and the accuracy is 0.843750\n",
      "the loss is 0.274515 and the accuracy is 0.875000\n",
      "the loss is 0.301603 and the accuracy is 0.812500\n",
      "the loss is 0.546509 and the accuracy is 0.875000\n",
      "the loss is 0.309019 and the accuracy is 0.906250\n",
      "the loss is 0.391813 and the accuracy is 0.875000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is 0.412722 and the accuracy is 0.781250\n",
      "the loss is 0.645474 and the accuracy is 0.718750\n",
      "the loss is 0.288513 and the accuracy is 0.875000\n",
      "the loss is 0.341441 and the accuracy is 0.875000\n",
      "the loss is 0.416576 and the accuracy is 0.906250\n",
      "the loss is 0.405128 and the accuracy is 0.750000\n",
      "the loss is 0.299159 and the accuracy is 0.875000\n",
      "the loss is 0.217114 and the accuracy is 0.906250\n",
      "the loss is 0.154547 and the accuracy is 0.968750\n",
      "the loss is 0.391375 and the accuracy is 0.812500\n",
      "the loss is 0.168188 and the accuracy is 0.906250\n",
      "the loss is 0.341552 and the accuracy is 0.875000\n",
      "the loss is 0.300788 and the accuracy is 0.843750\n",
      "the loss is 0.305392 and the accuracy is 0.906250\n",
      "the loss is 0.314034 and the accuracy is 0.812500\n",
      "the loss is 0.209268 and the accuracy is 0.937500\n",
      "the loss is 0.166563 and the accuracy is 0.937500\n",
      "the loss is 0.121366 and the accuracy is 1.000000\n",
      "the loss is 0.371397 and the accuracy is 0.843750\n",
      "the loss is 0.130107 and the accuracy is 0.968750\n",
      "the loss is 0.238555 and the accuracy is 0.875000\n",
      "the loss is 0.445817 and the accuracy is 0.718750\n",
      "the loss is 0.474400 and the accuracy is 0.812500\n",
      "the loss is 0.345136 and the accuracy is 0.875000\n",
      "the loss is 0.195565 and the accuracy is 0.968750\n",
      "the loss is 0.185412 and the accuracy is 0.937500\n",
      "the loss is 0.268457 and the accuracy is 0.906250\n",
      "the loss is 0.331446 and the accuracy is 0.843750\n",
      "the loss is 0.339763 and the accuracy is 0.750000\n",
      "the loss is 0.449145 and the accuracy is 0.906250\n",
      "the loss is 0.223628 and the accuracy is 0.906250\n",
      "the loss is 0.205415 and the accuracy is 0.937500\n",
      "the loss is 0.329949 and the accuracy is 0.843750\n",
      "the loss is 0.298220 and the accuracy is 0.875000\n",
      "the loss is 0.163795 and the accuracy is 0.937500\n",
      "the loss is 0.264293 and the accuracy is 0.875000\n",
      "the loss is 0.232265 and the accuracy is 0.875000\n",
      "the loss is 0.399343 and the accuracy is 0.812500\n",
      "the loss is 0.576428 and the accuracy is 0.718750\n",
      "the loss is 0.325864 and the accuracy is 0.781250\n",
      "the loss is 0.457894 and the accuracy is 0.781250\n",
      "the loss is 0.309791 and the accuracy is 0.843750\n",
      "the loss is 0.254308 and the accuracy is 0.843750\n",
      "the loss is 0.173309 and the accuracy is 0.968750\n",
      "the loss is 0.208135 and the accuracy is 0.906250\n",
      "the loss is 0.270027 and the accuracy is 0.843750\n",
      "the loss is 0.229989 and the accuracy is 0.875000\n",
      "the loss is 0.332745 and the accuracy is 0.937500\n",
      "the loss is 0.233334 and the accuracy is 0.937500\n",
      "the loss is 0.360663 and the accuracy is 0.812500\n",
      "the loss is 0.294227 and the accuracy is 0.875000\n",
      "the loss is 0.288124 and the accuracy is 0.906250\n",
      "the loss is 0.261579 and the accuracy is 0.875000\n",
      "the loss is 0.366527 and the accuracy is 0.875000\n",
      "the loss is 0.334169 and the accuracy is 0.875000\n",
      "the loss is 0.242931 and the accuracy is 0.875000\n",
      "the loss is 0.481265 and the accuracy is 0.843750\n",
      "the loss is 0.391267 and the accuracy is 0.781250\n",
      "the loss is 0.223022 and the accuracy is 0.906250\n",
      "the loss is 0.241552 and the accuracy is 0.906250\n",
      "the loss is 0.285773 and the accuracy is 0.812500\n",
      "the loss is 0.299248 and the accuracy is 0.937500\n",
      "the loss is 0.172128 and the accuracy is 0.906250\n",
      "the loss is 0.156572 and the accuracy is 0.937500\n",
      "the loss is 0.348755 and the accuracy is 0.906250\n",
      "the loss is 0.346375 and the accuracy is 0.875000\n",
      "the loss is 0.237196 and the accuracy is 0.906250\n",
      "the loss is 0.290901 and the accuracy is 0.906250\n",
      "the loss is 0.302639 and the accuracy is 0.875000\n",
      "the loss is 0.337466 and the accuracy is 0.718750\n",
      "the loss is 0.444638 and the accuracy is 0.750000\n",
      "the loss is 0.232123 and the accuracy is 0.937500\n",
      "the loss is 0.150240 and the accuracy is 0.937500\n",
      "the loss is 0.233704 and the accuracy is 0.843750\n",
      "the loss is 0.211906 and the accuracy is 0.937500\n",
      "the loss is 0.225847 and the accuracy is 0.906250\n",
      "the loss is 0.364068 and the accuracy is 0.875000\n",
      "the loss is 0.289200 and the accuracy is 0.843750\n",
      "the loss is 0.214589 and the accuracy is 0.906250\n",
      "the loss is 0.184911 and the accuracy is 0.906250\n",
      "the loss is 0.380996 and the accuracy is 0.843750\n",
      "the loss is 0.319259 and the accuracy is 0.812500\n",
      "the loss is 0.292736 and the accuracy is 0.875000\n",
      "the loss is 0.305438 and the accuracy is 0.875000\n",
      "the loss is 0.406108 and the accuracy is 0.812500\n",
      "the loss is 0.254291 and the accuracy is 0.875000\n",
      "the loss is 0.490788 and the accuracy is 0.781250\n",
      "the loss is 0.160719 and the accuracy is 0.968750\n",
      "the loss is 0.397069 and the accuracy is 0.906250\n",
      "the loss is 0.181695 and the accuracy is 0.906250\n",
      "the loss is 0.266755 and the accuracy is 0.906250\n",
      "the loss is 0.396156 and the accuracy is 0.843750\n",
      "the loss is 0.218760 and the accuracy is 0.906250\n",
      "the loss is 0.294405 and the accuracy is 0.843750\n",
      "the loss is 0.375767 and the accuracy is 0.781250\n",
      "the loss is 0.139333 and the accuracy is 0.937500\n",
      "the loss is 0.282817 and the accuracy is 0.843750\n",
      "the loss is 0.340112 and the accuracy is 0.843750\n",
      "the loss is 0.310035 and the accuracy is 0.875000\n",
      "the loss is 0.271823 and the accuracy is 0.875000\n",
      "the loss is 0.253197 and the accuracy is 0.843750\n",
      "the loss is 0.293746 and the accuracy is 0.906250\n",
      "the loss is 0.487948 and the accuracy is 0.718750\n",
      "the loss is 0.185937 and the accuracy is 0.906250\n",
      "the loss is 0.283110 and the accuracy is 0.875000\n",
      "the loss is 0.326287 and the accuracy is 0.843750\n",
      "the loss is 0.233148 and the accuracy is 0.937500\n",
      "the loss is 0.309626 and the accuracy is 0.906250\n",
      "the loss is 0.321108 and the accuracy is 0.906250\n",
      "the loss is 0.234664 and the accuracy is 0.906250\n",
      "the loss is 0.133565 and the accuracy is 0.937500\n",
      "the loss is 0.214241 and the accuracy is 0.906250\n",
      "the loss is 0.352904 and the accuracy is 0.906250\n",
      "the loss is 0.462961 and the accuracy is 0.750000\n",
      "the loss is 0.449698 and the accuracy is 0.781250\n",
      "the loss is 0.416914 and the accuracy is 0.812500\n",
      "the loss is 0.255614 and the accuracy is 0.906250\n",
      "the loss is 0.140416 and the accuracy is 0.937500\n",
      "the loss is 0.277578 and the accuracy is 0.906250\n",
      "the loss is 0.414618 and the accuracy is 0.781250\n",
      "the loss is 0.511836 and the accuracy is 0.781250\n",
      "the loss is 0.365041 and the accuracy is 0.843750\n",
      "the loss is 0.514295 and the accuracy is 0.750000\n",
      "the loss is 0.245463 and the accuracy is 0.875000\n",
      "the loss is 0.199207 and the accuracy is 0.937500\n",
      "the loss is 0.261376 and the accuracy is 0.812500\n",
      "the loss is 0.137227 and the accuracy is 0.968750\n",
      "the loss is 0.462691 and the accuracy is 0.781250\n",
      "the loss is 0.145468 and the accuracy is 0.968750\n",
      "the loss is 0.244963 and the accuracy is 0.906250\n",
      "the loss is 0.236329 and the accuracy is 0.906250\n",
      "the loss is 0.137224 and the accuracy is 0.937500\n",
      "the loss is 0.483830 and the accuracy is 0.812500\n",
      "the loss is 0.359222 and the accuracy is 0.843750\n",
      "the loss is 0.154671 and the accuracy is 0.937500\n",
      "the loss is 0.346306 and the accuracy is 0.843750\n",
      "the loss is 0.200623 and the accuracy is 0.937500\n",
      "the loss is 0.234253 and the accuracy is 0.906250\n",
      "the loss is 0.278020 and the accuracy is 0.875000\n",
      "the loss is 0.374985 and the accuracy is 0.750000\n",
      "the loss is 0.403538 and the accuracy is 0.812500\n",
      "the loss is 0.248524 and the accuracy is 0.875000\n",
      "the loss is 0.322766 and the accuracy is 0.843750\n",
      "the loss is 0.196567 and the accuracy is 0.906250\n",
      "the loss is 0.346680 and the accuracy is 0.843750\n",
      "the loss is 0.542696 and the accuracy is 0.750000\n",
      "the loss is 0.229009 and the accuracy is 0.906250\n",
      "the loss is 0.255606 and the accuracy is 0.906250\n",
      "the loss is 0.164675 and the accuracy is 0.937500\n",
      "the loss is 0.173142 and the accuracy is 0.937500\n",
      "the loss is 0.251156 and the accuracy is 0.875000\n",
      "the loss is 0.392202 and the accuracy is 0.781250\n",
      "the loss is 0.206389 and the accuracy is 0.906250\n",
      "the loss is 0.199721 and the accuracy is 0.937500\n",
      "the loss is 0.432985 and the accuracy is 0.812500\n",
      "the loss is 0.155428 and the accuracy is 0.968750\n",
      "the loss is 0.198152 and the accuracy is 0.937500\n",
      "the loss is 0.239598 and the accuracy is 0.843750\n",
      "the loss is 0.319677 and the accuracy is 0.875000\n",
      "the loss is 0.391003 and the accuracy is 0.875000\n",
      "the loss is 0.507233 and the accuracy is 0.812500\n",
      "the loss is 0.235741 and the accuracy is 0.937500\n",
      "the loss is 0.227058 and the accuracy is 0.875000\n",
      "the loss is 0.317782 and the accuracy is 0.937500\n",
      "the loss is 0.419573 and the accuracy is 0.843750\n",
      "the loss is 0.356910 and the accuracy is 0.843750\n",
      "the loss is 0.242085 and the accuracy is 0.906250\n",
      "the loss is 0.319074 and the accuracy is 0.843750\n",
      "the loss is 0.253269 and the accuracy is 0.937500\n",
      "the loss is 0.160801 and the accuracy is 0.937500\n",
      "the loss is 0.211236 and the accuracy is 0.968750\n",
      "the loss is 0.424437 and the accuracy is 0.812500\n",
      "the loss is 0.246017 and the accuracy is 0.812500\n",
      "the loss is 0.286429 and the accuracy is 0.875000\n",
      "the loss is 0.320096 and the accuracy is 0.906250\n",
      "the loss is 0.326164 and the accuracy is 0.875000\n",
      "the loss is 0.109173 and the accuracy is 0.968750\n",
      "the loss is 0.241126 and the accuracy is 0.937500\n",
      "the loss is 0.203612 and the accuracy is 0.875000\n",
      "done training\n"
     ]
    }
   ],
   "source": [
    "% run train_lr_model.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
